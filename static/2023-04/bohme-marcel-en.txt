My talk is going to be a little different.
So my talk is going to be on a surprising efficiency and exponential cost of fuzzing.
So how can something be surprisingly efficient and also come with an exponential cost?
So the actual purpose of this talk is to introduce to the weirdness of randomness and probability theory.
So given it - given a name of this event I won't talk much about the theory
but I want to talk about intuition.
And one of the key messages that I want you to take away from this talk is that we might have strong intuitions about solving a problem
but without a deep understanding of the problem sometimes our intuitions might lead us astray.
So what is fuzzing?
Fuzzing is a testing process.
So here we are given a program and that program takes four characters.
One approach to test this program is called white box fuzzing - white box because the first thing is that the analysis can actually see
the internals of that program.
The program has four branches and we could now try to explore every path in that program simply by trying to capture the conditions of each of these branches.
Say one branch is - one input would be exercising the path where the first character is not a b,
another input would exercise that path where the first input is a b but the second input is not an a,
and so on.
So we could explore all paths and at the end after exploring the fifth path - number five - we would see that
the program actually crashes.
And so in this sense this approach called white box fuzzing is actually most effective.
Why most effective?
Because it can actually prove the absence of an error,
in this case of an assertion violation,
simply by enumerating all paths through the program.
Because you're making some assumptions but in principle we could say that white box buzzing would be able to prove the absence of error,
in this sense be most effective.
And also it's quite efficient,
so if we -
suppose we are -
we have these five -
there are five paths in that program.
If we sample a path at random without replacement we would expect to take about three inputs to find that crashing bug,
right,
generated by enumerating all of these paths using this technique called white box buzzing.
Now on the other side of the spectrum there's something called black box fuzzing.
Black box fuzzing doesn't know anything about the program - what it would do -
it simply generates random inputs for that program.
So in - on most machines a character can take one of 256 values,
and suppose we just randomly generate these values using sampling - uniform at random with replacement.
Of course it can never prove the absence of errors,
in fact there's this great quote by Dijkstra saying program testing can be used to show the presence of bugs
but never too show their absence.
It's almost more recently we've looked into this problem of giving testing some kind of statistical guarantees
so we can somehow compute what is called a residual risk after a certain amount of testing
but the effect remains,
black box fuzzing is not most effective -
it cannot prove the absence of errors.
Okay so then if we look at this from a statistical perspective,
I said earlier that white box fuzzing would require about three inputs and expectation to find that bug.
Now black box fuzzing,
if we sample each input each value for each character uniformly at random,
we would expect to generate about four billion inputs before discovering this bug.
This sounds a lot.
So then white box buzzing should be better, right,
it's the most effective, it's also quite efficient.
And here it's where it's going wrong for the first time,
at least not always.
Sometimes black box fuzzing wins.
And this was discovered 30-40 years ago when people started doing experiments with these two techniques
with the hypothetically most effective technique and with just a simple random sampling.
Somehow they found that given some limited time,
this very simple, very dumb, technique wins and finds more bugs than the most effective technique.
And so we looked at this very recently from a statistical perspective
and found that if a white box fuzzer takes too long per input our black box fuzzer outperforms the white box fuzzer.
Right,
if the generation for one input takes too long then the black box fuzzer outperforms.
Because the black box fuzzer generates inputs very fast.
So on my machine it takes about 6.3 seconds to generate 4 billion inputs
and if I had 100 machines it would take 63 milliseconds
so we can easily scale bug finding because because black box fuzzing is essentially embarrassingly parallel.
And so in this paper we actually give a probabilistic bound on this maximum time.
So then is black box fuzzing the best that we can do?
And the answer here is wrong, not - we can do even better than that.
So what I presented here was a generational black box fuzzer.
What it means is,
I generate values for each of these characters,
but I could also - instead of trying to generate inputs from scratch,
which is the generational approach,
maybe we can reuse existing inputs,
and this is called mutational black box testing.
So suppose we have a seed input which is "bad?"
The bad input is "bad!"
So if we had a mutational fuzzer which simply selects the four - which simply selects the character at random
and then chooses a value for that at random
then with a probability of one over four times one over 256
an expectation of about 1000 inputs
which is much less than four billion inputs.
But I cheated a little bit here.
We chose a really good seed to start with,
so can we do even better?
Can we somehow automatically discover this seed input?
And this is where the third approach gray box fuzzing comes in.
Can we make can we take the advantage of black box fuzzing and the advantage of white box fuzzing,
can we kind of combine it?
And gray box fuzzing - because we don't actually analyze the program,
but we take some feedback called coverage feedback from gray box buzzing
and we add generated inputs to the corpus which increase coverage.
So suppose we just start with a random input.
The probability that we generate the first coverage increasing input is one over one thousand,
which means an expectation we require about 1024 inputs to generate the first coverage increasing input.
We add it to the corpus then we select this next seed uniformly at random
and in this case - this seed - and the probability that we chose this seed, this character and generate 'a' as the value requires about 2000 inputs.
So we go on like that,
and easily starting from a random input we can generate - we can find a bug using only 10,000 inputs.
And now my machine just takes 150 microseconds.
So we - so this is much faster than a symbolic execution tool which requires all this machinery - constraint solving and encoding and so on for three inputs.
And in the work that we presented at CCS16 we also boosted gray box fuzzing simply by choosing that seed
which exercises the lowest probability domain,
and we go down further to four thousand inputs and to 55 microseconds.
Okay so the insight is,
if you have a really efficient fuzzer let's just throw more machines at the problem.
You remember on my machine it takes 6.3 seconds,
on 100 machines it takes 63 milliseconds to find the same bug.
So then you might think,
well, if I have - I can take X times small machines means I can find X times more bugs, right?
And again we are wrong.
So this is an empirical cost.
We looked at a lot of data where we see this is an exponentially increasing number of machines.
It's a log scale here.
And this is the number of additional vulnerabilities discovered within the same time.
And we see that on a linear increase in the number of new vulnerabilities discovered requires an exponential increase in the number of machines.
And this is the exponential cost.
And a little bit of an explanation here,
this is just the intuition.
If you think about just one bug and we increase the number of machines exponentially for a long time we won't -
for a long time means the number of machines -
we won't see that bug
and there's almost linear increase at a certain number of machines
and then we are again almost -
we have discovered this bug and so we kind of go on with a straight line.
If we now - instead of having just one vulnerability we have 10 vulnerabilities
we kind of get these quickly lines and they almost look like straight lines
and we increase the number of - the number of vulnerabilities, number of bugs or whatever you want to measure you find it -
you get more and more linear.
And the reason for this is that we have these kind of constant - we never see that either -
we never see the one to be discovered or we always see the one already discovered
and in between we have this kind of almost linear increases.
This is how we kind of get this linear increase for an exponential number of machines.
Okay so intuitively each new vulnerability requires some more resources than the previous vulnerability
so the constant rate of vulnerability discovery requires exponential amount of resources.
So what I showed you is white box fuzzing - we have a technique which we really love to work with,
which is really smart,
which analyzes the program,
which in fact is the most effective,
but in practice it is easily outperformed by a very dumb technique called black box fuzzing,
by simply randomly generating inputs.
And in fact this is so efficient that we can easily scale that across a lot of machines and find the same the same number of bugs X times faster.
I also talked about a machine that kind of leverages the efficiency of black box fuzzing but it's more like -
but it enumerates paths like whitebox fuzzing
but then I explained how even that gray box fuzzing technique includes black box fuzzing
and gray box fuzzing are somehow affected by an exponential cost.
Thank you so much.
All right thank you very much Marcel.
It's great to see this kind of quantitative approach to this problem.
A question coming in from one of the viewers is,
how much of the statistics do I need to understand to be able to apply these sorts of techniques?
Oh so there's - that's - to apply it has no need to understand statistics.
It's more like - to understand the statistics is more a help for you that -
For instance, the insight that you cannot just throw more machines at the problem and then hopefully you find more bugs, doesn't work.
At some point you kind of run out of machines because the cost for finding more vulnerabilities is exponential.
That's interesting to understand why this is the case and we use statistics and probability theory to explain why this is the case.
But when you apply fuzzing you don't need to know,
you don't need to know understand the statistics.
Maybe one other thing that we explored is that - we are often interested in the probability that we find about -
if we have not found a bug.
Suppose you have run a campaign for 24 hours and you have not found any bug,
You still want to know what is the probability that we find a bug with just one more input generated
and this is where you can use statistics.
