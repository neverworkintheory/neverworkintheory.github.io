@comment{AAA}

@inproceedings{Abdalkareem2017,
  doi = {10.1145/3106237.3106267},
  url = {https://doi.org/10.1145/3106237.3106267},
  year = {2017},
  month = aug,
  publisher = {{ACM}},
  author = {Rabe Abdalkareem and Olivier Nourry and Sultan Wehaibi and Suhaib Mujahid and Emad Shihab},
  title = {Why do developers use trivial packages? an empirical case study on npm},
  booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
  abstract = {Code reuse is traditionally seen as good practice. Recent trends have pushed the concept of code reuse to an extreme, by using packages that implement simple and trivial tasks, which we call 'trivial packages'. A recent incident where a trivial package led to the breakdown of some of the most popular web applications such as Facebook and Netflix made it imperative to question the growing use of trivial packages. Therefore, in this paper, we mine more than 230,000 npm packages and 38,000 JavaScript applications in order to study the prevalence of trivial packages. We found that trivial packages are common and are increasing in popularity, making up 16.8\% of the studied npm packages. We performed a survey with 88 Node.js developers who use trivial packages to understand the reasons and drawbacks of their use. Our survey revealed that trivial packages are used because they are perceived to be well implemented and tested pieces of code. However, developers are concerned about maintaining and the risks of breakages due to the extra dependencies trivial packages introduce. To objectively verify the survey results, we empirically validate the most cited reason and drawback and find that, contrary to developers' beliefs, only 45.2\% of trivial packages even have tests. However, trivial packages appear to be `deployment tested' and to have similar test, usage and community interest as non-trivial packages. On the other hand, we found that 11.5\% of the studied trivial packages have more than 20 dependencies. Hence, developers should be careful about which trivial packages they decide to use.}
}

@article{AbuHassan2020,
  doi = {10.1002/smr.2320},
  url = {https://doi.org/10.1002/smr.2320},
  year = {2020},
  month = oct,
  publisher = {Wiley},
  volume = {33},
  number = {3},
  author = {Amjad AbuHassan and Mohammad Alshayeb and Lahouari Ghouti},
  title = {Software smell detection techniques: A systematic literature review},
  journal = {Journal of Software: Evolution and Process},
  abstract = {Software smells indicate design or code issues that might degrade the evolution and maintenance of software systems. Detecting and identifying these issues are challenging tasks. This paper explores, identifies, and analyzes the existing software smell detection techniques at design and code levels. We carried out a systematic literature review (SLR) to identify and collect 145 primary studies related to smell detection in software design and code. Based on these studies, we address several questions related to the analysis of the existing smell detection techniques in terms of abstraction level (design or code), targeted smells, used metrics, implementation, and validation. Our analysis identified several detection techniques categories. We observed that 57\% of the studies did not use any performance measures, 41\% of them omitted details on the targeted programing language, and the detection techniques were not validated in 14\% of these studies. With respect to the abstraction level, only 18\% of the studies addressed bad smell detection at the design level. This low coverage urges for more focus on bad smell detection at the design level to handle them at early stages. Finally, our SLR brings to the attention of the research community several opportunities for future research.}
}

@inproceedings{Aghajani2019,
  doi = {10.1109/icse.2019.00122},
  url = {https://doi.org/10.1109/icse.2019.00122},
  year = {2019},
  month = may,
  publisher = {{IEEE}},
  author = {Emad Aghajani and Csaba Nagy and Olga Lucero Vega-Marquez and Mario Linares-Vasquez and Laura Moreno and Gabriele Bavota and Michele Lanza},
  title = {Software Documentation Issues Unveiled},
  booktitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering ({ICSE})},
  abstract = {(Good) Software documentation provides developers and users with a description of what a software system does, how it operates, and how it should be used. For example, technical documentation (e.g., an API reference guide) aids developers during evolution/maintenance activities, while a user manual explains how users are to interact with a system. Despite its intrinsic value, the creation and the maintenance of documentation is often neglected, negatively impacting its quality and usefulness, ultimately leading to a generally unfavourable take on documentation. Previous studies investigating documentation issues have been based on surveying developers, which naturally leads to a somewhat biased view of problems affecting documentation. We present a large scale empirical study, where we mined, analyzed, and categorized 878 documentation-related artifacts stemming from four different sources, namely mailing lists, Stack Overflow discussions, issue repositories, and pull requests. The result is a detailed taxonomy of documentation issues from which we infer a series of actionable proposals both for researchers and practitioners.}
}

@article{Ajami2018,
  doi = {10.1007/s10664-018-9628-3},
  url = {https://doi.org/10.1007/s10664-018-9628-3},
  year = {2018},
  month = jun,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {24},
  number = {1},
  pages = {287--328},
  author = {Shulamyt Ajami and Yonatan Woodbridge and Dror G. Feitelson},
  title = {Syntax, predicates, idioms{\textemdash}what really affects code complexity?},
  journal = {Empirical Software Engineering},
  abstract = {Program comprehension concerns the ability to understand code written by others. But not all code is the same. We use an experimental platform fashioned as an online game-like environment to measure how quickly and accurately 220 professional programmers can interpret code snippets with similar functionality but different structures; snippets that take longer to understand or produce more errors are considered harder. The results indicate, inter alia, that for loops are significantly harder than if s, that some but not all negations make a predicate harder, and that loops counting down are slightly harder than loops counting up. This demonstrates how the effect of syntactic structures, different ways to express predicates, and the use of known idioms can be measured empirically, and that syntactic structures are not necessarily the most important factor. We also found that the metrics of time to understanding and errors made are not necessarily equivalent. Thus loops counting down took slightly longer, but loops with unusual bounds caused many more errors. By amassing many more empirical results like these it may be possible to derive better code complexity metrics than we have today, and also to better appreciate their limitations.}
}

@inproceedings{Almeida2017,
  doi = {10.1109/icpc.2017.7},
  url = {https://doi.org/10.1109/icpc.2017.7},
  year = {2017},
  month = may,
  publisher = {{IEEE}},
  author = {Daniel A. Almeida and Gail C. Murphy and Greg Wilson and Mike Hoye},
  title = {Do Software Developers Understand Open Source Licenses?},
  booktitle = {2017 {IEEE}/{ACM} 25th International Conference on Program Comprehension ({ICPC})},
  abstract = {Software provided under open source licenses is widely used, from forming high-profile stand-alone applications (e.g., Mozilla Firefox) to being embedded in commercial offerings (e.g., network routers). Despite the high frequency of use of open source licenses, there has been little work about whether software developers understand the open source licenses they use. To our knowledge, only one survey has been conducted, which focused on which licenses developers choose and when they encounter problems with licensing open source software. To help fill the gap of whether or not developers understand the open source licenses they use, we conducted a survey that posed development scenarios involving three popular open source licenses (GNU GPL 3.0, GNU LGPL 3.0 and MPL 2.0) both alone and in combination. The 375 respondents to the survey, who were largely developers, gave answers consistent with those of a legal expert's opinion in 62\% of 42 cases. Although developers clearly understood cases involving one license, they struggled when multiple licenses were involved. An analysis of the quantitative and qualitative results of the study indicate a need for tool support to help guide developers in understanding this critical information attached to software components.}
}

@article{AlSubaihin2021,
  doi = {10.1109/tse.2019.2891715},
  url = {https://doi.org/10.1109/tse.2019.2891715},
  year = {2021},
  month = feb,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {2},
  pages = {300--319},
  author = {Afnan A. Al-Subaihin and Federica Sarro and Sue Black and Licia Capra and Mark Harman},
  title = {App Store Effects on Software Engineering Practices},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {In this paper, we study the app store as a phenomenon from the developers' perspective to investigate the extent to which app stores affect software engineering tasks. Through developer interviews and questionnaires, we uncover findings that highlight and quantify the effects of three high-level app store themes: bridging the gap between developers and users, increasing market transparency and affecting mobile release management. Our findings have implications for testing, requirements engineering and mining software repositories research fields. These findings can help guide future research in supporting mobile app developers through a deeper understanding of the app store-developer interaction.}
}

@article{Ames2018,
  doi = {10.1145/3274287},
  url = {https://doi.org/10.1145/3274287},
  year = {2018},
  month = nov,
  publisher = {Association for Computing Machinery ({ACM})},
  volume = {2},
  number = {{CSCW}},
  pages = {1--19},
  author = {Morgan G. Ames},
  title = {Hackers, Computers, and Cooperation: A Critical History of Logo and Constructionist Learning},
  journal = {Proceedings of the {ACM} on Human-Computer Interaction},
  abstract = {This paper examines the history of the learning theory \"constructionism\" and its most well-known implementation, Logo, to examine beliefs involving both \"C's\" in CSCW: computers and cooperation. Tracing the tumultuous history of one of the first examples of computer-supported cooperative learning (CSCL) allows us to question some present-day assumptions regarding the universal appeal of learning to program computers that undergirds popular CSCL initiatives today, including the Scratch programming environment and the \"FabLab\" makerspace movement. Furthermore, teasing out the individualistic and anti-authority threads in this project and its links to present day narratives of technology development exposes the deeply atomized and even oppositional notions of collaboration in these projects and others under the auspices of CSCW today that draw on early notions of 'hacker culture.' These notions tend to favor a limited view of work, learning, and practice-an invisible constraint that continues to inform how we build and evaluate CSCW technologies.}
}

@comment{BBB}

@inproceedings{Bafatakis2019,
  doi = {10.1109/msr.2019.00042},
  url = {https://doi.org/10.1109/msr.2019.00042},
  year = {2019},
  month = may,
  publisher = {{IEEE}},
  author = {Nikolaos Bafatakis and Niels Boecker and Wenjie Boon and Martin Cabello Salazar and Jens Krinke and Gazi Oznacar and Robert White},
  title = {Python Coding Style Compliance on Stack Overflow},
  booktitle = {2019 {IEEE}/{ACM} 16th International Conference on Mining Software Repositories ({MSR})},
  abstract = {Software developers all over the world use Stack Overflow (SO) to interact and exchange code snippets. Research also uses SO to harvest code snippets for use with recommendation systems. However, previous work has shown that code on SO may have quality issues, such as security or license problems. We analyse Python code on SO to determine its coding style compliance. From 1,962,535 code snippets tagged with 'python', we extracted 407,097 snippets of at least 6 statements of Python code. Surprisingly, 93.87\% of the extracted snippets contain style violations, with an average of 0.7 violations per statement and a huge number of snippets with a considerably higher ratio. Researchers and developers should, therefore, be aware that code snippets on SO may not representative of good coding style. Furthermore, while user reputation seems to be unrelated to coding style compliance, for posts with vote scores in the range between -10 and 20, we found a strong correlation ($r = -0.87$, $p < 10^-7$) between the vote score a post received and the average number of violations per statement for snippets in such posts.}
}

@article{Balali2018,
  doi = {10.1007/s10606-018-9310-8},
  url = {https://doi.org/10.1007/s10606-018-9310-8},
  year = {2018},
  month = apr,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {27},
  number = {3-6},
  pages = {679--714},
  author = {Sogol Balali and Igor Steinmacher and Umayal Annamalai and Anita Sarma and Marco Aurelio Gerosa},
  title = {Newcomers' Barriers{\ldots} Is That All? An Analysis of Mentors' and Newcomers' Barriers in {OSS} Projects},
  journal = {Computer Supported Cooperative Work ({CSCW})},
  abstract = {Newcomers' seamless onboarding is important for open collaboration communities, particularly those that leverage outsiders' contributions to remain sustainable. Nevertheless, previous work shows that OSS newcomers often face several barriers to contribute, which lead them to lose motivation and even give up on contributing. A well-known way to help newcomers overcome initial contribution barriers is mentoring. This strategy has proven effective in offline and online communities, and to some extent has been employed in OSS projects. Studying mentors' perspectives on the barriers that newcomers face play a vital role in improving onboarding processes; yet, OSS mentors face their own barriers, which hinder the effectiveness of the strategy. Since little is known about the barriers mentors face, in this paper, we investigate the barriers that affect mentors and their newcomer mentees. We interviewed mentors from OSS projects and qualitatively analyzed their answers. We found 44 barriers: 19 that affect mentors; and 34 that affect newcomers (9 affect both newcomers and mentors). Interestingly, most of the barriers we identified (66\%) have a social nature. Additionally, we identified 10 strategies that mentors indicated to potentially alleviate some of the barriers. Since gender-related challenges emerged in our analysis, we conducted nine follow-up structured interviews to further explore this perspective. The contributions of this paper include: identifying the barriers mentors face; bringing the unique perspective of mentors on barriers faced by newcomers; unveiling strategies that can be used by mentors to support newcomers; and investigating gender-specific challenges in OSS mentorship. Mentors, newcomers, online communities, and educators can leverage this knowledge to foster new contributors to OSS projects.}
}

@article{Baltes2020,
  doi = {10.1109/ms.2020.3014178},
  url = {https://doi.org/10.1109/ms.2020.3014178},
  year = {2020},
  month = nov,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {37},
  number = {6},
  pages = {26--31},
  author = {Sebastian Baltes and George Park and Alexander Serebrenik},
  title = {Is 40 the New 60? How Popular Media Portrays the Employability of Older Software Developers},
  journal = {{IEEE} Software},
  abstract = {We studied the public discourse around age and software development, focusing on the United States. This work was designed to build awareness among decision makers in software projects to help them anticipate and mitigate challenges that their older employees may face.}
}

@article{Bao2021,
  doi = {10.1109/tse.2019.2918536},
  url = {https://doi.org/10.1109/tse.2019.2918536},
  year = {2021},
  month = jun,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {6},
  pages = {1277--1298},
  author = {Lingfeng Bao and Xin Xia and David Lo and Gail C. Murphy},
  title = {A Large Scale Study of Long-Time Contributor Prediction for {GitHub} Projects},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {The continuous contributions made by long time contributors (LTCs) are a key factor enabling open source software (OSS) projects to be successful and survival. We study Github as it has a large number of OSS projects and millions of contributors, which enables the study of the transition from newcomers to LTCs. In this paper, we investigate whether we can effectively predict newcomers in OSS projects to be LTCs based on their activity data that is collected from Github. We collect Github data from GHTorrent, a mirror of Github data. We select the most popular 917 projects, which contain 75,046 contributors. We determine a developer as a LTC of a project if the time interval between his/her first and last commit in the project is larger than a certain time $T$. In our experiment, we use three different settings on the time interval: 1, 2, and 3 years. There are 9,238, 3,968, and 1,577 contributors who become LTCs of a project in three settings of time interval, respectively. To build a prediction model, we extract many features from the activities of developers on Github, which group into five dimensions: developer profile, repository profile, developer monthly activity, repository monthly activity, and collaboration network. We apply several classifiers including naive Bayes, SVM, decision tree, kNN and random forest. We find that random forest classifier achieves the best performance with AUCs of more than 0.75 in all three settings of time interval for LTCs. We also investigate the most important features that differentiate newcomers who become LTCs from newcomers who stay in the projects for a short time. We find that the number of followers is the most important feature in all three settings of the time interval studied. We also find that the programming language and the average number of commits contributed by other developers when a newcomer joins a project also belong to the top 10 most important features in all three settings of time interval for LTCs. Finally, we provide several implications for action based on our analysis results to help OSS projects retain newcomers.}
}

@inproceedings{Barbosa2014,
  doi = {10.1109/sbes.2014.19},
  url = {https://doi.org/10.1109/sbes.2014.19},
  year = {2014},
  month = sep,
  publisher = {{IEEE}},
  author = {Eiji Adachi Barbosa and Alessandro Garcia and Simone Diniz Junqueira Barbosa},
  title = {Categorizing Faults in Exception Handling: A Study of Open Source Projects},
  booktitle = {2014 Brazilian Symposium on Software Engineering},
  abstract = {Even though exception handling mechanisms have been proposed as a means to improve software robustness, empirical evidence suggests that exception handling code is still poorly implemented in industrial systems. Moreover, it is often claimed that the poor quality of exception handling code can be a source of faults in a software system. However, there is still a gap in the literature in terms of better understanding exceptional faults, i.e., faults whose causes regard to exception handling. In particular, there is still little empirical knowledge about what are the specific causes of exceptional faults in software systems. In this paper we start to fill this gap by presenting a categorization of the causes of exceptional faults observed in two mainstream open source projects. We observed ten different categories of exceptional faults, most of which were never reported before in the literature. Our results pinpoint that current verification and validation mechanisms for exception handling code are still not properly addressing these categories of exceptional faults.}
}

@inproceedings{Barik2017,
  doi = {10.1109/icse.2017.59},
  url = {https://doi.org/10.1109/icse.2017.59},
  year = {2017},
  month = may,
  publisher = {{IEEE}},
  author = {Titus Barik and Justin Smith and Kevin Lubick and Elisabeth Holmes and Jing Feng and Emerson Murphy-Hill and Chris Parnin},
  title = {Do Developers Read Compiler Error Messages?},
  booktitle = {2017 {IEEE}/{ACM} 39th International Conference on Software Engineering ({ICSE})},
  abstract = {In integrated development environments, developers receive compiler error messages through a variety of textual and visual mechanisms, such as popups and wavy red underlines. Although error messages are the primary means of communicating defects to developers, researchers have a limited understanding on how developers actually use these messages to resolve defects. To understand how developers use error messages, we conducted an eye tracking study with 56 participants from undergraduate and graduate software engineering courses at our university. The participants attempted to resolve common, yet problematic defects in a Java code base within the Eclipse development environment. We found that: 1) participants read error messages and the difficulty of reading these messages is comparable to the difficulty of reading source code, 2) difficulty reading error messages significantly predicts participants' task performance, and 3) participants allocate a substantial portion of their total task to reading error messages (13\%-25\%). The results of our study offer empirical justification for the need to improve compiler error messages for developers.}
}

@article{Barke2019,
  doi = {10.7717/peerj-cs.241},
  url = {https://doi.org/10.7717/peerj-cs.241},
  year = {2019},
  month = dec,
  publisher = {{PeerJ}},
  volume = {5},
  pages = {e241},
  author = {Helena Barke and Lutz Prechelt},
  title = {Role clarity deficiencies can wreck agile teams},
  journal = {{PeerJ} Computer Science},
  abstract = {Background One of the twelve agile principles is to build projects around motivated individuals and trust them to get the job done. Such agile teams must self-organize, but this involves conflict, making self-organization difficult. One area of difficulty is agreeing on everybody's role. Background What dynamics arise in a self-organizing team from the negotiation of everybody's role? Method We conceptualize observations from five agile teams (work observations, interviews) by Charmazian Grounded Theory Methodology. Results We define role as something transient and implicit, not fixed and named. The roles are characterized by the responsibilities and expectations of each team member. Every team member must understand and accept their own roles (Local role clarity) and everbody else's roles (Team-wide role clarity). Role clarity allows a team to work smoothly and effectively and to develop its members' skills fast. Lack of role clarity creates friction that not only hampers the day-to-day work, but also appears to lead to high employee turnover. Agile coaches are critical to create and maintain role clarity. Conclusions Agile teams should pay close attention to the levels of Local role clarity of each member and Team-wide role clarity overall, because role clarity deficits are highly detrimental.}
}

@inproceedings{Becker2019,
  doi = {10.1145/3344429.3372508},
  url = {https://doi.org/10.1145/3344429.3372508},
  year = {2019},
  month = dec,
  publisher = {{ACM}},
  author = {Brett A. Becker and Paul Denny and Raymond Pettit and Durell Bouchard and Dennis J. Bouvier and Brian Harrington and Amir Kamil and Amey Karkare and Chris McDonald and Peter-Michael Osera and Janice L. Pearce and James Prather},
  title = {Compiler Error Messages Considered Unhelpful},
  booktitle = {Proceedings of the Working Group Reports on Innovation and Technology in Computer Science Education},
  abstract = {Diagnostic messages generated by compilers and interpreters such as syntax error messages have been researched for over half of a century. Unfortunately, these messages which include error, warning, and run-time messages, present substantial difficulty and could be more effective, particularly for novices. Recent years have seen an increased number of papers in the area including studies on the effectiveness of these messages, improving or enhancing them, and their usefulness as a part of programming process data that can be used to predict student performance, track student progress, and tailor learning plans. Despite this increased interest, the long history of literature is quite scattered and has not been brought together in any digestible form. In order to help the computing education community (and related communities) to further advance work on programming error messages, we present a comprehensive, historical and state-of-the-art report on research in the area. In addition, we synthesise and present the existing evidence for these messages including the difficulties they present and their effectiveness. We finally present a set of guidelines, curated from the literature, classified on the type of evidence supporting each one (historical, anecdotal, and empirical). This work can serve as a starting point for those who wish to conduct research on compiler error messages, runtime errors, and warnings. We also make the bibtex file of our 300+ reference corpus publicly available. Collectively this report and the bibliography will be useful to those who wish to design better messages or those that aim to measure their effectiveness, more effectively.}
}

@inproceedings{Behroozi2019,
  doi = {10.1109/vlhcc.2019.8818836},
  url = {https://doi.org/10.1109/vlhcc.2019.8818836},
  year = {2019},
  month = oct,
  publisher = {{IEEE}},
  author = {Mahnaz Behroozi and Chris Parnin and Titus Barik},
  title = {Hiring is Broken: What Do Developers Say About Technical Interviews?},
  booktitle = {2019 {IEEE} Symposium on Visual Languages and Human-Centric Computing ({VL}/{HCC})},
  abstract = {Technical interviews---a problem-solving form of interview in which candidates write code---are commonplace in the software industry, and are used by several well-known companies including Facebook, Google, and Microsoft. These interviews are intended to objectively assess candidates and determine fit within the company. But what do developers say about them?To understand developer perceptions about technical interviews, we conducted a qualitative study using the online social news website, Hacker News---a venue for software practitioners. Hacker News posters report several concerns and negative perceptions about interviews, including their lack of real-world relevance, bias towards younger developers, and demanding time commitment. Posters report that these interviews cause unnecessary anxiety and frustration, requiring them to learn arbitrary, implicit, and obscure norms. The findings from our study inform inclusive hiring guidelines for technical interviews, such as collaborative problem-solving sessions.}
}

@inproceedings{Behroozi2020,
  doi = {10.1145/3377815.3381372},
  url = {https://doi.org/10.1145/3377815.3381372},
  year = {2020},
  publisher = {{ACM}},
  author = {Mahnaz Behroozi and Shivani Shirolkar and Titus Barik and Chris Parnin},
  title = {Debugging Hiring: What Went Right and What Went Wrong in the Technical Interview Process},
  booktitle = {International Conference on Software Engineering ({ICSE} 2020)},
  abstract = {The typical hiring pipeline for software engineering occurs over several stages---from phone screening and technical on-site interviews, to offer and negotiation. When these hiring pipelines are "leaky," otherwise qualified candidates are lost at some stage of the pipeline. These leaky pipelines impact companies in several ways, including hindering a company's ability to recruit competitive candidates and build diverse software teams.To understand where candidates become disengaged in the hiring pipeline---and what companies can do to prevent it---we conducted a qualitative study on over 10,000 reviews on 19 companies from Glassdoor, a website where candidates can leave reviews about their hiring process experiences. We identified several poor practices which prematurely sabotage the hiring process---for example, not adequately communicating hiring criteria, conducting interviews with inexperienced interviewers, and ghosting candidates. Our findings provide a set of guidelines to help companies improve their hiring pipeline practices---such as being deliberate about phrasing and language during initial contact with the candidate, providing candidates with constructive feedback after their interviews, and bringing salary transparency and long-term career discussions into offers and negotiations. Operationalizing these guidelines helps make the hiring pipeline more transparent, fair, and inclusive.}
}

@article{Beller2019,
  doi = {10.1109/tse.2017.2776152},
  url = {https://doi.org/10.1109/tse.2017.2776152},
  year = {2019},
  month = mar,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {45},
  number = {3},
  pages = {261--284},
  author = {Moritz Beller and Georgios Gousios and Annibale Panichella and Sebastian Proksch and Sven Amann and Andy Zaidman},
  title = {Developer Testing in the {IDE}: Patterns, Beliefs, and Behavior},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Software testing is one of the key activities to achieve software quality in practice. Despite its importance, however, we have a remarkable lack of knowledge on how developers test in real-world projects. In this paper, we report on a large-scale field study with 2,443 software engineers whose development activities we closely monitored over 2.5 years in four integrated development environments (IDEs). Our findings, which largely generalized across the studied IDEs and programming languages Java and C\#, question several commonly shared assumptions and beliefs about developer testing: half of the developers in our study do not test; developers rarely run their tests in the IDE; most programming sessions end without any test execution; only once they start testing, do they do it extensively; a quarter of test cases is responsible for three quarters of all test failures; 12 percent of tests show flaky behavior; Test-Driven Development (TDD) is not widely practiced; and software developers only spend a quarter of their time engineering tests, whereas they think they test half of their time. We summarize these practices of loosely guiding one's development efforts with the help of testing in an initial summary on Test-Guided Development (TGD), a behavior we argue to be closer to the development reality of most developers than TDD.}
}

@article{Bi2021,
  doi = {10.1016/j.jss.2021.111035},
  url = {https://doi.org/10.1016/j.jss.2021.111035},
  year = {2021},
  month = nov,
  publisher = {Elsevier {BV}},
  volume = {181},
  pages = {111035},
  author = {Tingting Bi and Wei Ding and Peng Liang and Antony Tang},
  title = {Architecture information communication in two {OSS} projects: The why,  who,  when,  and what},
  journal = {Journal of Systems and Software},
  abstract = {Architecture information is vital for Open Source Software (OSS) development, and mailing list is one of the widely used channels for developers to share and communicate architecture information. This work investigates the nature of architecture information communication (i.e., why, who, when, and what) by OSS developers via developer mailing lists. We employed a multiple case study approach to extract and analyze the architecture information communication from the developer mailing lists of two OSS projects, ArgoUML and Hibernate, during their development life-cycle of over 18 years. Our main findings are: (a) architecture negotiation and interpretation are the two main reasons (i.e., why) of architecture communication; (b) the amount of architecture information communicated in developer mailing lists decreases after the first stable release (i.e., when); (c) architecture communications centered around a few core developers (i.e., who); (d) and the most frequently communicated architecture elements (i.e., what) are Architecture Rationale and Architecture Model. There are a few similarities of architecture communication between the two OSS projects. Such similarities point to how OSS developers naturally gravitate towards the four aspects of architecture communication in OSS development.}
}

@article{Blackwell2019,
  doi = {10.1016/j.ijhcs.2019.06.009},
  url = {https://doi.org/10.1016/j.ijhcs.2019.06.009},
  year = {2019},
  month = nov,
  publisher = {Elsevier {BV}},
  volume = {131},
  pages = {52--63},
  author = {Alan F. Blackwell and Marian Petre and Luke Church},
  title = {Fifty years of the psychology of programming},
  journal = {International Journal of Human-Computer Studies},
  abstract = {Abstract This paper reflects on the evolution (past, present and future) of the 'psychology of programming' over the 50 year period of this anniversary issue. The International Journal of Human-Computer Studies (IJHCS) has been a key venue for much seminal work in this field, including its first foundations, and we review the changing research concerns seen in publications over these five decades. We relate this thematic evolution to research taking place over the same period within more specialist communities, especially the Psychology of Programming Interest Group (PPIG), the Empirical Studies of Programming series (ESP), and the ongoing community in Visual Languages and Human-Centric Computing (VL/HCC). Many other communities have interacted with psychology of programming, both influenced by research published within the specialist groups, and in turn influencing research priorities. We end with an overview of the core theories that have been developed over this period, as an introductory resource for new researchers, and also with the authors' own analysis of key priorities for future research.}
}

@article{Borle2017,
  doi = {10.1007/s10664-017-9576-3},
  url = {https://doi.org/10.1007/s10664-017-9576-3},
  year = {2017},
  month = nov,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {23},
  number = {4},
  pages = {1931--1958},
  author = {Neil C. Borle and Meysam Feghhi and Eleni Stroulia and Russell Greiner and Abram Hindle},
  title = {Analyzing the effects of test driven development in {GitHub}},
  journal = {Empirical Software Engineering},
  abstract = {Testing is an integral part of the software development lifecycle, approached with varying degrees of rigor by different process models. Agile process models recommend Test Driven Development (TDD) as a key practice for reducing costs and improving code quality. The objective of this work is to perform a cost-benefit analysis of this practice. To that end, we have conducted a comparative analysis of GitHub repositories that adopts TDD to a lesser or greater extent, in order to determine how TDD affects software development productivity and software quality. We classified GitHub repositories archived in 2015 in terms of how rigorously they practiced TDD, thus creating a TDD spectrum. We then matched and compared various subsets of these repositories on this TDD spectrum with control sets of equal size. The control sets were samples from all GitHub repositories that matched certain characteristics, and that contained at least one test file. We compared how the TDD sets differed from the control sets on the following characteristics: number of test files, average commit velocity, number of bug-referencing commits, number of issues recorded, usage of continuous integration, number of pull requests, and distribution of commits per author. We found that Java TDD projects were relatively rare. In addition, there were very few significant differences in any of the metrics we used to compare TDD-like and non-TDD projects; therefore, our results do not reveal any observable benefits from using TDD.}
}

@inproceedings{Brown2018,
  doi = {10.1145/3230977.3230991},
  url = {https://doi.org/10.1145/3230977.3230991},
  year = {2018},
  month = aug,
  publisher = {{ACM}},
  author = {Neil C. C. Brown and Amjad Altadmri and Sue Sentance and Michael K\"{o}lling},
  title = {Blackbox, Five Years On: An Evaluation of a Large-scale Programming Data Collection Project},
  booktitle = {Proceedings of the 2018 {ACM} Conference on International Computing Education Research},
  abstract = {The Blackbox project has been collecting programming activity data from users of BlueJ (a novice-targeted Java development environment) for nearly five years. The resulting dataset of more than two terabytes of data has been made available to interested researchers from the outset. In this paper, we assess the impact of the Blackbox project: we perform a mapping study to assess eighteen publications which have made use of the Blackbox data, and we report on the advantages and difficulties experienced by researchers working with this data, collected via a survey. We find that Blackbox has enabled pieces of research which otherwise would not have been possible, but there remain technical challenges in the analysis. Some of these -- but not all -- relate to the scale of the data. We provide suggestions for the future use of Blackbox, and reflections on the role of such data collection projects in programming research.}
}

@inproceedings{Brown2020,
  doi = {10.1145/3368089.3409722},
  url = {https://doi.org/10.1145/3368089.3409722},
  year = {2020},
  month = nov,
  publisher = {{ACM}},
  author = {Chris Brown and Chris Parnin},
  title = {Understanding the impact of {GitHub} suggested changes on recommendations between developers},
  booktitle = {Proceedings of the 28th {ACM} Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  abstract = {Recommendations between colleagues are effective for encouraging developers to adopt better practices. Research shows these peer interactions are useful for improving developer behaviors, or the adoption of activities to help software engineers complete programming tasks. However, in-person recommendations between developers in the workplace are declining. One form of online recommendations between developers are pull requests, which allow users to propose code changes and provide feedback on contributions. GitHub, a popular code hosting platform, recently introduced the suggested changes feature, which allows users to recommend improvements for pull requests. To better understand this feature and its impact on recommendations between developers, we report an empirical study of this system, measuring usage, effectiveness, and perception. Our results show that suggested changes support code review activities and significantly impact the timing and communication between developers on pull requests. This work provides insight into the suggested changes feature and implications for improving future systems for automated developer recommendations, such as providing situated, concise, and actionable feedback.}
}

@article{Butler2019,
  doi = {10.1109/tse.2019.2919305},
  url = {https://doi.org/10.1109/tse.2019.2919305},
  year = {2019},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  pages = {1--1},
  author = {Simon Butler and Jonas Gamalielsson and Bjorn Lundell and Christoffer Brax and Johan Sjoberg and Anders Mattsson and Tomas Gustavsson and Jonas Feist and Erik Lonroth},
  title = {On Company Contributions to Community Open Source Software Projects},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {The majority of contributions to community open source software (OSS) projects are made by practitioners acting on behalf of companies and other organisations. Previous research has addressed the motivations of both individuals and companies to engage with OSS projects. However, limited research has been undertaken that examines and explains the practical mechanisms or work practices used by companies and their developers to pursue their commercial and technical objectives when engaging with OSS projects. This research investigates the variety of work practices used in public communication channels by company contributors to engage with and contribute to eight community OSS projects. Through interviews with contributors to the eight projects we draw on their experiences and insights to explore the motivations to use particular methods of contribution. We find that companies utilise work practices for contributing to community projects which are congruent with the circumstances and their capabilities that support their short- and long-term needs. We also find that companies contribute to community OSS projects in ways that may not always be apparent from public sources, such as employing core project developers, making donations, and joining project steering committees in order to advance strategic interests. The factors influencing contributor work practices can be complex and are often dynamic arising from considerations such as company and project structure, as well as technical concerns and commercial strategies. The business context in which software created by the OSS project is deployed is also found to influence contributor work practices.}
}

@comment{CCC}

@inproceedings{Cabral2007,
  doi = {10.1007/978-3-540-73589-2_8},
  url = {https://doi.org/10.1007/978-3-540-73589-2_8},
  publisher = {Springer Berlin Heidelberg},
  pages = {151--175},
  author = {Bruno Cabral and Paulo Marques},
  title = {Exception Handling: A Field Study in Java and .{NET}},
  booktitle = {European Conference on Object-Oriented Programming ({ECOOP} 2007)},
  year = {2007},
  abstract = {Most modern programming languages rely on exceptions for dealing with abnormal situations. Although exception handling was a significant improvement over other mechanisms like checking return codes, it is far from perfect. In fact, it can be argued that this mechanism is seriously limited, if not, flawed. This paper aims to contribute to the discussion by providing quantitative measures on how programmers are currently using exception handling. We examined 32 different applications, both for Java and .NET. The major conclusion for this work is that exceptions are not being correctly used as an error recovery mechanism. Exception handlers are not specialized enough for allowing recovery and, typically, programmers just do one of the following actions: logging, user notification and application termination. To our knowledge, this is the most comprehensive study done on exception handling to date, providing a quantitative measure useful for guiding the development of new error handling mechanisms.}
}

@inproceedings{Campos2017,
  doi = {10.1109/esem.2017.55},
  url = {https://doi.org/10.1109/esem.2017.55},
  year = {2017},
  month = nov,
  publisher = {{IEEE}},
  author = {Eduardo Cunha Campos and Marcelo de Almeida Maia},
  title = {Common Bug-Fix Patterns: A Large-Scale Observational Study},
  booktitle = {2017 {ACM}/{IEEE} International Symposium on Empirical Software Engineering and Measurement ({ESEM})},
  abstract = {[Background]: There are more bugs in real-world programs than human programmers can realistically address. Several approaches have been proposed to aid debugging. A recent research direction that has been increasingly gaining interest to address the reduction of costs associated with defect repair is automatic program repair. Recent work has shown that some kind of bugs are more suitable for automatic repair techniques. [Aim]: The detection and characterization of common bug-fix patterns in software repositories play an important role in advancing the field of automatic program repair. In this paper, we aim to characterize the occurrence of known bug-fix patterns in Java repositories at an unprecedented large scale. [Method]: The study was conducted for Java GitHub projects organized in two distinct data sets: the first one (i.e., Boa data set) contains more than 4 million bug-fix commits from 101,471 projects and the second one (i.e., Defects4J data set) contains 369 real bug fixes from five open-source projects. We used a domain-specific programming language called Boa in the first data set and conducted a manual analysis on the second data set in order to confront the results. [Results]: We characterized the prevalence of the five most common bug-fix patterns (identified in the work of Pan et al.) in those bug fixes. The combined results showed direct evidence that developers often forget to add IF preconditions in the code. Moreover, 76\% of bug-fix commits associated with the IF-APC bug-fix pattern are isolated from the other four bug-fix patterns analyzed. [Conclusion]: Targeting on bugs that miss preconditions is a feasible alternative in automatic repair techniques that would produce a relevant payback.}
}

@inproceedings{Catolino2019,
  doi = {10.1109/icse-seis.2019.00010},
  url = {https://doi.org/10.1109/icse-seis.2019.00010},
  year = {2019},
  month = may,
  publisher = {{IEEE}},
  author = {Gemma Catolino and Fabio Palomba and Damian A. Tamburri and Alexander Serebrenik and Filomena Ferrucci},
  title = {Gender Diversity and Women in Software Teams: How Do They Affect Community Smells?},
  booktitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering: Software Engineering in Society ({ICSE}-{SEIS})},
  abstract = {As social as software engineers are, there is a known and established gender imbalance in our community structures, regardless of their open-or closed-source nature. To shed light on the actual benefits of achieving such balance, this empirical study looks into the relations between such balance and the occurrence of community smells, that is, sub-optimal circumstances and patterns across the software organizational structure. Examples of community smells are Organizational Silo effects (overly disconnected sub-groups) or Lone Wolves (defiant community members). Results indicate that the presence of women generally reduces the amount of community smells. We conclude that women are instrumental to reducing community smells in software development teams.}
}

@inproceedings{Chattopadhyay2020,
  doi = {10.1145/3377811.3380330},
  url = {https://doi.org/10.1145/3377811.3380330},
  year = {2020},
  month = jun,
  publisher = {{ACM}},
  author = {Souti Chattopadhyay and Nicholas Nelson and Audrey Au and Natalia Morales and Christopher Sanchez and Rahul Pandita and Anita Sarma},
  title = {A tale from the trenches: cognitive biases and software development},
  booktitle = {Proceedings of the {ACM}/{IEEE} 42nd International Conference on Software Engineering},
  abstract = {Cognitive biases are hard-wired behaviors that influence developer actions and can set them on an incorrect course of action, necessitating backtracking. While researchers have found that cognitive biases occur in development tasks in controlled lab studies, we still don't know how these biases affect developers' everyday behavior. Without such an understanding, development tools and practices remain inadequate. To close this gap, we conducted a 2-part field study to examine the extent to which cognitive biases occur, the consequences of these biases on developer behavior, and the practices and tools that developers use to deal with these biases. About 70\% of observed actions that were reversed were associated with at least one cognitive bias. Further, even though developers recognized that biases frequently occur, they routinely are forced to deal with such issues with ad hoc processes and sub-optimal tool support. As one participant (IP12) lamented: There is no salvation!}
}

@article{Coelho2016,
  doi = {10.1007/s10664-016-9443-7},
  url = {https://doi.org/10.1007/s10664-016-9443-7},
  year = {2016},
  month = aug,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {22},
  number = {3},
  pages = {1264--1304},
  author = {Roberta Coelho and Lucas Almeida and Georgios Gousios and Arie van Deursen and Christoph Treude},
  title = {Exception handling bug hazards in Android},
  journal = {Empirical Software Engineering},
  abstract = {Adequate handling of exceptions has proven difficult for many software engineers. Mobile app developers in particular, have to cope with compatibility, middleware, memory constraints, and battery restrictions. The goal of this paper is to obtain a thorough understanding of common exception handling bug hazards that app developers face. To that end, we first provide a detailed empirical study of over 6,000 Java exception stack traces we extracted from over 600 open source Android projects. Key insights from this study include common causes for system crashes, and common chains of wrappings between checked and unchecked exceptions. Furthermore, we provide a survey with 71 developers involved in at least one of the projects analyzed. The results corroborate the stack trace findings, and indicate that developers are unaware of frequently occurring undocumented exception handling behavior. Overall, the findings of our study call for tool support to help developers understand their own and third party exception handling and wrapping logic.}
}

@article{Cogo2021,
  doi = {10.1007/s10664-021-09980-6},
  url = {https://doi.org/10.1007/s10664-021-09980-6},
  year = {2021},
  month = jul,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {5},
  author = {Filipe R. Cogo and Gustavo A. Oliva and Cor-Paul Bezemer and Ahmed E. Hassan},
  title = {An empirical study of same-day releases of popular packages in the npm ecosystem},
  journal = {Empirical Software Engineering},
  abstract = {Within a software ecosystem, client packages can reuse provider packages as third-party libraries. The reuse relation between client and provider packages is called a dependency. When a client package depends on the code of a provider package, every change that is introduced in a release of the provider has the potential to impact the client package. Since a large number of dependencies exist within a software ecosystem, releases of a popular provider package can impact a large number of clients. Occasionally, multiple releases of a popular package need to be published on the same day, leading to a scenario in which the time available to revise, test, build, and document the release is restricted compared to releases published within a regular schedule. In this paper, our objective is to study the same-day releases that are published by popular packages in the npm ecosystem. We design an exploratory study to characterize the type of changes that are introduced in same-day releases, the prevalence of same-day releases in the npm ecosystem, and the adoption of same-day releases by client packages. A preliminary manual analysis of the existing release notes suggests that same-day releases introduce non-trivial changes (e.g., bug fixes). We then focus on three RQs. First, we study how often same-day releases are published. We found that the median proportion of regularly scheduled releases that are interrupted by a same-day release (per popular package) is 22\%, suggesting the importance of having timely and systematic procedures to cope with same-day releases. Second, we study the performed code changes in same-day releases. We observe that 32\% of the same-day releases have larger changes compared with their prior release, thus showing that some same-day releases can undergo significant maintenance activity despite their time-constrained nature. In our third RQ, we study how client packages react to same-day releases of their providers. We observe the vast majority of client packages that adopt the release preceding the same-day release would also adopt the latter without having to change their versioning statement (implicit updates). We also note that explicit adoptions of same-day releases (i.e., adoptions that require a change to the versioning statement of the provider in question) is significantly faster than the explicit adoption of regular releases. Based on our findings, we argue that (i) third-party tools that support the automation of dependency management (e.g., Dependabot) should consider explicitly flagging same-day releases, (ii) popular packages should strive for optimized release pipelines that can properly handle same-day releases, and (iii) future research should design scalable, ecosystem-ready tools that support provider packages in assessing the impact of their code changes on client packages.}
}

@article{Costa2019,
  doi = {10.1109/tse.2019.2925345},
  url = {https://doi.org/10.1109/tse.2019.2925345},
  year = {2019},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  pages = {1--1},
  author = {Diego Elias Damasceno Costa and Cor-Paul Bezemer and Philip Leitner and Artur Andrzejak},
  title = {What{\textquotesingle}s Wrong With My Benchmark Results? Studying Bad Practices in {JMH} Benchmarks},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Microbenchmarking frameworks, such as Java's Microbenchmark Harness (JMH), allow developers to write fine-grained performance test suites at the method or statement level. However, due to the complexities of the Java Virtual Machine, developers often struggle with writing expressive JMH benchmarks which accurately represent the performance of such methods or statements. In this paper, we empirically study bad practices of JMH benchmarks. We present a tool that leverages static analysis to identify 5 bad JMH practices. Our empirical study of 123 open source Java-based systems shows that each of these 5 bad practices are prevalent in open source software. Further, we conduct several experiments to quantify the impact of each bad practice in multiple case studies, and find that bad practices often significantly impact the benchmark results. To validate our experimental results, we constructed seven patches that fix the identified bad practices for six of the studied open source projects, of which six were merged into the main branch of the project. In this paper, we show that developers struggle with accurate Java microbenchmarking, and provide several recommendations to developers of microbenchmarking frameworks on how to improve future versions of their framework.}
}

@comment{DDD}

@inproceedings{Davis2019,
  doi = {10.1145/3338906.3338909},
  url = {https://doi.org/10.1145/3338906.3338909},
  year = {2019},
  month = aug,
  publisher = {{ACM}},
  author = {James C. Davis and Louis G. Michael IV and Christy A. Coghlan and Francisco Servant and Dongyoon Lee},
  title = {Why aren't regular expressions a lingua franca? an empirical study on the re-use and portability of regular expressions},
  booktitle = {Proceedings of the 2019 27th {ACM} Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  abstract = {This paper explores the extent to which regular expressions (regexes) are portable across programming languages. Many languages offer similar regex syntaxes, and it would be natural to assume that regexes can be ported across language boundaries. But can regexes be copy/pasted across language boundaries while retaining their semantic and performance characteristics? In our survey of 158 professional software developers, most indicated that they re-use regexes across language boundaries and about half reported that they believe regexes are a universal language. We experimentally evaluated the riskiness of this practice using a novel regex corpus---537,806 regexes from 193,524 projects written in JavaScript, Java, PHP, Python, Ruby, Go, Perl, and Rust. Using our polyglot regex corpus, we explored the hitherto-unstudied regex portability problems: logic errors due to semantic differences, and security vulnerabilities due to performance differences. We report that developers belief in a regex lingua franca is understandable but unfounded. Though most regexes compile across language boundaries, 15\% exhibit semantic differences across languages and 10\% exhibit performance differences across languages. We explained these differences using regex documentation, and further illuminate our findings by investigating regex engine implementations. Along the way we found bugs in the regex engines of JavaScript-V8, Python, Ruby, and Rust, and potential semantic and performance regex bugs in thousands of modules.}
}

@article{Decan2021,
  doi = {10.1109/tse.2019.2918315},
  url = {https://doi.org/10.1109/tse.2019.2918315},
  year = {2021},
  month = jun,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {6},
  pages = {1226--1240},
  author = {Alexandre Decan and Tom Mens},
  title = {What Do Package Dependencies Tell Us About Semantic Versioning?},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {The semantic versioning (semver) policy is commonly accepted by open source package management systems to inform whether new releases of software packages introduce possibly backward incompatible changes. Maintainers depending on such packages can use this information to avoid or reduce the risk of breaking changes in their own packages by specifying version constraints on their dependencies. Depending on the amount of control a package maintainer desires to have over her package dependencies, these constraints can range from very permissive to very restrictive. This article empirically compares semver compliance of four software packaging ecosystems (Cargo, npm, Packagist and Rubygems), and studies how this compliance evolves over time. We explore to what extent ecosystem-specific characteristics or policies influence the degree of compliance. We also propose an evaluation based on the "wisdom of the crowds" principle to help package maintainers decide which type of version constraints they should impose on their dependencies.}
}

@article{DeOliveiraNeto2019,
  doi = {10.1016/j.jss.2019.07.002},
  url = {https://doi.org/10.1016/j.jss.2019.07.002},
  year = {2019},
  month = oct,
  publisher = {Elsevier {BV}},
  volume = {156},
  pages = {246--267},
  author = {Francisco Gomes {de Oliveira Neto} and Richard Torkar and Robert Feldt and Lucas Gren and Carlo A. Furia and Ziwei Huang},
  title = {Evolution of statistical analysis in empirical software engineering research: Current state and steps forward},
  journal = {Journal of Systems and Software},
  abstract = {Software engineering research is evolving and papers are increasingly based on empirical data from a multitude of sources, using statistical tests to determine if and to what degree empirical evidence supports their hypotheses. To investigate the practices and trends of statistical analysis in empirical software engineering (ESE), this paper presents a review of a large pool of papers from top-ranked software engineering journals. First, we manually reviewed 161 papers and in the second phase of our method, we conducted a more extensive semi-automatic classification of papers spanning the years 2001--2015 and 5,196 papers. Results from both review steps was used to: i) identify and analyze the predominant practices in ESE (e.g., using t-test or ANOVA), as well as relevant trends in usage of specific statistical methods (e.g., nonparametric tests and effect size measures) and, ii) develop a conceptual model for a statistical analysis workflow with suggestions on how to apply different statistical methods as well as guidelines to avoid pitfalls. Lastly, we confirm existing claims that current ESE practices lack a standard to report practical significance of results. We illustrate how practical significance can be discussed in terms of both the statistical analysis and in the practitioner's context.}
}

@inproceedings{DePadua2018,
  doi = {10.1145/3196398.3196435},
  url = {https://doi.org/10.1145/3196398.3196435},
  year = {2018},
  month = may,
  publisher = {{ACM}},
  author = {Guilherme B. de P{\'{a}}dua and Weiyi Shang},
  title = {Studying the relationship between exception handling practices and post-release defects},
  booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
  abstract = {Modern programming languages, such as Java and C\#, typically provide features that handle exceptions. These features separate error-handling code from regular source code and aim to assist in the practice of software comprehension and maintenance. Nevertheless, their misuse can still cause reliability degradation or even catastrophic software failures. Prior studies on exception handling revealed the suboptimal practices of the exception handling flows and the prevalence of their anti-patterns. However, little is known about the relationship between exception handling practices and software quality. In this work, we investigate the relationship between software quality (measured by the probability of having post-release defects) and: (i) exception flow characteristics and (ii) 17 exception handling anti-patterns. We perform a case study on three Java and C\# open-source projects. By building statistical models of the probability of post-release defects using traditional software metrics and metrics that are associated with exception handling practice, we study whether exception flow characteristics and exception handling anti-patterns have a statistically significant relationship with post-release defects. We find that exception flow characteristics in Java projects have a significant relationship with post-release defects. In addition, although the majority of the exception handing anti-patterns are not significant in the models, there exist anti-patterns that can provide significant explanatory power to the probability of post-release defects. Therefore, development teams should consider allocating more resources to improving their exception handling practices and avoid the anti-patterns that are found to have a relationship with post-release defects. Our findings also highlight the need for techniques that assist in handling exceptions in the software development practice.}
}

@inproceedings{Dias2021,
  doi = {10.1109/icse43902.2021.00093},
  url = {https://doi.org/10.1109/icse43902.2021.00093},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Edson Dias and Paulo Meirelles and Fernando Castor and Igor Steinmacher and Igor Wiese and Gustavo Pinto},
  title = {What Makes a Great Maintainer of Open Source Projects?},
  booktitle = {2021 {IEEE}/{ACM} 43rd International Conference on Software Engineering ({ICSE})},
  abstract = {Although Open Source Software (OSS) maintainers devote a significant proportion of their work to coding tasks, great maintainers must excel in many other activities beyond coding. Maintainers should care about fostering a community, helping new members to find their place, while also saying \"no\" to patches that although are well-coded and well-tested, do not contribute to the goal of the project. To perform all these activities masterfully, maintainers should exercise attributes that software engineers (working on closed source projects) do not always need to master. This paper aims to uncover, relate, and prioritize the unique attributes that great OSS maintainers might have. To achieve this goal, we conducted 33 semi-structured interviews with well-experienced maintainers that are the gatekeepers of notable projects such as the Linux Kernel, the Debian operating system, and the GitLab coding platform. After we analyzed the interviews and curated a list of attributes, we created a conceptual framework to explain how these attributes are connected. We then conducted a rating survey with 90 OSS contributors. We noted that \"technical excellence\" and \"communication\" are the most recurring attributes. When grouped, these attributes fit into four broad categories: management, social, technical, and personality. While we noted that \"sustain a long term vision of the project\" and being \"extremely careful\" seem to form the basis of our framework, we noted through our survey that the communication attribute was perceived as the most essential one.}
}

@inproceedings{Durieux2020,
  doi = {10.1145/3379597.3387460},
  url = {https://doi.org/10.1145/3379597.3387460},
  year = {2020},
  month = jun,
  publisher = {{ACM}},
  author = {Thomas Durieux and Claire Le Goues and Michael Hilton and Rui Abreu},
  title = {Empirical Study of Restarted and Flaky Builds on Travis {CI}},
  booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
  abstract = {Continuous Integration (CI) is a development practice where developers frequently integrate code into a common codebase. After the code is integrated, the CI server runs a test suite and other tools to produce a set of reports (e.g., the output of linters and tests). If the result of a CI test run is unexpected, developers have the option to manually restart the build, re-running the same test suite on the same code; this can reveal build flakiness, if the restarted build outcome differs from the original build. In this study, we analyze restarted builds, flaky builds, and their impact on the development workflow. We observe that developers restart at least 1.72\% of builds, amounting to 56,522 restarted builds in our Travis CI dataset. We observe that more mature and more complex projects are more likely to include restarted builds. The restarted builds are mostly builds that are initially failing due to a test, network problem, or a Travis CI limitations such as execution timeout. Finally, we observe that restarted builds have an impact on development workflow. Indeed, in 54.42\% of the restarted builds, the developers analyze and restart a build within an hour of the initial build execution. This suggests that developers wait for CI results, interrupting their workflow to address the issue. Restarted builds also slow down the merging of pull requests by a factor of three, bringing median merging time from 16h to 48h.}
}

@comment{EEE}

@comment{FFF}

@article{Fagerholm2017,
  doi = {10.7717/peerj-cs.131},
  url = {https://doi.org/10.7717/peerj-cs.131},
  year = {2017},
  month = sep,
  publisher = {{PeerJ}},
  volume = {3},
  pages = {e131},
  author = {Fabian Fagerholm and Marco Kuhrmann and J\"{u}rgen M\"{u}nch},
  title = {Guidelines for using empirical studies in software engineering education},
  journal = {{PeerJ} Computer Science},
  abstract = {Software engineering education is supposed to provide students with industry-relevant knowledge and skills. Educators must address issues beyond exercises and theories that can be directly rehearsed in small settings. A way to experience such efects and to increase the relevance of software engineering education is to apply empirical studies in teaching. In our article, we show how diferent types of empirical studies can be used for educational purposes in software engineering. We give examples illustrating how to utilize empirical studies, discuss challenges, and derive an initial guideline that supports teachers to include empirical studies in software engineering courses. This summary refers to the paper Guidelines for Using Empirical Studies in Software Engineering Education [FKM17]. This paper was published in the PeerJ Computer Science journal.}
}

@article{Feal2020,
  doi = {10.2478/popets-2020-0029},
  url = {https://doi.org/10.2478/popets-2020-0029},
  year = {2020},
  month = apr,
  publisher = {Walter de Gruyter {GmbH}},
  volume = {2020},
  number = {2},
  pages = {314--335},
  author = {{\'{A}}lvaro Feal and Paolo Calciati and Narseo Vallina-Rodriguez and Carmela Troncoso and Alessandra Gorla},
  title = {Angel or Devil? A Privacy Study of Mobile Parental Control Apps},
  journal = {Proceedings on Privacy Enhancing Technologies},
  abstract = {Android parental control applications are used by parents to monitor and limit their childrens mobile behaviour (e.g., mobile apps usage, web browsing, calling, and texting). In order to offer this service, parental control apps require privileged access to sys-tem resources and access to sensitive data. This may significantly reduce the dangers associated with kids online activities, but it raises important privacy con-cerns. These concerns have so far been overlooked by organizations providing recommendations regarding the use of parental control applications to the public. We conduct the first in-depth study of the Android parental control apps ecosystem from a privacy and regulatory point of view. We exhaustively study 46 apps from 43 developers which have a combined 20M installs in the Google Play Store. Using a combination of static and dynamic analysis we find that: these apps are on average more permissions-hungry than the top 150 apps in the Google Play Store, and tend to request more dangerous permissions with new releases; 11\% of the apps transmit personal data in the clear; 34\% of the apps gather and send personal information without appropriate consent; and 72\% of the apps share data with third parties (including online advertising and analytics services) without mentioning their presence in their privacy policies. In summary, parental control applications lack transparency and lack compliance with reg ulatory requirements. This holds even for those applications recommended by European and other national security centers.}
}

@article{Ferreira2021,
  author = {Gabriel Ferreira and Limin Jia and Joshua Sunshine and Christian K{\"{a}}stner},
  title = {Containing Malicious Package Updates in npm with a Lightweight Permission System},
  journal = {CoRR},
  volume = {abs/2103.05769},
  year = {2021},
  url = {https://arxiv.org/abs/2103.05769},
  archivePrefix = {arXiv},
  eprint = {2103.05769},
  timestamp = {Tue, 16 Mar 2021 11:26:59 +0100},
  biburl = {https://dblp.org/rec/journals/corr/abs-2103-05769.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {The large amount of third-party packages available in fast-moving software ecosystems, such as Node.js/npm, enables attackers to compromise applications by pushing malicious updates to their package dependencies. Studying the npm repository, we observed that many packages in the npm repository that are used in Node.js applications perform only simple computations and do not need access to filesystem or network APIs. This offers the opportunity to enforce least-privilege design per package, protecting applications and package dependencies from malicious updates. We propose a lightweight permission system that protects Node.js applications by enforcing package permissions at runtime. We discuss the design space of solutions and show that our system makes a large number of packages much harder to be exploited, almost for free.}
}

@inproceedings{Ford2017,
  doi = {10.1109/esem.2017.54},
  url = {https://doi.org/10.1109/esem.2017.54},
  year = {2017},
  month = nov,
  publisher = {{IEEE}},
  author = {Denae Ford and Tom Zimmermann and Christian Bird and Nachiappan Nagappan},
  title = {Characterizing Software Engineering Work with Personas Based on Knowledge Worker Actions},
  booktitle = {2017 {ACM}/{IEEE} International Symposium on Empirical Software Engineering and Measurement ({ESEM})},
  abstract = {Mistaking versatility for universal skills, some companies tend to categorize all software engineers the same not knowing a difference exists. For example, a company may select one of many software engineers to complete a task, later finding that the engineer's skills and style do not match those needed to successfully complete that task. This can result in delayed task completion and demonstrates that a one-size fits all concept should not apply to how software engineers work. In order to gain a comprehensive understanding of different software engineers and their working styles we interviewed 21 participants and surveyed 868 software engineers at a large software company and asked them about their work in terms of knowledge worker actions. We identify how tasks, collaboration styles, and perspectives of autonomy can significantly effect different approaches to software engineering work. To characterize differences, we describe empirically informed personas on how they work. Our defined software engineering personas include those with focused debugging abilities, engineers with an active interest in learning, experienced advisors who serve as experts in their role, and more. Our study and results serve as a resource for building products, services, and tools around these software engineering personas.}
}

@inproceedings{Ford2019,
  doi = {10.1109/icse-seis.2019.00014},
  url = {https://doi.org/10.1109/icse-seis.2019.00014},
  year = {2019},
  month = may,
  publisher = {{IEEE}},
  author = {Denae Ford and Mahnaz Behroozi and Alexander Serebrenik and Chris Parnin},
  title = {Beyond the Code Itself: How Programmers Really Look at Pull Requests},
  booktitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering: Software Engineering in Society ({ICSE}-{SEIS})},
  abstract = {Developers in open source projects must make decisions on contributions from other community members, such as whether or not to accept a pull request. However, secondary factors-beyond the code itself-can influence those decisions. For example, signals from GitHub profiles, such as a number of followers, activity, names, or gender can also be considered when developers make decisions. In this paper, we examine how developers use these signals (or not) when making decisions about code contributions. To evaluate this question, we evaluate how signals related to perceived gender identity and code quality influenced decisions on accepting pull requests. Unlike previous work, we analyze this decision process with data collected from an eye-tracker. We analyzed differences in what signals developers said are important for themselves versus what signals they actually used to make decisions about others. We found that after the code snippet (x=57\%), the second place programmers spent their time fixating is on supplemental technical signals (x=32\%), such as previous contributions and popular repositories. Diverging from what participants reported themselves, we also found that programmers fixated on social signals more than recalled.}
}

@article{Foundjem2021,
  doi = {10.1007/s10664-020-09929-1},
  url = {https://doi.org/10.1007/s10664-020-09929-1},
  year = {2021},
  month = mar,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {3},
  author = {Armstrong Foundjem and Bram Adams},
  title = {Release synchronization in software ecosystems},
  journal = {Empirical Software Engineering},
  abstract = {Software ecosystems bring value by integrating software projects related to a given domain, such as Linux distributions integrating upstream open-source projects or the Android ecosystem for mobile Apps. Since each project within an ecosystem may potentially have its release cycle and roadmap, this creates an enormous burden for users who must expend the effort to identify and install compatible project releases from the ecosystem manually. Thus, many ecosystems, such as the Linux distributions, take it upon them to release a polished, well-integrated product to the end-user. However, the body of knowledge lacks empirical evidence about the coordination and synchronization efforts needed at the ecosystem level to ensure such federated releases. This paper empirically studies the strategies used to synchronize releases of ecosystem projects in the context of the OpenStack ecosystem, in which a central release team manages the six-month release cycle of the overall OpenStack ecosystem product. We use qualitative analysis on the release team's IRC-meeting logs that comprise two OpenStack releases (one-year long). Thus, we identified, cataloged, and documented ten major release synchronization activities, which we further validated through interviews with eight active OpenStack senior practitioners (members of either the release team or project teams). Our results suggest that even though an ecosystem's power lies in the interaction of inter-dependent projects, release synchronization remains a challenge for both the release team and the project teams. Moreover, we found evidence (and reasons) of multiple release strategies co-existing within a complex ecosystem.}
}

@article{Fucci2020,
  doi = {10.1109/tse.2018.2834900},
  url = {https://doi.org/10.1109/tse.2018.2834900},
  year = {2020},
  month = jan,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {46},
  number = {1},
  pages = {1--19},
  author = {Davide Fucci and Giuseppe Scanniello and Simone Romano and Natalia Juristo},
  title = {Need for Sleep: The Impact of a Night of Sleep Deprivation on Novice Developers' Performance},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {We present a quasi-experiment to investigate whether, and to what extent, sleep deprivation impacts the performance of novice software developers using the agile practice of test-first development (TFD). We recruited 45 undergraduates, and asked them to tackle a programming task. Among the participants, 23 agreed to stay awake the night before carrying out the task, while 22 slept normally. We analyzed the quality (i.e., the functional correctness) of the implementations delivered by the participants in both groups, their engagement in writing source code (i.e., the amount of activities performed in the IDE while tackling the programming task) and ability to apply TFD (i.e., the extent to which a participant is able to apply this practice). By comparing the two groups of participants, we found that a single night of sleep deprivation leads to a reduction of 50 percent in the quality of the implementations. There is notable evidence that the developers' engagement and their prowess to apply TFD are negatively impacted. Our results also show that sleep-deprived developers make more fixes to syntactic mistakes in the source code. We conclude that sleep deprivation has possibly disruptive effects on software development activities. The results open opportunities for improving developers' performance by integrating the study of sleep with other psycho-physiological factors in which the software engineering research community has recently taken an interest in.}
}

@article{Furia2019,
  doi = {10.1109/tse.2019.2935974},
  url = {https://doi.org/10.1109/tse.2019.2935974},
  year = {2019},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  pages = {1--1},
  author = {Carlo Alberto Furia and Robert Feldt and Richard Torkar},
  title = {Bayesian Data Analysis in Empirical Software Engineering Research},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Statistics comes in two main flavors: frequentist and Bayesian. For historical and technical reasons, frequentist statistics have traditionally dominated empirical data analysis, and certainly remain prevalent in empirical software engineering. This situation is unfortunate because frequentist statistics suffer from a number of shortcomings---such as lack of flexibility and results that are unintuitive and hard to interpret---that curtail their effectiveness when dealing with the heterogeneous data that is increasingly available for empirical analysis of software engineering practice. In this paper, we pinpoint these shortcomings, and present Bayesian data analysis techniques that work better on the same data---as they can provide clearer results that are simultaneously robust and nuanced. After a short, high-level introduction to the basic tools of Bayesian statistics, our presentation targets the reanalysis of two empirical studies targeting data about the effectiveness of automatically generated tests and the performance of programming languages. By contrasting the original frequentist analysis to our new Bayesian analysis, we demonstrate concrete advantages of using Bayesian techniques, and we advocate a prominent role for them in empirical software engineering research and practice.}
}

@comment{GGG}

@inproceedings{Gao2017,
  doi = {10.1109/icse.2017.75},
  url = {https://doi.org/10.1109/icse.2017.75},
  year = {2017},
  month = may,
  publisher = {{IEEE}},
  author = {Zheng Gao and Christian Bird and Earl T. Barr},
  title = {To Type or Not to Type: Quantifying Detectable Bugs in {JavaScript}},
  booktitle = {2017 {IEEE}/{ACM} 39th International Conference on Software Engineering ({ICSE})},
  abstract = {JavaScript is growing explosively and is now used in large mature projects even outside the web domain. JavaScript is also a dynamically typed language for which static type systems, notably Facebook's Flow and Microsoft's TypeScript, have been written. What benefits do these static type systems provide? Leveraging JavaScript project histories, we select a fixed bug and check out the code just prior to the fix. We manually add type annotations to the buggy code and test whether Flow and TypeScript report an error on the buggy code, thereby possibly prompting a developer to fix the bug before its public release. We then report the proportion of bugs on which these type systems reported an error. Evaluating static type systems against public bugs, which have survived testing and review, is conservative: it understates their effectiveness at detecting bugs during private development, not to mention their other benefits such as facilitating code search/completion and serving as documentation. Despite this uneven playing field, our central finding is that both static type systems find an important percentage of public bugs: both Flow 0.30 and TypeScript 2.0 successfully detect 15\%!.}
}

@inproceedings{Gao2020,
  doi = {10.1109/vl/hcc50065.2020.9127274},
  url = {https://doi.org/10.1109/vl/hcc50065.2020.9127274},
  year = {2020},
  month = aug,
  publisher = {{IEEE}},
  author = {Gao Gao and Finn Voichick and Michelle Ichinco and Caitlin Kelleher},
  title = {Exploring Programmers{\textquotesingle} {API} Learning Processes: Collecting Web Resources as External Memory},
  booktitle = {2020 {IEEE} Symposium on Visual Languages and Human-Centric Computing ({VL}/{HCC})},
  abstract = {Modern programming frequently requires the use of APIs (Application Programming Interfaces). Yet many programmers struggle when trying to learn APIs. We ran an exploratory study in which we observed participants performing an API learning task. We analyze their processes using a proposed model of API learning, grounded in Cognitive Load Theory, Information Foraging Theory, and External Memory research. The results provide support for the model of API Learning and add new insights into the form and usage of external memory while learning APIs. Programmers quickly curated a set of API resources through Information Foraging which served as external memory and then primarily referred to these resources to meet information needs while coding.}
}

@article{Garcia2021,
  doi = {10.1007/s10664-021-09975-3},
  url = {https://doi.org/10.1007/s10664-021-09975-3},
  year = {2021},
  month = jul,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {5},
  author = {Boni Garc{\'{\i}}a and Mario Munoz-Organero and Carlos Alario-Hoyos and Carlos Delgado Kloos},
  title = {Automated driver management for Selenium {WebDriver}},
  journal = {Empirical Software Engineering},
  abstract = {Selenium WebDriver is a framework used to control web browsers automatically. It provides a cross-browser Application Programming Interface (API) for different languages (e.g., Java, Python, or JavaScript) that allows automatic navigation, user impersonation, and verification of web applications. Internally, Selenium WebDriver makes use of the native automation support of each browser. Hence, a platform-dependent binary file (the so-called driver) must be placed between the Selenium WebDriver script and the browser to support this native communication. The management (i.e., download, setup, and maintenance) of these drivers is cumbersome for practitioners. This paper provides a complete methodology to automate this management process. Particularly, we present WebDriverManager, the reference tool implementing this methodology. WebDriverManager provides different execution methods: as a Java dependency, as a Command-Line Interface (CLI) tool, as a server, as a Docker container, and as a Java agent. To provide empirical validation of the proposed approach, we surveyed the WebDriverManager users. The aim of this study is twofold. First, we assessed the extent to which WebDriverManager is adopted and used. Second, we evaluated the WebDriverManager API following Clarke's usability dimensions. A total of 148 participants worldwide completed this survey in 2020. The results show a remarkable assessment of the automation capabilities and API usability of WebDriverManager by Java users, but a scarce adoption for other languages.}
}

@inproceedings{Gerosa2021,
  doi = {10.1109/icse43902.2021.00098},
  url = {https://doi.org/10.1109/icse43902.2021.00098},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Marco Gerosa and Igor Wiese and Bianca Trinkenreich and Georg Link and Gregorio Robles and Christoph Treude and Igor Steinmacher and Anita Sarma},
  title = {The Shifting Sands of Motivation: Revisiting What Drives Contributors in Open Source},
  booktitle = {2021 {IEEE}/{ACM} 43rd International Conference on Software Engineering ({ICSE})},
  abstract = {Open Source Software (OSS) has changed drastically over the last decade, with OSS projects now producing a large ecosystem of popular products, involving industry participation, and providing professional career opportunities. But our field's understanding of what motivates people to contribute to OSS is still fundamentally grounded in studies from the early 2000s. With the changed landscape of OSS, it is very likely that motivations to join OSS have also evolved. Through a survey of 242 OSS contributors, we investigate shifts in motivation from three perspectives: (1) the impact of the new OSS landscape, (2) the impact of individuals' personal growth as they become part of OSS communities, and (3) the impact of differences in individuals' demographics. Our results show that some motivations related to social aspects and reputation increased in frequency and that some intrinsic and internalized motivations, such as learning and intellectual stimulation, are still highly relevant. We also found that contributing to OSS often transforms extrinsic motivations to intrinsic, and that while experienced contributors often shift toward altruism, novices often shift toward career, fun, kinship, and learning. OSS projects can leverage our results to revisit current strategies to attract and retain contributors, and researchers and tool builders can better support the design of new studies and tools to engage and support OSS development.}
}

@inproceedings{Glanz2020,
  doi = {10.1145/3320269.3384745},
  url = {https://doi.org/10.1145/3320269.3384745},
  year = {2020},
  month = oct,
  publisher = {{ACM}},
  author = {Leonid Glanz and Patrick M\"{u}ller and Lars Baumg\"{a}rtner and Michael Reif and Sven Amann and Pauline Anthonysamy and Mira Mezini},
  title = {Hidden in Plain Sight: Obfuscated Strings Threatening Your Privacy},
  booktitle = {Proceedings of the 15th {ACM} Asia Conference on Computer and Communications Security},
  abstract = {String obfuscation is an established technique used by proprietary, closed-source applications to protect intellectual property. Furthermore, it is also frequently used to hide spyware or malware in applications. In both cases, the techniques range from bit-manipulation over XOR operations to AES encryption. However, string obfuscation techniques/tools suffer from one shared weakness: They generally have to embed the necessary logic to deobfuscate strings into the app code. In this paper, we show that most of the string obfuscation techniques found in malicious and benign applications for Android can easily be broken in an automated fashion. We developed StringHound, an open-source tool that uses novel techniques that identify obfuscated strings and reconstruct the originals using slicing. We evaluated StringHound on both benign and malicious Android apps. In summary, we deobfuscate almost 30 times more obfuscated strings than other string deobfuscation tools. Additionally, we analyzed 100,000 Google Play Store apps and found multiple obfuscated strings that hide vulnerable cryptographic usages, insecure internet accesses, API keys, hard-coded passwords, and exploitation of privileges without the awareness of the developer. Furthermore, our analysis reveals that not only malware uses string obfuscation but also benign apps make extensive use of string obfuscation.}
}

@article{Gujral2021,
  doi = {10.1002/smr.2361},
  url = {https://doi.org/10.1002/smr.2361},
  year = {2021},
  month = jun,
  publisher = {Wiley},
  volume = {33},
  number = {7},
  author = {Harshit Gujral and Sangeeta Lal and Heng Li},
  title = {An exploratory semantic analysis of logging questions},
  journal = {Journal of Software: Evolution and Process},
  abstract = {Logging is an integral part of software development. Software practitioners often face issues in software logging, and they post these issues on Q\&A websites to take suggestions from the experts. In this study, we perform a three-level empirical analysis of logging questions posted on six popular technical Q\&A websites, namely, Stack Overflow (SO), Serverfault (SF), Superuser (SU), Database Administrators (DB), Software Engineering (SE), and Android Enthusiasts (AE). The findings show that logging issues are prevalent across various domains, for example, database, networks, and mobile computing, and software practitioners from different domains face different logging issues. The semantic analysis of logging questions using Latent Dirichlet Allocation (LDA) reveals trends of several existing and new logging topics, such as logging conversion pattern, Android device logging, and database logging. In addition, we observe specific logging topics for each website: DB (log shipping and log file growing/shrinking), SU (event log and syslog configuration), SF (log analysis and syslog configuration), AE (app install and usage tracking), SE (client server logging and exception logging), and SO (log file creation/deletion, Android emulator logging, and logger class of Log4j). We obtain an increasing trend of logging topics on the SO, SU, and DB websites whereas a decreasing trend of logging topics on the SF website.}
}

@comment{HHH}

@inproceedings{Hata2019,
  doi = {10.1109/icse.2019.00123},
  url = {https://doi.org/10.1109/icse.2019.00123},
  year = {2019},
  month = may,
  publisher = {{IEEE}},
  author = {Hideaki Hata and Christoph Treude and Raula Gaikovina Kula and Takashi Ishio},
  title = {9.6 Million Links in Source Code Comments: Purpose, Evolution, and Decay},
  booktitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering ({ICSE})},
  abstract = {Links are an essential feature of the World Wide Web, and source code repositories are no exception. However, despite their many undisputed benefits, links can suffer from decay, insufficient versioning, and lack of bidirectional traceability. In this paper, we investigate the role of links contained in source code comments from these perspectives. We conducted a large-scale study of around 9.6 million links to establish their prevalence, and we used a mixed-methods approach to identify the links' targets, purposes, decay, and evolutionary aspects. We found that links are prevalent in source code repositories, that licenses, software homepages, and specifications are common types of link targets, and that links are often included to provide metadata or attribution. Links are rarely updated, but many link targets evolve. Almost 10\% of the links included in source code comments are dead. We then submitted a batch of link-fixing pull requests to open source software repositories, resulting in most of our fixes being merged successfully. Our findings indicate that links in source code comments can indeed be fragile, and our work opens up avenues for future work to address these problems.}
}

@inproceedings{Hayashi2019,
  doi = {10.1109/msr.2019.00076},
  url = {https://doi.org/10.1109/msr.2019.00076},
  year = {2019},
  month = may,
  publisher = {{IEEE}},
  author = {Junichi Hayashi and Yoshiki Higo and Shinsuke Matsumoto and Shinji Kusumoto},
  title = {Impacts of Daylight Saving Time on Software Development},
  booktitle = {2019 {IEEE}/{ACM} 16th International Conference on Mining Software Repositories ({MSR})},
  abstract = {Daylight saving time (DST) is observed in many countries and regions. DST is not considered on some software systems at the beginning of their developments, for example, software systems developed in regions where DST is not observed. However, such systems may have to consider DST at the requests of their users. Before now, there has been no study about the impacts of DST on software development. In this paper, we study the impacts of DST on software development by mining the repositories on GitHub. We analyze the date when the code related to DST is changed, and we analyze the regions where the developers applied the changes live. Furthermore, we classify the changes into some patterns.}
}

@article{Hoda2021,
  doi = {10.1109/tse.2021.3106280},
  url = {https://doi.org/10.1109/tse.2021.3106280},
  year = {2021},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  pages = {1--1},
  author = {Rashina Hoda},
  title = {Socio-Technical Grounded Theory for Software Engineering},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Grounded Theory (GT), a sociological research method designed to study social phenomena, is increasingly being used to investigate the human and social aspects of software engineering (SE). However, being written by and for sociologists, GT is often challenging for a majority of SE researchers to understand and apply. Additionally, SE researchers attempting ad hoc adaptations of traditional GT guidelines for modern socio-technical (ST) contexts often struggle in the absence of clear and relevant guidelines to do so, resulting in poor quality studies. To overcome these research community challenges and leverage modern research opportunities, this paper presents Socio-Technical Grounded Theory (STGT) designed to ease application and achieve quality outcomes. It defines what exactly is meant by an ST research context and presents the STGT guidelines that expand GTs philosophical foundations, provide increased clarity and flexibility in its methodological steps and procedures, define possible scope and contexts of application, encourage frequent reporting of a variety of interim, preliminary, and mature outcomes, and introduce nuanced evaluation guidelines for different outcomes. It is hoped that the SE research community and related ST disciplines such as computer science, data science, artificial intelligence, information systems, human computer/robot/AI interaction, human-centered emerging technologies (and increasingly other disciplines being transformed by rapid digitalisation and AI-based augmentation), will benefit from applying STGT to conduct quality research studies and systematically produce rich findings and mature theories with confidence.}
}

@inproceedings{Hora2021a,
  doi = {10.1109/msr52588.2021.00044},
  url = {https://doi.org/10.1109/msr52588.2021.00044},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Andre Hora},
  title = {Googling for Software Development: What Developers Search For and What They Find},
  booktitle = {2021 {IEEE}/{ACM} 18th International Conference on Mining Software Repositories ({MSR})},
  abstract = {Developers often search for software resources on the web. In practice, instead of going directly to websites (e.g., Stack Overflow), they rely on search engines (e.g., Google). Despite this being a common activity, we are not yet aware of what developers search from the perspective of popular software development websites and what search results are returned. With this knowledge, we can understand real-world queries, developers' needs, and the query impact on the search results. In this paper, we provide an empirical study to understand what developers search on the web and what they find. We assess 1.3M queries to popular programming websites and we perform thousands of queries on Google to explore search results. We find that (i) developers' queries typically start with keywords (e.g., Python, Android, etc.), are short (3 words), tend to omit functional words, and are similar among each other; (ii) minor changes to queries do not largely affect the Google search results, however, some cosmetic changes may have a non-negligible impact; and (iii) search results are dominated by Stack Overflow, but YouTube is also a relevant source nowadays. We conclude by presenting detailed implications for researchers and developers.}
}

@inproceedings{Hora2021b,
  doi = {10.1109/msr52588.2021.00051},
  url = {https://doi.org/10.1109/msr52588.2021.00051},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Andre Hora},
  title = {What Code Is Deliberately Excluded from Test Coverage and Why?},
  booktitle = {2021 {IEEE}/{ACM} 18th International Conference on Mining Software Repositories ({MSR})},
  abstract = {Test coverage is largely used to assess test effectiveness. In practice, not all code is equally important for coverage analysis, for instance, code that will not be executed during tests is irrelevant and can actually harm the analysis. Some coverage tools provide support for code exclusion from coverage reports, however, we are not yet aware of what code tends to be excluded nor the reasons behind it. This can support the creation of more accurate coverage reports and reveal novel and harmful usage cases. In this paper, we provide the first empirical study to understand code exclusion practices in test coverage. We mine 55 Python projects and assess commit messages and code comments to detect rationales for exclusions. We find that (1) over 1/3 of the projects perform deliberate coverage exclusion; (2) 75\% of the code are already created using the exclusion feature, while 25\% add it over time; (3) developers exclude non-runnable, debug-only, and defensive code, but also platform-specific and conditional importing; and (4) most code is excluded because it is already untested, low-level, or complex. Finally, we discuss implications to improve coverage analysis and shed light on the existence of biased coverage reports.}
}

@article{Hoyos2021,
  doi = {10.1007/s10664-020-09902-y},
  url = {https://doi.org/10.1007/s10664-020-09902-y},
  year = {2021},
  month = feb,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {2},
  author = {Juan Hoyos and Rabe Abdalkareem and Suhaib Mujahid and Emad Shihab and Albeiro Espinosa Bedoya},
  title = {On the Removal of Feature Toggles: A Study of Python Projects and Practitioners Motivations},
  journal = {Empirical Software Engineering},
  abstract = {Feature Toggling is a technique to control the execution of features in a software project. For example, practitioners using feature toggles can experiment with new features in a production environment by exposing them to a subset of users. Some of these toggles require additional maintainability efforts and are expected to be removed, whereas others are meant to remain for a long time. However, to date, very little is known about the removal of feature toggles, which is why we focus on this topic in our paper. We conduct an empirical study that focuses on the removal of feature toggles. We use source code analysis techniques to analyze 12 Python open source projects and surveyed 61 software practitioners to provide deeper insights on the topic. Our study shows that 75\% of the toggle components in the studied Python projects are removed within 49 weeks after introduction. However, eventually practitioners remove feature toggles to follow the life cycle of a feature when it becomes stable in production. We also find that not all long-term feature toggles are designed to live that long and not all feature toggles are removed from the source code, opening the possibilities to unwanted risks. Our study broadens the understanding of feature toggles by identifying reasons for their survival in practice and aims to help practitioners make better decisions regarding the way they manage and remove feature toggles.}
}

@comment{III}

@comment{JJJ}

@article{Jalote2021,
  doi = {10.1109/tse.2019.2904230},
  url = {https://doi.org/10.1109/tse.2019.2904230},
  year = {2021},
  month = apr,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {4},
  pages = {801--817},
  author = {Pankaj Jalote and Damodaram Kamma},
  title = {Studying Task Processes for Improving Programmer Productivity},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Productivity of a software development organization can be enhanced by improving the software process, using better tools/technology, and enhancing the productivity of programmers. This work focuses on improving programmer productivity by studying the process used by a programmer for executing an assigned task, which we call the task process. We propose a general framework for studying the impact of task processes on programmer productivity and also the impact of transferring task processes of high-productivity programmers to average-productivity peers. We applied the framework to a few live projects in Robert Bosch Engineering and Business Solutions Limited, a CMMI Level 5 company. In each project, we identified two groups of programmers: high-productivity and average-productivity programmers. We requested each programmer to video capture their computer screen while executing his/her assigned tasks. We then analyzed these task videos to extract the task processes and then used them to identify the differences between the task processes used by the two groups. Some key differences were found between the task processes, which could account for the difference in productivities of the two groups. Similarities between the task processes were also analyzed quantitatively by modeling each task process as a Markov chain. We found that programmers from the same group used similar task processes, but the task processes of the two groups differed considerably. The task processes of high-productivity programmers were transferred to the average-productivity programmers by training them on the key steps missing in their process but commonly present in the work of their high-productivity peers. A substantial productivity gain was found in the average-productivity programmers as a result of this transfer. The study shows that task processes of programmers impact their productivity, and it is possible to improve the productivity of average-productivity programmers by transferring task processes from high-productivity programmers to them.}
}

@inproceedings{Johnson2019,
  doi = {10.1109/icsme.2019.00085},
  url = {https://doi.org/10.1109/icsme.2019.00085},
  year = {2019},
  month = sep,
  publisher = {{IEEE}},
  author = {John Johnson and Sergio Lubo and Nishitha Yedla and Jairo Aponte and Bonita Sharif},
  title = {An Empirical Study Assessing Source Code Readability in Comprehension},
  booktitle = {2019 {IEEE} International Conference on Software Maintenance and Evolution ({ICSME})},
  abstract = {Software developers spend a significant amount of time reading source code. If code is not written with readability in mind, it impacts the time required to maintain it. In order to alleviate the time taken to read and understand code, it is important to consider how readable the code is. The general consensus is that source code should be written to minimize the time it takes for others to read and understand it. In this paper, we conduct a controlled experiment to assess two code readability rules: nesting and looping. We test 32 Java methods in four categories: ones that follow/do not follow the readability rule and that are correct/incorrect. The study was conducted online with 275 participants. The results indicate that minimizing nesting decreases the time a developer spends reading and understanding source code, increases confidence about the developer's understanding of the code, and also suggests that it improves their ability to find bugs. The results also show that avoiding the do-while statement had no significant impact on level of understanding, time spent reading and understanding, confidence in understanding, or ease of finding bugs. It was also found that the better knowledge of English a participant had, the more their readability and comprehension confidence ratings were affected by the minimize nesting rule. We discuss the implications of these findings for code readability and comprehension.}
}

@article{Johnson2021,
  doi = {10.1109/tse.2019.2903053},
  url = {https://doi.org/10.1109/tse.2019.2903053},
  year = {2021},
  month = apr,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {4},
  pages = {736--757},
  author = {Brittany Johnson and Thomas Zimmermann and Christian Bird},
  title = {The Effect of Work Environments on Productivity and Satisfaction of Software Engineers},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {The physical work environment of software engineers can have various effects on their satisfaction and the ability to get the work done. To better understand the factors of the environment that affect productivity and satisfaction of software engineers, we explored different work environments at Microsoft. We used a mixed-methods, multiple stage research design with a total of 1,159 participants: two surveys with 297 and 843 responses respectively and interviews with 19 employees. We found several factors that were considered as important for work environments: personalization, social norms and signals, room composition and atmosphere, work-related environment affordances, work area and furniture, and productivity strategies. We built statistical models for satisfaction with the work environment and perceived productivity of software engineers and compared them to models for employees in the Program Management, IT Operations, Marketing, and Business Program \& Operations disciplines. In the satisfaction models, the ability to work privately with no interruptions and the ability to communicate with the team and leads were important factors among all disciplines. In the productivity models, the overall satisfaction with the work environment and the ability to work privately with no interruptions were important factors among all disciplines. For software engineers, another important factor for perceived productivity was the ability to communicate with the team and leads. We found that private offices were linked to higher perceived productivity across all disciplines.}
}

@article{Jolak2020,
  doi = {10.1007/s10664-020-09835-6},
  url = {https://doi.org/10.1007/s10664-020-09835-6},
  year = {2020},
  month = sep,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {25},
  number = {6},
  pages = {4427--4471},
  author = {Rodi Jolak and Maxime Savary-Leblanc and Manuela Dalibor and Andreas Wortmann and Regina Hebig and Juraj Vincur and Ivan Polasek and Xavier Le Pallec and S{\'{e}}bastien G{\'{e}}rard and Michel R. V. Chaudron},
  title = {Software engineering whispers: The effect of textual vs. graphical software design descriptions on software design communication},
  journal = {Empirical Software Engineering},
  abstract = {Software engineering is a social and collaborative activity. Communicating and sharing knowledge between software developers requires much effort. Hence, the quality of communication plays an important role in influencing project success. To better understand the effect of communication on project success, more in-depth empirical studies investigating this phenomenon are needed. We investigate the effect of using a graphical versus textual design description on co-located software design communication. Therefore, we conducted a family of experiments involving a mix of 240 software engineering students from four universities. We examined how different design representations (i.e., graphical vs. textual) affect the ability to Explain, Understand, Recall, and Actively Communicate knowledge. We found that the graphical design description is better than the textual in promoting Active Discussion between developers and improving the Recall of design details. Furthermore, compared to its unaltered version, a well-organized and motivated textual design description---that is used for the same amount of time---enhances the recall of design details and increases the amount of active discussions at the cost of reducing the perceived quality of explaining.}
}

@book{Jones2020,
  author = {Derek M. Jones},
  title = {Evidence-based Software Engineering: based on the publicly available data},
  publisher = {Knowledge Software, Ltd.},
  ISBN = {978-1-8382913-0-3},
  month = nov,
  year = {2020},
  url = {http://www.knosof.co.uk/ESEUR/},
  abstract = {This book discusses what is currently known about software engineering, based on an analysis of all the publicly available data. This aim is not as ambitious as it sounds, because there is not a great deal of data publicly available. The intent is to provide material that is useful to professional developers working in industry; until recently researchers in software engineering have been more interested in vanity work, promoted by ego and bluster. The material is organized in two parts, the first covering software engineering and the second the statistics likely to be needed for the analysis of software engineering data.}
}

@comment{KKK}

@inproceedings{Kamienski2021,
  doi = {10.1109/msr52588.2021.00066},
  url = {https://doi.org/10.1109/msr52588.2021.00066},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Arthur V. Kamienski and Luisa Palechor and Cor-Paul Bezemer and Abram Hindle},
  title = {{PySStuBs}: Characterizing Single-Statement Bugs in Popular Open-Source Python Projects},
  booktitle = {2021 {IEEE}/{ACM} 18th International Conference on Mining Software Repositories ({MSR})},
  abstract = {Single-statement bugs (SStuBs) can have a severe impact on developer productivity. Despite usually being simple and not offering much of a challenge to fix, these bugs may still disturb a developer's workflow and waste precious development time. However, few studies have paid attention to these simple bugs, focusing instead on bugs of any size and complexity. In this study, we explore the occurrence of SStuBs in some of the most popular open-source Python projects on GitHub, while also characterizing their patterns and distribution. We further compare these bugs to SStuBs found in a previous study on Java Maven projects. We find that these Python projects have different SStuB patterns than the ones in Java Maven projects and identify 7 new SStuB patterns. Our results may help uncover the importance of understanding these bugs for the Python programming language, and how developers can handle them more effectively.}
}

@inproceedings{Kavaler2019,
  doi = {10.1109/icse.2019.00060},
  url = {https://doi.org/10.1109/icse.2019.00060},
  year = {2019},
  month = may,
  publisher = {{IEEE}},
  author = {David Kavaler and Asher Trockman and Bogdan Vasilescu and Vladimir Filkov},
  title = {Tool Choice Matters: {JavaScript} Quality Assurance Tools and Usage Outcomes in {GitHub} Projects},
  booktitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering ({ICSE})},
  abstract = {Quality assurance automation is essential in modern software development. In practice, this automation is supported by a multitude of tools that fit different needs and require developers to make decisions about which tool to choose in a given context. Data and analytics of the pros and cons can inform these decisions. Yet, in most cases, there is a dearth of empirical evidence on the effectiveness of existing practices and tool choices. We propose a general methodology to model the time-dependent effect of automation tool choice on four outcomes of interest: prevalence of issues, code churn, number of pull requests, and number of contributors, all with a multitude of controls. On a large data set of npm JavaScript projects, we extract the adoption events for popular tools in three task classes: linters, dependency managers, and coverage reporters. Using mixed methods approaches, we study the reasons for the adoptions and compare the adoption effects within each class, and sequential tool adoptions across classes. We find that some tools within each group are associated with more beneficial outcomes than others, providing an empirical perspective for the benefits of each. We also find that the order in which some tools are implemented is associated with varying outcomes.}
}

@article{Kim2021,
  doi = {10.1007/s10664-021-09969-1},
  url = {https://doi.org/10.1007/s10664-021-09969-1},
  year = {2021},
  month = jul,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {5},
  author = {Dong Jae Kim and Tse-Hsun Chen and Jinqiu Yang},
  title = {The secret life of test smells{\textemdash}an empirical study on test smell evolution and maintenance},
  journal = {Empirical Software Engineering},
  abstract = {In recent years, researchers and practitioners have been studying the impact of test smells in test maintenance. However, there is still limited empirical evidence on why developers remove test smells in software maintenance and the mechanism employed for addressing test smells. In this paper, we conduct an empirical study on 12 real-world open-source systems to study the evolution and maintenance of test smells and how test smells are related to software quality. Results show that: 1) Although the number of test smell instances increases, test smell density decreases as systems evolve. 2) However, our qualitative analysis on those removed test smells reveals that most test smell removal (83\%) is a by-product of feature maintenance activities. 45\% of the removed test smells relocate to other test cases due to refactoring, while developers deliberately address the only 17\% of test smells, consisting of largely Exception Catch/Throw and Sleepy Test. 3) Our statistical model shows that test smell metrics can provide additional explanatory power on post-release defects over traditional baseline metrics (an average of 8.25\% increase in AUC). However, most types of test smells have a minimal effect on post-release defects. Our study provides insight into developers' perception of test smells and current practices. Future studies on test smells may consider focusing on the specific types of test smells that may have a higher correlation with defect-proneness when helping developers with test code maintenance.}
}

@article{Klotins2021,
  doi = {10.1109/tse.2019.2900213},
  url = {https://doi.org/10.1109/tse.2019.2900213},
  year = {2021},
  month = mar,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {3},
  pages = {498--521},
  author = {Eriks Klotins and Michael Unterkalmsteiner and Panagiota Chatzipetrou and Tony Gorschek and Rafael Prikladnicki and Nirnaya Tripathi and Leandro Bento Pompermaier},
  title = {A Progression Model of Software Engineering Goals, Challenges, and Practices in Start-Ups},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Context: Software start-ups are emerging as suppliers of innovation and software-intensive products. However, traditional software engineering practices are not evaluated in the context, nor adopted to goals and challenges of start-ups. As a result, there is insufficient support for software engineering in the start-up context. Objective: We aim to collect data related to engineering goals, challenges, and practices in start-up companies to ascertain trends and patterns characterizing engineering work in start-ups. Such data allows researchers to understand better how goals and challenges are related to practices. This understanding can then inform future studies aimed at designing solutions addressing those goals and challenges. Besides, these trends and patterns can be useful for practitioners to make more informed decisions in their engineering practice. Method: We use a case survey method to gather first-hand, in-depth experiences from a large sample of software start-ups. We use open coding and cross-case analysis to describe and identify patterns, and corroborate the findings with statistical analysis. Results: We analyze 84 start-up cases and identify 16 goals, 9 challenges, and 16 engineering practices that are common among start-ups. We have mapped these goals, challenges, and practices to start-up life-cycle stages (inception, stabilization, growth, and maturity). Thus, creating the progression model guiding software engineering efforts in start-ups. Conclusions: We conclude that start-ups to a large extent face the same challenges and use the same practices as established companies. However, the primary software engineering challenge in start-ups is to evolve multiple process areas at once, with a little margin for serious errors.}
}

@article{Kochhar2019,
  doi = {10.1109/tse.2019.2937025},
  url = {https://doi.org/10.1109/tse.2019.2937025},
  year = {2019},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  pages = {1--1},
  author = {Pavneet Singh Kochhar and Eirini Kalliamvakou and Nachiappan Nagappan and Thomas Zimmermann and Christian Bird},
  title = {Moving from Closed to Open Source: Observations from Six Transitioned Projects to {GitHub}},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Open source software systems have gained a lot of attention in the past few years. With the emergence of open source platforms like GitHub, developers can contribute, store, and manage their projects with ease. Large organizations like Microsoft, Google, and Facebook are open sourcing their in-house technologies in an effort to more broadly involve the community in the development of software systems. Although closed source and open source systems have been studied extensively, there has been little research on the transition from closed source to open source systems. Through this study we aim to: a) provide guidance and insights for other teams planning to open source their projects and b) to help them avoid pitfalls during the transition process. We studied six different Microsoft systems, which were recently open-sourced i.e., CoreFX, CoreCLR, Roslyn, Entity Framework, MVC, and Orleans. This paper presents the transition from the viewpoints of both Microsoft and the open source community based on interviews with eleven Microsoft developer, five Microsoft senior managers involved in the decision to open source, and eleven open-source developers. From Microsoft's perspective we discuss the reasons for the transition, experiences of developers involved, and the transition's outcomes and challenges. Our results show that building a vibrant community, prompt answers, developing an open source culture, security regulations and business opportunities are the factors which persuade companies to open source their products. We also discuss the transition outcomes on processes such as code reviews, version control systems, continuous integration as well as developers' perception of these changes. From the open source community's perspective, we illustrate the response to the open-sourcing initiative through contributions and interactions with the internal developers and provide guidelines for other projects planning to go open source.}
}

@article{Kosar2018,
  doi = {10.1007/s10664-017-9593-2},
  url = {https://doi.org/10.1007/s10664-017-9593-2},
  year = {2018},
  month = feb,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {23},
  number = {5},
  pages = {2734--2763},
  author = {Toma{\v{z}} Kosar and Sa{\v{s}}o Gaberc and Jeffrey C. Carver and Marjan Mernik},
  title = {Program comprehension of domain-specific and general-purpose languages: replication of a family of experiments using integrated development environments},
  journal = {Empirical Software Engineering},
  abstract = {Domain-specific languages (DSLs) allow developers to write code at a higher level of abstraction compared with general-purpose languages (GPLs). Developers often use DSLs to reduce the complexity of GPLs. Our previous study found that developers performed program comprehension tasks more accurately and efficiently with DSLs than with corresponding APIs in GPLs. This study replicates our previous study to validate and extend the results when developers use IDEs to perform program comprehension tasks. We performed a dependent replication of a family of experiments. We made two specific changes to the original study: (1) participants used IDEs to perform the program comprehension tasks, to address a threat to validity in the original experiment and (2) each participant performed program comprehension tasks on either DSLs or GPLs, not both as in the original experiment. The results of the replication are consistent with and expanded the results of the original study. Developers are significantly more effective and efficient in tool-based program comprehension when using a DSL than when using a corresponding API in a GPL. The results indicate that, where a DSL is available, developers will perform program comprehension better using the DSL than when using the corresponding API in a GPL.}
}

@inproceedings{Krueger2020,
  doi = {10.1145/3377811.3380348},
  url = {https://doi.org/10.1145/3377811.3380348},
  year = {2020},
  month = jun,
  publisher = {{ACM}},
  author = {Ryan Krueger and Yu Huang and Xinyu Liu and Tyler Santander and Westley Weimer and Kevin Leach},
  title = {Neurological divide: an {fMRI} study of prose and code writing},
  booktitle = {Proceedings of the {ACM}/{IEEE} 42nd International Conference on Software Engineering},
  abstract = {Software engineering involves writing new code or editing existing code. Recent efforts have investigated the neural processes associated with reading and comprehending code---however, we lack a thorough understanding of the human cognitive processes underlying code writing. While prose reading and writing have been studied thoroughly, that same scrutiny has not been applied to code writing. In this paper, we leverage functional brain imaging to investigate neural representations of code writing in comparison to prose writing. We present the first human study in which participants wrote code and prose while undergoing a functional magnetic resonance imaging (fMRI) brain scan, making use of a full-sized fMRI-safe QWERTY keyboard. We find that code writing and prose writing are significantly dissimilar neural tasks. While prose writing entails significant left hemisphere activity associated with language, code writing involves more activations of the right hemisphere, including regions associated with attention control, working memory, planning and spatial cognition. These findings are unlike existing work in which code and prose comprehension were studied. By contrast, we present the first evidence suggesting that code and prose writing are quite dissimilar at the neural level.}
}

@comment{LLL}

@inproceedings{Latendresse2021,
  doi = {10.1109/msr52588.2021.00062},
  url = {https://doi.org/10.1109/msr52588.2021.00062},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Jasmine Latendresse and Rabe Abdalkareem and Diego Elias Costa and Emad Shihab},
  title = {How Effective is Continuous Integration in Indicating Single-Statement Bugs?},
  booktitle = {2021 {IEEE}/{ACM} 18th International Conference on Mining Software Repositories ({MSR})},
  abstract = {Continuous Integration (CI) is the process of automatically compiling, building, and testing code changes in the hope of catching bugs as they are introduced into the code base. With bug fixing being a core and increasingly costly task in software development, the community has adopted CI to mitigate this issue and improve the quality of their software products. Bug fixing is a core task in software development and becomes increasingly costly over time. However, little is known about how effective CI is at detecting simple, single-statement bugs.In this paper, we analyze the effectiveness of CI in 14 popular open source Java-based projects to warn about 318 single-statement bugs (SStuBs). We analyze the build status at the commits that introduce SStuBs and before the SStuBs were fixed. We then investigate how often CI indicates the presence of these bugs, through test failure. Our results show that only 2\% of the commits that introduced SStuBs have builds with failed tests and 7.5\% of builds before the fix reported test failures. Upon close manual inspection, we found that none of the failed builds actually captured SStuBs, indicating that CI is not the right medium to capture the SStuBs we studied. Our results suggest that developers should not rely on CI to catch SStuBs or increase their CI pipeline coverage to detect single-statement bugs.}
}

@article{LeGoues2018,
  doi = {10.1109/ms.2018.3571235},
  url = {https://doi.org/10.1109/ms.2018.3571235},
  year = {2018},
  month = sep,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {35},
  number = {5},
  pages = {50--57},
  author = {Claire {Le Goues} and Ciera Jaspan and Ipek Ozkaya and Mary Shaw and Kathryn T. Stolee},
  title = {Bridging the Gap: From Research to Practical Advice},
  journal = {{IEEE} Software},
  abstract = {Software developers need actionable guidance, but researchers rarely integrate diverse types of evidence in a way that indicates the recommendations' strength. A levels-ofevidence framework might allow researchers and practitioners to translate research results to a pragmatically useful form.}
}

@article{LeGoues2021,
  doi = {10.1109/ms.2021.3072577},
  url = {https://doi.org/10.1109/ms.2021.3072577},
  year = {2021},
  month = jul,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {38},
  number = {4},
  pages = {22--27},
  author = {Claire Le Goues and Michael Pradel and Abhik Roychoudhury and Satish Chandra},
  title = {Automatic Program Repair},
  journal = {{IEEE} Software},
  abstract = {An introduction to a special journal issue on automatic program repair.}
}

@article{Leito2019,
  doi = {10.1080/07370024.2019.1685883},
  url = {https://doi.org/10.1080/07370024.2019.1685883},
  year = {2019},
  month = dec,
  publisher = {Informa {UK} Limited},
  volume = {36},
  number = {3},
  pages = {203--242},
  author = {Roxanne Leit{\~{a}}o},
  title = {Technology-Facilitated Intimate Partner Abuse: a qualitative analysis of data from online domestic abuse forums},
  journal = {Human{\textendash}Computer Interaction},
  abstract = {This article reports on a qualitative analysis of data gathered from three online discussion forums for victims and survivors of domestic abuse. The analysis focussed on technology-facilitated abuse and the findings cover three main themes, namely, 1) forms of technology-facilitated abuse being discussed on the forums, 2) the ways in which forum members are using technology within the context of intimate partner abuse, and 3) the digital privacy and security advice being exchanged between victims/survivors on the forums. The article concludes with a discussion on the dual role of digital technologies within the context of intimate partner abuse, on the challenges and advantages of digital ubiquity, as well as on the issues surrounding digital evidence of abuse, and the labor of managing digital privacy and security.}
}

@article{Lemire2021,
  doi = {10.1002/spe.2984},
  url = {https://doi.org/10.1002/spe.2984},
  year = {2021},
  month = may,
  publisher = {Wiley},
  volume = {51},
  number = {8},
  pages = {1700--1727},
  author = {Daniel Lemire},
  title = {Number parsing at a gigabyte per second},
  journal = {Software: Practice and Experience},
  abstract = {With disks and networks providing gigabytes per second, parsing decimal numbers from strings becomes a bottleneck. We consider the problem of parsing decimal numbers to the nearest binary floating-point value. The general problem requires variable-precision arithmetic. However, we need at most 17 digits to represent 64-bit standard floating-point numbers (IEEE 754). Thus, we can represent the decimal significand with a single 64-bit word. By combining the significand and precomputed tables, we can compute the nearest floating-point number using as few as one or two 64-bit multiplications. Our implementation can be several times faster than conventional functions present in standard C libraries on modern 64-bit systems (Intel, AMD, ARM, and POWER9). Our work is available as open source software used by major systems such as Apache Arrow and Yandex ClickHouse. The Go standard library has adopted a version of our approach.}
}

@article{Levy2020,
  doi = {10.1093/cybsec/tyaa006},
  url = {https://doi.org/10.1093/cybsec/tyaa006},
  year = {2020},
  month = jan,
  publisher = {Oxford University Press ({OUP})},
  volume = {6},
  number = {1},
  author = {Karen Levy and Bruce Schneier},
  title = {Privacy threats in intimate relationships},
  journal = {Journal of Cybersecurity},
  abstract = {This article provides an overview of intimate threats: a class of privacy threats that can arise within our families, romantic partnerships, close friendships, and caregiving relationships. Many common assumptions about privacy are upended in the context of these relationships, and many otherwise effective protective measures fail when applied to intimate threats. Those closest to us know the answers to our secret questions, have access to our devices, and can exercise coercive power over us. We survey a range of intimate relationships and describe their common features. Based on these features, we explore implications for both technical privacy design and policy, and offer design recommendations for ameliorating intimate privacy risks.}
}

@article{Lima2021,
  doi = {10.1007/s10664-021-09983-3},
  url = {https://doi.org/10.1007/s10664-021-09983-3},
  year = {2021},
  month = jun,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {5},
  author = {Luan P. Lima and Lincoln S. Rocha and Carla I. M. Bezerra and Matheus Paixao},
  title = {Assessing exception handling testing practices in open-source libraries},
  journal = {Empirical Software Engineering},
  abstract = {Modern programming languages (e.g., Java and C\#) provide features to separate error-handling code from regular code, seeking to enhance software comprehensibility and maintainability. Nevertheless, the way exception handling (EH) code is structured in such languages may lead to multiple, different, and complex control flows, which may affect the software testability. Previous studies have reported that EH code is typically neglected, not well tested, and its misuse can lead to reliability degradation and catastrophic failures. However, little is known about the relationship between testing practices and EH testing effectiveness. In this exploratory study, we (i) measured the adequacy degree of EH testing concerning code coverage (instruction, branch, and method) criteria; and (ii) evaluated the effectiveness of the EH testing by measuring its capability to detect artificially injected faults (i.e., mutants) using 7 EH mutation operators. Our study was performed using test suites of 27 long-lived Java libraries from open-source ecosystems. Our results show that instructions and branches within catch blocks and throw instructions are less covered, with statistical significance, than the overall instructions and branches. Nevertheless, most of the studied libraries presented test suites capable of detecting more than 70\% of the injected faults. From a total of 12, 331 mutants created in this study, the test suites were able to detect 68\% of them.}
}

@article{LimaJunior2021,
  doi = {10.1002/smr.2337},
  url = {https://doi.org/10.1002/smr.2337},
  year = {2021},
  month = apr,
  publisher = {Wiley},
  volume = {33},
  number = {6},
  author = {Manoel Limeira Lima J{\'{u}}nior and Daric{\'{e}}lio Soares and Alexandre Plastino and Leonardo Murta},
  title = {Predicting the lifetime of pull requests in open-source projects},
  journal = {Journal of Software: Evolution and Process},
  abstract = {A recent survey using industrial projects has shown that providing an estimate of the lifetime of pull requests to developers helps to speed up their conclusion. Previous work has explored pull request lifetime prediction in open-source projects using regression techniques but with a broad margin of error. The first objective of our work was to reduce the average error rate of the prediction obtained by the regression techniques so far. We performed experiments with different regression techniques and achieved a significant decrease in the mean error rate. The second objective of our work was to obtain a more effective and useful predictive model that can classify pull requests according to five discrete time intervals. We proposed new predictive attributes for the estimation of the time intervals and employed attribute selection strategies to identify subsets of attributes that could improve the predictive behavior of the classifiers. Our classification approach achieved the best accuracy in all the 20 projects evaluated in comparison with the literature. The average accuracy was of 45.28\% to predict pull request lifetime, with an average normalized improvement of 14.68\% in relation to the majority class and 6.49\% in relation to the state-of-the-art.}
}

@article{Liu2021,
  doi = {10.1109/tse.2018.2884955},
  url = {https://doi.org/10.1109/tse.2018.2884955},
  year = {2021},
  month = jan,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {1},
  pages = {165--188},
  author = {Kui Liu and Dongsun Kim and Tegawende F. Bissyande and Shin Yoo and Yves Le Traon},
  title = {Mining Fix Patterns for {FindBugs} Violations},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Several static analysis tools, such as Splint or FindBugs, have been proposed to the software development community to help detect security vulnerabilities or bad programming practices. However, the adoption of these tools is hindered by their high false positive rates. If the false positive rate is too high, developers may get acclimated to violation reports from these tools, causing concrete and severe bugs being overlooked. Fortunately, some violations are actually addressed and resolved by developers. We claim that those violations that are recurrently fixed are likely to be true positives, and an automated approach can learn to repair similar unseen violations. However, there is lack of a systematic way to investigate the distributions on existing violations and fixed ones in the wild, that can provide insights into prioritizing violations for developers, and an effective way to mine code and fix patterns which can help developers easily understand the reasons of leading violations and how to fix them. In this paper, we first collect and track a large number of fixed and unfixed violations across revisions of software. The empirical analyses reveal that there are discrepancies in the distributions of violations that are detected and those that are fixed, in terms of occurrences, spread and categories, which can provide insights into prioritizing violations. To automatically identify patterns in violations and their fixes, we propose an approach that utilizes convolutional neural networks to learn features and clustering to regroup similar instances. We then evaluate the usefulness of the identified fix patterns by applying them to unfixed violations. The results show that developers will accept and merge a majority (69/116) of fixes generated from the inferred fix patterns. It is also noteworthy that the yielded patterns are applicable to four real bugs in the Defects4J major benchmark for software testing and automated repair.}
}

@inproceedings{Louis2020,
  doi = {10.1145/3377816.3381736},
  url = {https://doi.org/10.1145/3377816.3381736},
  year = {2020},
  month = jun,
  publisher = {{ACM}},
  author = {Annie Louis and Santanu Kumar Dash and Earl T. Barr and Michael D. Ernst and Charles Sutton},
  title = {Where should I comment my code?: a dataset and model for predicting locations that need comments},
  booktitle = {Proceedings of the {ACM}/{IEEE} 42nd International Conference on Software Engineering: New Ideas and Emerging Results},
  abstract = {Programmers should write code comments, but not on every line of code. We have created a machine learning model that suggests locations where a programmer should write a code comment. We trained it on existing commented code to learn locations that are chosen by developers. Once trained, the model can predict locations in new code. Our models achieved precision of 74\% and recall of 13\% in identifying comment-worthy locations. This first success opens the door to future work, both in the new where-to-comment problem and in guiding comment generation. Our code and data is available at http://groups.inf.ed.ac.uk/cup/comment-locator/.}
}

@comment{MMM}

@article{Ma2021,
  doi = {10.1007/s10664-020-09905-9},
  url = {https://doi.org/10.1007/s10664-020-09905-9},
  year = {2021},
  month = feb,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {2},
  author = {Yuxing Ma and Tapajit Dey and Chris Bogart and Sadika Amreen and Marat Valiev and Adam Tutko and David Kennard and Russell Zaretzki and Audris Mockus},
  title = {World of code: enabling a research workflow for mining and analyzing the universe of open source {VCS} data},
  journal = {Empirical Software Engineering},
  abstract = {Open source software (OSS) is essential for modern society and, while substantial research has been done on individual (typically central) projects, only a limited understanding of the periphery of the entire OSS ecosystem exists. For example, how are the tens of millions of projects in the periphery interconnected through. technical dependencies, code sharing, or knowledge flow? To answer such questions we: a) create a very large and frequently updated collection of version control data in the entire FLOSS ecosystems named World of Code (WoC), that can completely cross-reference authors, projects, commits, blobs, dependencies, and history of the FLOSS ecosystems and b) provide capabilities to efficiently correct, augment, query, and analyze that data. Our current WoC implementation is capable of being updated on a monthly basis and contains over 18B Git objects. To evaluate its research potential and to create vignettes for its usage, we employ WoC in conducting several research tasks. In particular, we find that it is capable of supporting trend evaluation, ecosystem measurement, and the determination of package usage. We expect WoC to spur investigation into global properties of OSS development leading to increased resiliency of the entire OSS ecosystem. Our infrastructure facilitates the discovery of key technical dependencies, code flow, and social networks that provide the basis to determine the structure and evolution of the relationships that drive FLOSS activities and innovation.}
}

@article{Maenpaa2018,
  doi = {10.1186/s13174-018-0088-1},
  url = {https://doi.org/10.1186/s13174-018-0088-1},
  year = {2018},
  month = aug,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {9},
  number = {1},
  author = {Hanna M\"{a}enp\"{a}\"{a} and Simo M\"{a}kinen and Terhi Kilamo and Tommi Mikkonen and Tomi M\"{a}nnist\"{o} and Paavo Ritala},
  title = {Organizing for openness: six models for developer involvement in hybrid {OSS} projects},
  journal = {Journal of Internet Services and Applications},
  abstract = {This article examines organization and governance of commercially influenced Open Source Software development communities by presenting a multiple-case study of six contemporary, hybrid OSS projects. The findings provide in-depth understanding on how to design the participatory nature of the software development process, while understanding the factors that influence the delicate balance of openness, motivations, and governance. The results lay ground for further research on how to organize and manage developer communities where needs of the stakeholders are competing, yet complementary.}
}

@article{Macho2021,
  doi = {10.1007/s10664-020-09926-4},
  url = {https://doi.org/10.1007/s10664-020-09926-4},
  year = {2021},
  month = mar,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {3},
  author = {Christian Macho and Stefanie Beyer and Shane McIntosh and Martin Pinzger},
  title = {The nature of build changes: An empirical study of Maven-based build systems},
  journal = {Empirical Software Engineering},
  abstract = {Build systems are an essential part of modern software projects. As software projects change continuously, it is crucial to understand how the build system changes because neglecting its maintenance can, at best, lead to expensive build breakage, or at worst, introduce user-reported defects due to incorrectly compiled, linked, packaged, or deployed official releases. Recent studies have investigated the (co-)evolution of build configurations and reasons for build breakage; however, the prior analysis focused on a coarse-grained outcome (i.e., either build changing or not). In this paper, we present BUILDDIFF, an approach to extract detailed build changes from MAVEN build files and classify them into 143 change types. In a manual evaluation of 400 build-changing commits, we show that BUILDDIFF can extract and classify build changes with average precision, recall, and f1-scores of 0.97, 0.98, and 0.97, respectively. We then present two studies using the build changes extracted from 144 open source Java projects to study the frequency and time of build changes. The results show that the top-10 most frequent change types account for 51\% of the build changes. Among them, changes to version numbers and changes to dependencies of the projects occur most frequently. We also observe frequently co-occurring changes, such as changes to the source code management definitions, and corresponding changes to the dependency management system and the dependency declaration. Furthermore, our results show that build changes frequently occur around release days. In particular, critical changes, such as updates to plugin configuration parts and dependency insertions, are performed before a release day. The contributions of this paper lay in the foundation for future research, such as for analyzing the (co-)evolution of build files with other artifacts, improving effort estimation approaches by incorporating necessary modifications to the build system specification, or automatic repair approaches for configuration code. Furthermore, our detailed change information enables improvements of refactoring approaches for build configurations and improvements of prediction models to identify error-prone build files.}
}

@article{Malik2019,
  doi = {10.3390/geosciences9120516},
  url = {https://doi.org/10.3390/geosciences9120516},
  year = {2019},
  month = dec,
  publisher = {{MDPI} {AG}},
  volume = {9},
  number = {12},
  pages = {516},
  author = {Mashkoor Malik and Alexandre C. G. Schimel and Giuseppe Masetti and Marc Roche and Julian Le Deunf and Margaret F.J. Dolan and Jonathan Beaudoin and Jean-Marie Augustin and Travis Hamilton and Iain Parnum},
  title = {Results from the First Phase of the Seafloor Backscatter Processing Software Inter-Comparison Project},
  journal = {Geosciences},
  abstract = {Seafloor backscatter mosaics are now routinely produced from multibeam echosounder data and used in a wide range of marine applications. However, large differences (>5 dB) can often be observed between the mosaics produced by different software packages processing the same dataset. Without transparency of the processing pipeline and the lack of consistency between software packages raises concerns about the validity of the final results. To recognize the source(s) of inconsistency between software, it is necessary to understand at which stage(s) of the data processing chain the differences become substantial. To this end, willing commercial and academic software developers were invited to generate intermediate processed backscatter results from a common dataset, for cross-comparison. The first phase of the study requested intermediate processed results consisting of two stages of the processing sequence: the one-value-per-beam level obtained after reading the raw data and the level obtained after radiometric corrections but before compensation of the angular dependence. Both of these intermediate results showed large differences between software solutions. This study explores the possible reasons for these differences and highlights the need for collaborative efforts between software developers and their users to improve the consistency and transparency of the backscatter data processing sequence.}
}

@article{Malloy2018,
  doi = {10.1007/s10664-018-9637-2},
  url = {https://doi.org/10.1007/s10664-018-9637-2},
  year = {2018},
  month = jul,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {24},
  number = {2},
  pages = {751--778},
  author = {Brian A. Malloy and James F. Power},
  title = {An empirical analysis of the transition from Python 2 to Python 3},
  journal = {Empirical Software Engineering},
  abstract = {Python is one of the most popular and widely adopted programming languages in use today. In 2008 the Python developers introduced a new version of the language, Python 3.0, that was not backward compatible with Python 2, initiating a transitional phase for Python software developers. In this paper, we describe a study that investigates the degree to which Python software developers are making the transition from Python 2 to Python 3. We have developed a Python compliance analyser, PyComply, and have analysed a previously studied corpus of Python applications called Qualitas. We use PyComply to measure and quantify the degree to which Python 3 features are being used, as well as the rate and context of their adoption in the Qualitas corpus. Our results indicate that Python software developers are not exploiting the new features and advantages of Python 3, but rather are choosing to retain backward compatibility with Python 2. Moreover, Python developers are confining themselves to a language subset, governed by the diminishing intersection of Python 2, which is not under development, and Python 3, which is under development with new features being introduced as the language continues to evolve.}
}

@article{Majumder2019,
  author = {Suvodeep Majumder and Joymallya Chakraborty and Amritanshu Agrawal and Tim Menzies},
  title = {Why Software Projects need Heroes: Lessons Learned from 1100+ Projects},
  journal = {arxiv.org},
  volume = {abs/1904.09954},
  year = {2019},
  url = {http://arxiv.org/abs/1904.09954},
  eprint = {1904.09954},
  abstract = {A "hero" project is one where 80\% or more of the contributions are made by the 20\% of the developers. Those developers are called "hero" developers. In the literature, heroes projects are deprecated since they might cause bottlenecks in development and communication. However, there is little empirical evidence on this matter. Further, recent studies show that such hero projects are very prevalent. Accordingly, this paper explores the effect of having heroes in project, from a code quality perspective by analyzing 1000+ open source GitHub projects. Based on the analysis, this study finds that (a) majority of the projects are hero projects; and (b)the commits from "hero developers" (who contribute most to the code) result in far fewer bugs than other developers. That is, contrary to the literature, heroes are standard and very useful part of modern open source projects.}
}

@article{Mangano2015,
  doi = {10.1109/tse.2014.2362924},
  url = {https://doi.org/10.1109/tse.2014.2362924},
  year = {2015},
  month = feb,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {41},
  number = {2},
  pages = {135--156},
  author = {Nicolas Mangano and Thomas D. LaToza and Marian Petre and Andre van der Hoek},
  title = {How Software Designers Interact with Sketches at the Whiteboard},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Whiteboard sketches play a crucial role in software development, helping to support groups of designers in reasoning about a software design problem at hand. However, little is known about these sketches and how they support design `in the moment', particularly in terms of the relationships among sketches, visual syntactic elements within sketches, and reasoning activities. To address this gap, we analyzed 14 hours of design activity by eight pairs of professional software designers, manually coding over 4000 events capturing the introduction of visual syntactic elements into sketches, focus transitions between sketches, and reasoning activities. Our findings indicate that sketches serve as a rich medium for supporting design conversations. Designers often use general-purpose notations. Designers introduce new syntactic elements to record aspects of the design, or re-purpose sketches as the design develops. Designers constantly shift focus between sketches, using groups of sketches together that contain complementary information. Finally, sketches play an important role in supporting several types of reasoning activities (mental simulation, review of progress, consideration of alternatives). But these activities often leave no trace and rarely lead to sketch creation. We discuss the implications of these and other findings for the practice of software design at the whiteboard and for the creation of new electronic software design sketching tools.}
}

@article{May2019,
  doi = {10.1007/s10664-019-09685-x},
  url = {https://doi.org/10.1007/s10664-019-09685-x},
  year = {2019},
  month = feb,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {24},
  number = {4},
  pages = {1997--2019},
  author = {Anna May and Johannes Wachs and Anik{\'{o}} Hann{\'{a}}k},
  title = {Gender differences in participation and reward on Stack Overflow},
  journal = {Empirical Software Engineering},
  abstract = {Programming is a valuable skill in the labor market, making the underrepresentation of women in computing an increasingly important issue. Online question and answer platforms serve a dual purpose in this field: they form a body of knowledge useful as a reference and learning tool, and they provide opportunities for individuals to demonstrate credible, verifiable expertise. Issues, such as male-oriented site design or overrepresentation of men among the site's elite may therefore compound the issue of women's underrepresentation in IT. In this paper we audit the differences in behavior and outcomes between men and women on Stack Overflow, the most popular of these Q\&A sites. We observe significant differences in how men and women participate in the platform and how successful they are. For example, the average woman has roughly half of the reputation points, the primary measure of success on the site, of the average man. Using an Oaxaca-Blinder decomposition, an econometric technique commonly applied to analyze differences in wages between groups, we find that most of the gap in success between men and women can be explained by differences in their activity on the site and differences in how these activities are rewarded. Specifically, 1) men give more answers than women and 2) are rewarded more for their answers on average, even when controlling for possible confounders such as tenure or buy-in to the site. Women ask more questions and gain more reward per question. We conclude with a hypothetical redesign of the site's scoring system based on these behavioral differences, cutting the reputation gap in half.}
}

@inproceedings{Melo2019,
  doi = {10.1109/saner.2019.8668001},
  url = {https://doi.org/10.1109/saner.2019.8668001},
  year = {2019},
  month = feb,
  publisher = {{IEEE}},
  author = {Hugo Melo and Roberta Coelho and Christoph Treude},
  title = {Unveiling Exception Handling Guidelines Adopted by Java Developers},
  booktitle = {2019 {IEEE} 26th International Conference on Software Analysis, Evolution and Reengineering ({SANER})},
  abstract = {Despite being an old language feature, Java exception handling code is one of the least understood parts of many systems. Several studies have analyzed the characteristics of exception handling code, trying to identify common practices or even link such practices to software bugs. Few works, however, have investigated exception handling issues from the point of view of developers. None of the works have focused on discovering exception handling guidelines adopted by current systems  which are likely to be a driver of common practices. In this work, we conducted a qualitative study based on semi-structured interviews and a survey whose goal was to investigate the guidelines that are (or should be) followed by developers in their projects. Initially, we conducted semi-structured interviews with seven experienced developers, which were used to inform the design of a survey targeting a broader group of Java developers (i.e., a group of active Java developers from top-starred projects on GitHub). We emailed 863 developers and received 98 valid answers. The study shows that exception handling guidelines usually exist (70\%) and are usually implicit and undocumented (54\%). Our study identifies 48 exception handling guidelines related to seven different categories. We also investigated how such guidelines are disseminated to the project team and how compliance between code and guidelines is verified; we could observe that according to more than half of respondents the guidelines are both disseminated and verified through code inspection or code review. Our findings provide software development teams with a means to improve exception handling guidelines based on insights from the state of practice of 87 software projects.}
}

@article{Meyer2021,
  doi = {10.1109/tse.2019.2904957},
  url = {https://doi.org/10.1109/tse.2019.2904957},
  year = {2021},
  month = may,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {5},
  pages = {863--880},
  author = {Andre N. Meyer and Earl T. Barr and Christian Bird and Thomas Zimmermann},
  title = {Today Was a Good Day: The Daily Life of Software Developers},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {What is a good workday for a software developer? What is a typical workday? We seek to answer these two questions to learn how to make good days typical. Concretely, answering these questions will help to optimize development processes and select tools that increase job satisfaction and productivity. Our work adds to a large body of research on how software developers spend their time. We report the results from 5,971 responses of professional developers at Microsoft, who reflected about what made their workdays good and typical, and self-reported about how they spent their time on various activities at work. We developed conceptual frameworks to help define and characterize developer workdays from two new perspectives: good and typical. Our analysis confirms some findings in previous work, including the fact that developers actually spend little time on development and developers' aversion for meetings and interruptions. It also discovered new findings, such as that only 1.7 percent of survey responses mentioned emails as a reason for a bad workday, and that meetings and interruptions are only unproductive during development phases; during phases of planning, specification and release, they are common and constructive. One key finding is the importance of agency, developers' control over their workday and whether it goes as planned or is disrupted by external factors. We present actionable recommendations for researchers and managers to prioritize process and tool improvements that make good workdays typical. For instance, in light of our finding on the importance of agency, we recommend that, where possible, managers empower developers to choose their tools and tasks.}
}

@article{Miller2020,
  doi = {10.1109/tse.2020.3047766},
  url = {https://doi.org/10.1109/tse.2020.3047766},
  year = {2020},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  pages = {1--1},
  author = {Barton Miller and Mengxiao Zhang and Elisa Heymann},
  title = {The Relevance of Classic Fuzz Testing: Have We Solved This One?},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {As fuzz testing has passed its 30th anniversary, and in the face of the incredible progress in fuzz testing techniques and tools, the question arises if the classic, basic fuzz technique is still useful and applicable? In that tradition, we have updated the basic fuzz tools and testing scripts and applied them to a large collection of Unix utilities on Linux, FreeBSD, and MacOS. As before, our failure criteria was whether the program crashed or hung. We found that 9 crash or hang out of 74 utilities on Linux, 15 out of 78 utilities on FreeBSD, and 12 out of 76 utilities on MacOS. A total of 24 different utilities failed across the three platforms. We note that these failure rates are somewhat higher than our in previous 1995, 2000, and 2006 studies of the reliability of command line utilities. In the basic fuzz tradition, we debugged each failed utility and categorized the causes the failures. Classic categories of failures, such as pointer and array errors and not checking return codes, were still broadly present in the current results. In addition, we found a couple of new categories of failures appearing. We present examples of these failures to illustrate the programming practices that allowed them to happen. As a side note, we tested the limited number of utilities available in a modern programming language (Rust) and found them to be of no better reliability than the standard ones.}
}

@inproceedings{Mitropoulos2019,
  doi = {10.1109/msr.2019.00029},
  url = {https://doi.org/10.1109/msr.2019.00029},
  year = {2019},
  month = may,
  publisher = {{IEEE}},
  author = {Dimitris Mitropoulos and Panos Louridas and Vitalis Salis and Diomidis Spinellis},
  title = {Time Present and Time Past: Analyzing the Evolution of {JavaScript} Code in the Wild},
  booktitle = {2019 {IEEE}/{ACM} 16th International Conference on Mining Software Repositories ({MSR})},
  abstract = {JavaScript is one of the web's key building blocks. It is used by the majority of web sites and it is supported by all modern browsers. We present the first large-scale study of client-side JavaScript code over time. Specifically, we have collected and analyzed a dataset containing daily snapshots of JavaScript code coming from Alexa's Top 10000 web sites (~7.5 GB per day) for nine consecutive months, to study different temporal aspects of web client code. We found that scripts change often; typically every few days, indicating a rapid pace in web applications development. We also found that the lifetime of web sites themselves, measured as the time between JavaScript changes, is also short, in the same time scale. We then performed a qualitative analysis to investigate the nature of the changes that take place. We found that apart from standard changes such as the introduction of new functions, many changes are related to online configuration management. In addition, we examined JavaScript code reuse over time and especially the widespread reliance on third-party libraries. Furthermore, we observed how quality issues evolve by employing established static analysis tools to identify potential software bugs, whose evolution we tracked over time. Our results show that quality issues seem to persist over time, while vulnerable libraries tend to decrease.}
}

@article{Mo2021,
  doi = {10.1109/tse.2019.2910856},
  url = {https://doi.org/10.1109/tse.2019.2910856},
  year = {2021},
  month = may,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {5},
  pages = {1008--1028},
  author = {Ran Mo and Yuanfang Cai and Rick Kazman and Lu Xiao and Qiong Feng},
  title = {Architecture Anti-Patterns: Automatically Detectable Violations of Design Principles},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {In large-scale software systems, error-prone or change-prone files rarely stand alone. They are typically architecturally connected and their connections usually exhibit architecture problems causing the propagation of error-proneness or change-proneness. In this paper, we propose and empirically validate a suite of architecture anti-patterns that occur in all large-scale software systems and are involved in high maintenance costs. We define these architecture anti-patterns based on fundamental design principles and Baldwin and Clark's design rule theory. We can automatically detect these anti-patterns by analyzing a project's structural relationships and revision history. Through our analyses of 19 large-scale software projects, we demonstrate that these architecture anti-patterns have significant impact on files' bug-proneness and change-proneness. In particular, we show that 1) files involved in these architecture anti-patterns are more error-prone and change-prone; 2) the more anti-patterns a file is involved in, the more error-prone and change-prone it is; and 3) while all of our defined architecture anti-patterns contribute to file's error-proneness and change-proneness, Unstable Interface and Crossing contribute the most by far.}
}

@article{Mokhov2018,
  doi = {10.1145/3236774},
  url = {https://doi.org/10.1145/3236774},
  year = {2018},
  month = jul,
  publisher = {Association for Computing Machinery ({ACM})},
  volume = {2},
  number = {{ICFP}},
  pages = {1--29},
  author = {Andrey Mokhov and Neil Mitchell and Simon Peyton Jones},
  title = {Build systems {\`{a}} la carte},
  journal = {Proceedings of the {ACM} on Programming Languages},
  abstract = {Build systems are awesome, terrifying---and unloved. They are used by every developer around the world, but are rarely the object of study. In this paper we offer a systematic, and executable, framework for developing and comparing build systems, viewing them as related points in landscape rather than as isolated phenomena. By teasing apart existing build systems, we can recombine their components, allowing us to prototype new build systems with desired properties.}
}

@inproceedings{Moldon2021,
  doi = {10.1109/icse43902.2021.00058},
  url = {https://doi.org/10.1109/icse43902.2021.00058},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Lukas Moldon and Markus Strohmaier and Johannes Wachs},
  title = {How Gamification Affects Software Developers: Cautionary Evidence from a Natural Experiment on {GitHub}},
  booktitle = {2021 {IEEE}/{ACM} 43rd International Conference on Software Engineering ({ICSE})},
  abstract = {We examine how the behavior of software developers changes in response to removing gamification elements from GitHub, an online platform for collaborative programming and software development. We find that the unannounced removal of daily activity streak counters from the user interface (from user profile pages) was followed by significant changes in behavior. Long-running streaks of activity were abandoned and became less common. Weekend activity decreased and days in which developers made a single contribution became less common. Synchronization of streaking behavior in the platform's social network also decreased, suggesting that gamification is a powerful channel for social influence. Focusing on a set of software developers that were publicly pursuing a goal to make contributions for 100 days in a row, we find that some of these developers abandon this quest following the removal of the public streak counter. Our findings provide evidence for the significant impact of gamification on the behavior of developers on large collaborative programming and software development platforms. They urge caution: gamification can steer the behavior of software developers in unexpected and unwanted directions.}
}

@article{Moraes2021,
  doi = {10.1007/s10664-020-09936-2},
  url = {https://doi.org/10.1007/s10664-020-09936-2},
  year = {2021},
  month = mar,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {3},
  author = {Jo{\~{a}}o Pedro Moraes and Ivanilton Polato and Igor Wiese and Filipe Saraiva and Gustavo Pinto},
  title = {From one to hundreds: multi-licensing in the {JavaScript} ecosystem},
  journal = {Empirical Software Engineering},
  abstract = {Open source licenses create a legal framework that plays a crucial role in the widespread adoption of open source projects. Without a license, any source code available on the internet could not be openly (re)distributed. Although recent studies provide evidence that most popular open source projects have a license, developers might lack confidence or expertise when they need to combine software licenses, leading to a mistaken project license unification.This license usage is challenged by the high degree of reuse that occurs in the heart of modern software development practices, in which third-party libraries and frameworks are easily and quickly integrated into a software codebase.This scenario creates what we call \"multi-licensed\" projects, which happens when one project has components that are licensed under more than one license. Although these components exist at the file-level, they naturally impact licensing decisions at the project-level. In this paper, we conducted a mix-method study to shed some light on these questions. We started by parsing 1,426,263 (source code and non-source code) files available on 1,552 JavaScript projects, looking for license information. Among these projects, we observed that 947 projects (61\%) employ more than one license. On average, there are 4.7 licenses per studied project (max: 256). Among the reasons for multi-licensing is to incorporate the source code of third-party libraries into the project's codebase. When doing so, we observed that 373 of the multi-licensed projects introduced at least one license incompatibility issue. We also surveyed with 83 maintainers of these projects aimed to cross-validate our findings. We observed that 63\% of the surveyed maintainers are not aware of the multi-licensing implications. For those that are aware, they adopt multiple licenses mostly to conform with third-party libraries' licenses.}
}

@article{MoreiraSoares2020,
  doi = {10.1002/spe.2946},
  url = {https://doi.org/10.1002/spe.2946},
  year = {2020},
  month = dec,
  publisher = {Wiley},
  volume = {51},
  number = {6},
  pages = {1173--1193},
  author = {Daric{\'{e}}lio {Moreira Soares} and Manoel Limeira Lima J{\'{u}}nior and Leonardo Murta and Alexandre Plastino},
  title = {What factors influence the lifetime of pull requests?},
  journal = {Software: Practice and Experience},
  abstract = {When external contributors want to collaborate with an open-source project, they fork the repository, make changes, and send a pull request to the core team. However, the lifetime of a pull request, defined by the time interval between its opening and its closing, has a high variation, potentially affecting the contributor engagement. In this context, understanding the root causes of pull request lifetime is important to both the external contributors and the core team. The former can adopt strategies that increase the chances of fast review, while the latter can establish priorities in the reviewing process, alleviating the pending tasks and improving the software quality. In this work, we mined association rules from 97,463 pull requests from 30 projects in order to find characteristics that have affected the pull requests lifetime. In addition, we present a qualitative analysis, helping to understand the patterns discovered from the association rules. The results indicate that: (i) contributions with shorter lifetimes tend to be accepted; (ii) structural characteristics, such as number of commits, changed files, and lines of code, have influence, in an isolated or combined way, on the pull request lifetime; (iii) the files changed and the directories to which they belong can be robust predictors for pull request lifetime; (iv) the profile of external contributors and their social relationships have influence on lifetime; and (v) the number of comments in a pull request, as well as the developer responsible for the review, are important predictors for its lifetime.}
}

@article{MurphyHill2021,
  doi = {10.1109/tse.2019.2900308},
  url = {https://doi.org/10.1109/tse.2019.2900308},
  year = {2021},
  month = mar,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {3},
  pages = {582--594},
  author = {Emerson Murphy-Hill and Ciera Jaspan and Caitlin Sadowski and David Shepherd and Michael Phillips and Collin Winter and Andrea Knight and Edward Smith and Matthew Jorde},
  title = {What Predicts Software Developers' Productivity?},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Organizations have a variety of options to help their software developers become their most productive selves, from modifying office layouts, to investing in better tools, to cleaning up the source code. But which options will have the biggest impact? Drawing from the literature in software engineering and industrial/organizational psychology to identify factors that correlate with productivity, we designed a survey that asked 622 developers across 3 companies about these productivity factors and about self-rated productivity. Our results suggest that the factors that most strongly correlate with self-rated productivity were non-technical factors, such as job enthusiasm, peer support for new ideas, and receiving useful feedback about job performance. Compared to other knowledge workers, our results also suggest that software developers' self-rated productivity is more strongly related to task variety and ability to work remotely.}
}

@comment{NNN}

@article{NguyenDuc2021,
  doi = {10.1007/s10664-021-09987-z},
  url = {https://doi.org/10.1007/s10664-021-09987-z},
  year = {2021},
  month = jul,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {5},
  author = {Anh Nguyen-Duc and Kai-Kristian Kemell and Pekka Abrahamsson},
  title = {The entrepreneurial logic of startup software development: A study of 40 software startups},
  journal = {Empirical Software Engineering},
  abstract = {Context: Software startups are an essential source of innovation and software-intensive products. The need to understand product development in startups and to provide relevant support are highlighted in software research. While state-of-the-art literature reveals how startups develop their software, the reasons why they adopt these activities are underexplored. Objective: This study investigates the tactics behind software engineering (SE) activities by analyzing key engineering events during startup journeys. We explore how entrepreneurial mindsets may be associated with SE knowledge areas and with each startup case. Method: Our theoretical foundation is based on causation and effectuation models. We conducted semi-structured interviews with 40 software startups. We used two-round open coding and thematic analysis to describe and identify entrepreneurial software development patterns. Additionally, we calculated an effectuation index for each startup case. Results: We identified 621 events merged into 32 codes of entrepreneurial logic in SE from the sample. We found a systemic occurrence of the logic in all areas of SE activities. Minimum Viable Product (MVP), Technical Debt (TD), and Customer Involvement (CI) tend to be associated with effectual logic, while testing activities at different levels are associated with causal logic. The effectuation index revealed that startups are either effectuation-driven or mixed-logics-driven. Conclusions: Software startups fall into two types that differentiate between how traditional SE approaches may apply to them. Effectuation seems the most relevant and essential model for explaining and developing suitable SE practices for software startups.}
}

@article{Nielebock2018,
  doi = {10.1007/s10664-018-9664-z},
  url = {https://doi.org/10.1007/s10664-018-9664-z},
  year = {2018},
  month = nov,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {24},
  number = {3},
  pages = {1418--1457},
  author = {Sebastian Nielebock and Dariusz Krolikowski and Jacob Kr\"{u}ger and Thomas Leich and Frank Ortmeier},
  title = {Commenting source code: is it worth it for small programming tasks?},
  journal = {Empirical Software Engineering},
  abstract = {Maintaining a program is a time-consuming and expensive task in software engineering. Consequently, several approaches have been proposed to improve the comprehensibility of source code. One of such approaches are comments in the code that enable developers to explain the program with their own words or predefined tags. Some empirical studies indicate benefits of comments in certain situations, while others find no benefits at all. Thus, the real effect of comments on software development remains uncertain. In this article, we describe an experiment in which 277 participants, mainly professional software developers, performed small programming tasks on differently commented code. Based on quantitative and qualitative feedback, we i) partly replicate previous studies, ii) investigate performances of differently experienced participants when confronted with varying types of comments, and iii) discuss the opinions of developers on comments. Our results indicate that comments seem to be considered more important in previous studies and by our participants than they are for small programming tasks. While other mechanisms, such as proper identifiers, are considered more helpful by our participants, they also emphasize the necessity of comments in certain situations.}
}

@comment{OOO}

@article{Olsson2021,
  doi = {10.1007/s10664-021-09998-w},
  url = {https://doi.org/10.1007/s10664-021-09998-w},
  year = {2021},
  month = jul,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {5},
  author = {Jesper Olsson and Erik Risfelt and Terese Besker and Antonio Martini and Richard Torkar},
  title = {Measuring affective states from technical debt},
  journal = {Empirical Software Engineering},
  abstract = {Context: Software engineering is a human activity. Despite this, human aspects are under-represented in technical debt research, perhaps because they are challenging to evaluate. Objective: This study's objective was to investigate the relationship between technical debt and affective states (feelings, emotions, and moods) from software practitioners. Method: Forty participants (N=40) from twelve companies took part in a mixed-methods approach, consisting of a repeated-measures (r=5) experiment (n=200), a survey, and semi-structured interviews. From the qualitative data, it is clear that technical debt activates a substantial portion of the emotional spectrum and is psychologically taxing. Further, the practitioners' reactions to technical debt appear to fall in different levels of maturity. Results: The statistical analysis shows that different design smells (strong indicators of technical debt) negatively or positively impact affective states. Conclusions: We argue that human aspects in technical debt are important factors to consider, as they may result in, e.g., procrastination, apprehension, and burnout.}
}

@inproceedings{Overney2020,
  doi = {10.1145/3377811.3380410},
  url = {https://doi.org/10.1145/3377811.3380410},
  year = {2020},
  month = jun,
  publisher = {{ACM}},
  author = {Cassandra Overney and Jens Meinicke and Christian K\"{a}stner and Bogdan Vasilescu},
  title = {How to not get rich: an empirical study of donations in open source},
  booktitle = {Proceedings of the {ACM}/{IEEE} 42nd International Conference on Software Engineering},
  abstract = {Open source is ubiquitous and many projects act as critical infrastructure, yet funding and sustaining the whole ecosystem is challenging. While there are many different funding models for open source and concerted efforts through foundations, donation platforms like PayPal, Patreon, and OpenCollective are popular and low-bar platforms to raise funds for open-source development. With a mixed-method study, we investigate the emerging and largely unexplored phenomenon of donations in open source. Specifically, we quantify how commonly open-source projects ask for donations, statistically model characteristics of projects that ask for and receive donations, analyze for what the requested funds are needed and used, and assess whether the received donations achieve the intended outcomes. We find 25,885 projects asking for donations on GitHub, often to support engineering activities; however, we also find no clear evidence that donations influence the activity level of a project. In fact, we find that donations are used in a multitude of ways, raising new research questions about effective funding.}
}

@comment{PPP}

@article{Palomba2021,
  doi = {10.1109/tse.2018.2883603},
  url = {https://doi.org/10.1109/tse.2018.2883603},
  year = {2021},
  month = jan,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {1},
  pages = {108--129},
  author = {Fabio Palomba and Damian Andrew Tamburri and Francesca Arcelli Fontana and Rocco Oliveto and Andy Zaidman and Alexander Serebrenik},
  title = {Beyond Technical Aspects: How Do Community Smells Influence the Intensity of Code Smells?},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Code smells are poor implementation choices applied by developers during software evolution that often lead to critical flaws or failure. Much in the same way, community smells reflect the presence of organizational and socio-technical issues within a software community that may lead to additional project costs. Recent empirical studies provide evidence that community smells are often---if not always---connected to circumstances such as code smells. In this paper we look deeper into this connection by conducting a mixed-methods empirical study of 117 releases from 9 open-source systems. The qualitative and quantitative sides of our mixed-methods study were run in parallel and assume a mutually-confirmative connotation. On the one hand, we survey 162 developers of the 9 considered systems to investigate whether developers perceive relationship between community smells and the code smells found in those projects. On the other hand, we perform a fine-grained analysis into the 117 releases of our dataset to measure the extent to which community smells impact code smell intensity (i.e., criticality). We then propose a code smell intensity prediction model that relies on both technical and community-related aspects. The results of both sides of our mixed-methods study lead to one conclusion: community-related factors contribute to the intensity of code smells. This conclusion supports the joint use of community and code smells detection as a mechanism for the joint management of technical and social problems around software development communities.}
}

@article{Paltoglou2021,
  doi = {10.1016/j.jss.2021.111049},
  url = {https://doi.org/10.1016/j.jss.2021.111049},
  year = {2021},
  month = nov,
  publisher = {Elsevier {BV}},
  volume = {181},
  pages = {111049},
  author = {Katerina Paltoglou and Vassilis E. Zafeiris and N.A. Diamantidis and E.A. Giakoumakis},
  title = {Automated refactoring of legacy {JavaScript} code to {ES}6 modules},
  journal = {Journal of Systems and Software},
  abstract = {The JavaScript language did not specify, until ECMAScript 6 (ES6), native features for streamlining encapsulation and modularity. Developer community filled the gap with a proliferation of design patterns and module formats, with impact on code reusability, portability and complexity of build configurations. This work studies the automated refactoring of legacy ES5 code to ES6 modules with fine-grained reuse of module contents through the named import/export language constructs. The focus is on reducing the coupling of refactored modules through destructuring exported module objects to fine-grained module features and enhancing module dependencies by leveraging the ES6 syntax. We employ static analysis to construct a model of a JavaScript project, the Module Dependence Graph (MDG), that represents modules and their dependencies. On the basis of MDG we specify the refactoring procedure for module migration to ES6. A prototype implementation has been empirically evaluated on 19 open source projects. Results highlight the relevance of the refactoring with a developer intent for fine-grained reuse. The analysis of refactored code shows an increase in the number of reusable elements per project and reduction in the coupling of refactored modules. The soundness of the refactoring is empirically validated through code inspection and execution of projects' test suites.}
}

@article{Passos2021,
  doi = {10.1109/tse.2018.2884911},
  url = {https://doi.org/10.1109/tse.2018.2884911},
  year = {2021},
  month = jan,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {1},
  pages = {146--164},
  author = {Leonardo Passos and Rodrigo Queiroz and Mukelabai Mukelabai and Thorsten Berger and Sven Apel and Krzysztof Czarnecki and Jesus Alejandro Padilla},
  title = {A Study of Feature Scattering in the Linux Kernel},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Feature code is often scattered across a software system. Scattering is not necessarily bad if used with care, as witnessed by systems with highly scattered features that evolved successfully. Feature scattering, often realized with a pre-processor, circumvents limitations of programming languages and software architectures. Unfortunately, little is known about the principles governing scattering in large and long-living software systems. We present a longitudinal study of feature scattering in the Linux kernel, complemented by a survey with 74, and interviews with nine Linux kernel developers. We analyzed almost eight years of the kernel's history, focusing on its largest subsystem: device drivers. We learned that the ratio of scattered features remained nearly constant and that most features were introduced without scattering. Yet, scattering easily crosses subsystem boundaries, and highly scattered outliers exist. Scattering often addresses a performance-maintenance tradeoff (alleviating complicated APIs), hardware design limitations, and avoids code duplication. While developers do not consciously enforce scattering limits, they actually improve the system design and refactor code, thereby mitigating pre-processor idiosyncrasies or reducing its use.}
}

@inproceedings{Peitek2021,
  doi = {10.1109/icse43902.2021.00056},
  url = {https://doi.org/10.1109/icse43902.2021.00056},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Norman Peitek and Sven Apel and Chris Parnin and Andre Brechmann and Janet Siegmund},
  title = {Program Comprehension and Code Complexity Metrics: An {fMRI} Study},
  booktitle = {2021 {IEEE}/{ACM} 43rd International Conference on Software Engineering ({ICSE})},
  abstract = {Background: Researchers and practitioners have been using code complexity metrics for decades to predict how developers comprehend a program. While it is plausible and tempting to use code metrics for this purpose, their validity is debated, since they rely on simple code properties and rarely consider particularities of human cognition. Aims: We investigate whether and how code complexity metrics reflect difficulty of program comprehension. Method: We have conducted a functional magnetic resonance imaging (fMRI) study with 19 participants observing program comprehension of short code snippets at varying complexity levels. We dissected four classes of code complexity metrics and their relationship to neuronal, behavioral, and subjective correlates of program comprehension, overall analyzing more than 41 metrics. Results: While our data corroborate that complexity metrics can-to a limited degree-explain programmers' cognition in program comprehension, fMRI allowed us to gain insights into why some code properties are difficult to process. In particular, a code's textual size drives programmers' attention, and vocabulary size burdens programmers' working memory. Conclusion: Our results provide neuro-scientific evidence supporting warnings of prior research questioning the validity of code complexity metrics and pin down factors relevant to program comprehension. Future Work: We outline several follow-up experiments investigating fine-grained effects of code complexity and describe possible refinements to code complexity metrics.}
}

@inproceedings{Peng2021,
  doi = {10.1109/saner50967.2021.00012},
  url = {https://doi.org/10.1109/saner50967.2021.00012},
  year = {2021},
  month = mar,
  publisher = {{IEEE}},
  author = {Yun Peng and Yu Zhang and Mingzhe Hu},
  title = {An Empirical Study for Common Language Features Used in Python Projects},
  booktitle = {2021 {IEEE} International Conference on Software Analysis,  Evolution and Reengineering ({SANER})},
  abstract = {As a dynamic programming language, Python is widely used in many fields. For developers, various language features affect programming experience. For researchers, they affect the difficulty of developing tasks such as bug finding and compilation optimization. Former research has shown that programs with Python dynamic features are more change-prone. However, we know little about the use and impact of Python language features in real-world Python projects. To resolve these issues, we systematically analyze Python language features and propose a tool named PYSCAN to automatically identify the use of 22 kinds of common Python language features in 6 categories in Python source code. We conduct an empirical study on 35 popular Python projects from eight application domains, covering over 4.3 million lines of code, to investigate the the usage of these language features in the project. We find that single inheritance, decorator, keyword argument, for loops and nested classes are top 5 used language features. Meanwhile different domains of projects may prefer some certain language features. For example, projects in DevOps use exception handling frequently. We also conduct in-depth manual analysis to dig extensive using patterns of frequently but differently used language features: exceptions, decorators and nested classes/functions. We find that developers care most about ImportError when handling exceptions. With the empirical results and in-depth analysis, we conclude with some suggestions and a discussion of implications for three groups of persons in Python community: Python designers, Python compiler designers and Python developers.}
}

@article{Pizard2021,
  doi = {10.1007/s10664-021-09953-9},
  url = {https://doi.org/10.1007/s10664-021-09953-9},
  year = {2021},
  month = mar,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {3},
  author = {Sebasti{\'{a}}n Pizard and Fernando Acerenza and Ximena Otegui and Silvana Moreno and Diego Vallespir and Barbara Kitchenham},
  title = {Training students in evidence-based software engineering and systematic reviews: a systematic review and empirical study},
  journal = {Empirical Software Engineering},
  abstract = {Context Although influential in academia, evidence-based software engineering (EBSE) has had little impact on industry practice. We found that other disciplines have identified lack of training as a significant barrier to Evidence-Based Practice. Objective To build and assess an EBSE training proposal suitable for students with more than 3 years of computer science/software engineering university-level training. Method We performed a systematic literature review (SLR) of EBSE teaching initiatives and used the SLR results to help us to develop and evaluate an EBSE training proposal. The course was based on the theory of learning outcomes and incorporated a large practical content related to performing an SLR. We ran the course with 10 students and based course evaluation on student performance and opinions of both students and teachers. We assessed knowledge of EBSE principles from the mid-term and final tests, as well as evaluating the SLRs produced by the student teams. We solicited student opinions about the course and its value via a student survey, a team survey, and a focus group. The teachers' viewpoint was collected in a debriefing meeting. Results Our SLR identified 14 relevant primary studies. The primary studies emphasized the importance of practical examples (usually based on the SLR process) and used a variety of evaluation methods, but lacked any formal education methodology. We identified 54 learning outcomes covering aspects of EBSE and the SLR method. All 10 students passed the course. Our course evaluation showed that a large percentage of the learning outcomes established for training were accomplished. Conclusions The course proved suitable for students to understand the EBSE paradigm and to be able to apply it to a limited-scope practical assignment. Our learning outcomes, course structure, and course evaluation process should help to improve the effectiveness and comparability of future studies of EBSE training. However, future courses should increase EBSE training related to the use of SLR results.}
}

@article{Prana2018,
  doi = {10.1007/s10664-018-9660-3},
  url = {https://doi.org/10.1007/s10664-018-9660-3},
  year = {2018},
  month = oct,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {24},
  number = {3},
  pages = {1296--1327},
  author = {Gede Artha Azriadi Prana and Christoph Treude and Ferdian Thung and Thushari Atapattu and David Lo},
  title = {Categorizing the Content of {GitHub} {README} Files},
  journal = {Empirical Software Engineering},
  abstract = {README files play an essential role in shaping a developer's first impression of a software repository and in documenting the software project that the repository hosts. Yet, we lack a systematic understanding of the content of a typical README file as well as tools that can process these files automatically. To close this gap, we conduct a qualitative study involving the manual annotation of 4,226 README file sections from 393 randomly sampled GitHub repositories and we design and evaluate a classifier and a set of features that can categorize these sections automatically. We find that information discussing the 'What' and 'How' of a repository is very common, while many README files lack information regarding the purpose and status of a repository. Our multi-label classifier which can predict eight different categories achieves an F1 score of 0.746. To evaluate the usefulness of the classification, we used the automatically determined classes to label sections in GitHub README files using badges and showed files with and without these badges to twenty software professionals. The majority of participants perceived the automated labeling of sections based on our classifier to ease information discovery. This work enables the owners of software repositories to improve the quality of their documentation and it has the potential to make it easier for the software development community to discover relevant information in GitHub README files.}
}

@comment{QQQ}

@inproceedings{Qiu2019,
  doi = {10.1109/icse.2019.00078},
  url = {https://doi.org/10.1109/icse.2019.00078},
  year = {2019},
  month = may,
  publisher = {{IEEE}},
  author = {Huilian Sophie Qiu and Alexander Nolte and Anita Brown and Alexander Serebrenik and Bogdan Vasilescu},
  title = {Going Farther Together: The Impact of Social Capital on Sustained Participation in Open Source},
  booktitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering ({ICSE})},
  abstract = {Sustained participation by contributors in opensource software is critical to the survival of open-source projects and can provide career advancement benefits to individual contributors. However, not all contributors reap the benefits of open-source participation fully, with prior work showing that women are particularly underrepresented and at higher risk of disengagement. While many barriers to participation in open-source have been documented in the literature, relatively little is known about how the social networks that open-source contributors form impact their chances of long-term engagement. In this paper we report on a mixed-methods empirical study of the role of social capital (i.e., the resources people can gain from their social connections) for sustained participation by women and men in open-source GitHub projects. After combining survival analysis on a large, longitudinal data set with insights derived from a user survey, we confirm that while social capital is beneficial for prolonged engagement for both genders, women are at disadvantage in teams lacking diversity in expertise.}
}

@comment{RRR}

@article{Ragkhitwetsagul2021,
  doi = {10.1109/tse.2019.2900307},
  url = {https://doi.org/10.1109/tse.2019.2900307},
  year = {2021},
  month = mar,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {3},
  pages = {560--581},
  author = {Chaiyong Ragkhitwetsagul and Jens Krinke and Matheus Paixao and Giuseppe Bianco and Rocco Oliveto},
  title = {Toxic Code Snippets on Stack Overflow},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Online code clones are code fragments that are copied from software projects or online sources to Stack Overflow as examples. Due to an absence of a checking mechanism after the code has been copied to Stack Overflow, they can become toxic code snippets, e.g., they suffer from being outdated or violating the original software license. We present a study of online code clones on Stack Overflow and their toxicity by incorporating two developer surveys and a large-scale code clone detection. A survey of 201 high-reputation Stack Overflow answerers (33 percent response rate) showed that 131 participants (65 percent) have ever been notified of outdated code and 26 of them (20 percent) rarely or never fix the code. 138 answerers (69 percent) never check for licensing conflicts between their copied code snippets and Stack Overflow's CC BY-SA 3.0. A survey of 87 Stack Overflow visitors shows that they experienced several issues from Stack Overflow answers: mismatched solutions, outdated solutions, incorrect solutions, and buggy code. 85 percent of them are not aware of CC BY-SA 3.0 license enforced by Stack Overflow, and 66 percent never check for license conflicts when reusing code snippets. Our clone detection found online clone pairs between 72,365 Java code snippets on Stack Overflow and 111 open source projects in the curated Qualitas corpus. We analysed 2,289 non-trivial online clone candidates. Our investigation revealed strong evidence that 153 clones have been copied from a Qualitas project to Stack Overflow. We found 100 of them (66 percent) to be outdated, of which 10 were buggy and harmful for reuse. Furthermore, we found 214 code snippets that could potentially violate the license of their original software and appear 7,112 times in 2,427 GitHub projects.}
}

@inproceedings{RakAmnouykit2020,
  doi = {10.1145/3426422.3426981},
  url = {https://doi.org/10.1145/3426422.3426981},
  year = {2020},
  month = nov,
  publisher = {{ACM}},
  author = {Ingkarat Rak-amnouykit and Daniel McCrevan and Ana Milanova and Martin Hirzel and Julian Dolby},
  title = {Python 3 types in the wild: a tale of two type systems},
  booktitle = {Proceedings of the 16th {ACM} {SIGPLAN} International Symposium on Dynamic Languages},
  abstract = {Python 3 is a highly dynamic language, but it has introduced a syntax for expressing types with PEP484. This paper ex- plores how developers use these type annotations, the type system semantics provided by type checking and inference tools, and the performance of these tools. We evaluate the types and tools on a corpus of public GitHub repositories. We review MyPy and PyType, two canonical static type checking and inference tools, and their distinct approaches to type analysis. We then address three research questions: (i) How often and in what ways do developers use Python 3 types? (ii) Which type errors do developers make? (iii) How do type errors from different tools compare? Surprisingly, when developers use static types, the code rarely type-checks with either of the tools. MyPy and PyType exhibit false positives, due to their static nature, but also flag many useful errors in our corpus. Lastly, MyPy and PyType embody two distinct type systems, flagging different errors in many cases. Understanding the usage of Python types can help guide tool-builders and researchers. Understanding the performance of popular tools can help increase the adoption of static types and tools by practitioners, ultimately leading to more correct and more robust Python code.}
}

@inproceedings{Rahman2020b,
  doi = {10.1109/icsme46990.2020.00063},
  url = {https://doi.org/10.1109/icsme46990.2020.00063},
  year = {2020},
  month = sep,
  publisher = {{IEEE}},
  author = {Mohammad Masudur Rahman and Foutse Khomh and Marco Castelluccio},
  title = {Why are Some Bugs Non-Reproducible? An Empirical Investigation using Data Fusion},
  booktitle = {2020 {IEEE} International Conference on Software Maintenance and Evolution ({ICSME})},
  abstract = {Software developers attempt to reproduce software bugs to understand their erroneous behaviours and to fix them. Unfortunately, they often fail to reproduce (or fix) them, which leads to faulty, unreliable software systems. However, to date, only a little research has been done to better understand what makes the software bugs non-reproducible. In this paper, we conduct a multimodal study to better understand the non-reproducibility of software bugs. First, we perform an empirical study using 576 non-reproducible bug reports from two popular software systems (Firefox, Eclipse) and identify 11 key factors that might lead a reported bug to non-reproducibility. Second, we conduct a user study involving 13 professional developers where we investigate how the developers cope with non-reproducible bugs. We found that they either close these bugs or solicit for further information, which involves long deliberations and counter-productive manual searches. Third, we offer several actionable insights on how to avoid non-reproducibility (e.g., false-positive bug report detector) and improve reproducibility of the reported bugs (e.g., sandbox for bug reproduction) by combining our analyses from multiple studies (e.g., empirical study, developer study).}
}

@inproceedings{Reyes2018,
  doi = {10.1145/3180155.3180161},
  url = {https://doi.org/10.1145/3180155.3180161},
  year = {2018},
  month = may,
  publisher = {{ACM}},
  author = {Rolando P. Reyes and Oscar Dieste and Efra{\'{\i}}n R. Fonseca and Natalia Juristo},
  title = {Statistical errors in software engineering experiments},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  abstract = {Background: Statistical concepts and techniques are often applied incorrectly, even in mature disciplines such as medicine or psychology. Surprisingly, there are very few works that study statistical problems in software engineering (SE). Aim: Assess the existence of statistical errors in SE experiments. Method: Compile the most common statistical errors in experimental disciplines. Survey experiments published in ICSE to assess whether errors occur in high quality SE publications. Results: The same errors as identified in others disciplines were found in ICSE experiments, where 30 of the reviewed papers included several error types such as: a) missing statistical hypotheses, b) missing sample size calculation, c) failure to assess statistical test assumptions, and d) uncorrected multiple testing. This rather large error rate is greater for research papers where experiments are confined to the validation section. The origin of the errors can be traced back to: a) researchers not having sufficient statistical training, and b) a profusion of exploratory research. Conclusions: This paper provides preliminary evidence that SE research suffers from the same statistical problems as other experimental disciplines. However, the SE community appears to be unaware of any shortcomings in its experiments, whereas other disciplines work hard to avoid these threats. Further research is necessary to find the underlying causes and set up corrective measures, but there are some potentially effective actions and are a priori easy to implement: a) improve the statistical training of SE researchers, and b) enforce quality assessment and reporting guidelines in SE publications.}
}

@article{Rico2021,
  doi = {10.1002/smr.2372},
  url = {https://doi.org/10.1002/smr.2372},
  year = {2021},
  month = jul,
  publisher = {Wiley},
  author = {Sergio Rico and Elizabeth Bjarnason and Emelie Engstr\"{o}m and Martin H\"{o}st and Per Runeson},
  title = {A case study of industry{\textendash}academia communication in a joint software engineering research project},
  journal = {Journal of Software: Evolution and Process},
  abstract = {Empirical software engineering research relies on good communication with industrial partners. Conducting joint research both requires and contributes to bridging the communication gap between industry and academia (IA) in software engineering. This study aims to explore communication between the two parties in such a setting. To better understand what facilitates good IA communication and what project outcomes such communication promotes, we performed a case study, in the context of a long-term IA joint project, followed by a validating survey among practitioners and researchers with experience of working in similar settings. We identified five facilitators of IA communication and nine project outcomes related to this communication. The facilitators concern the relevance of the research, practitioners' attitude and involvement in research, frequency of communication and longevity of the collaboration. The project outcomes promoted by this communication include, for researchers, changes in teaching and new scientific venues, and for practitioners, increased awareness, changes to practice, and new tools and source code. Besides, both parties gain new knowledge and develop social-networks through IA communication. Our study presents empirically based insights that can provide advise on how to improve communication in IA research projects and thus the co-creation of software engineering knowledge that is anchored in both practice and research.}
}

@article{Rigger2020,
  doi = {10.1145/3428279},
  url = {https://doi.org/10.1145/3428279},
  year = {2020},
  month = nov,
  publisher = {Association for Computing Machinery ({ACM})},
  volume = {4},
  number = {{OOPSLA}},
  pages = {1--30},
  author = {Manuel Rigger and Zhendong Su},
  title = {Finding bugs in database systems via query partitioning},
  journal = {Proceedings of the {ACM} on Programming Languages},
  abstract = {Logic bugs in Database Management Systems (DBMSs) are bugs that cause an incorrect result for a given query, for example, by omitting a row that should be fetched. These bugs are critical, since they are likely to go unnoticed by users. We propose Query Partitioning, a general and effective approach for finding logic bugs in DBMSs. The core idea of Query Partitioning is to, starting from a given original query, derive multiple, more complex queries (called partitioning queries), each of which computes a partition of the result. The individual partitions are then composed to compute a result set that must be equivalent to the original query's result set. A bug in the DBMS is detected when these result sets differ. Our intuition is that due to the increased complexity, the partitioning queries are more likely to stress the DBMS and trigger a logic bug than the original query. As a concrete instance of a partitioning strategy, we propose Ternary Logic Partitioning (TLP), which is based on the observation that a boolean predicate p can either evaluate to TRUE, FALSE, or NULL. Accordingly, a query can be decomposed into three partitioning queries, each of which computes its result on rows or intermediate results for which p, NOT p, and p IS NULL hold. This technique is versatile, and can be used to test WHERE, GROUP BY, as well as HAVING clauses, aggregate functions, and DISTINCT queries. As part of an extensive testing campaign, we found 175 bugs in widely-used DBMSs such as MySQL, TiDB, SQLite, and CockroachDB, 125 of which have been fixed. Notably, 77 of these were logic bugs, while the remaining were error and crash bugs. We expect that the effectiveness and wide applicability of Query Partitioning will lead to its broad adoption in practice, and the formulation of additional partitioning strategies.}
}

@article{RodrguezPrez2018,
  doi = {10.1016/j.infsof.2018.03.009},
  url = {https://doi.org/10.1016/j.infsof.2018.03.009},
  year = {2018},
  month = jul,
  publisher = {Elsevier {BV}},
  volume = {99},
  pages = {164--176},
  author = {Gema Rodr{\'{\i}}guez-P{\'{e}}rez and Gregorio Robles and Jes{\'{u}}s M. Gonz{\'{a}}lez-Barahona},
  title = {Reproducibility and credibility in empirical software engineering: A case study based on a systematic literature review of the use of the {SZZ} algorithm},
  journal = {Information and Software Technology},
  abstract = {When identifying the origin of software bugs, many studies assume that "a bug was introduced by the lines of code that were modified to fix it". However, this assumption does not always hold and at least in some cases, these modified lines are not responsible for introducing the bug. For example, when the bug was caused by a change in an external API. The lack of empirical evidence makes it impossible to assess how important these cases are and therefore, to which extent the assumption is valid. To advance in this direction, and better understand how bugs "are born", we propose a model for defining criteria to identify the first snapshot of an evolving software system that exhibits a bug. This model, based on the perfect test idea, decides whether a bug is observed after a change to the software. Furthermore, we studied the model's criteria by carefully analyzing how 116 bugs were introduced in two different open source software projects. The manual analysis helped classify the root cause of those bugs and created manually curated datasets with bug-introducing changes and with bugs that were not introduced by any change in the source code. Finally, we used these datasets to evaluate the performance of four existing SZZ-based algorithms for detecting bug-introducing changes. We found that SZZ-based algorithms are not very accurate, especially when multiple commits are found; the F-Score varies from 0.44 to 0.77, while the percentage of true positives does not exceed 63\%. Our results show empirical evidence that the prevalent assumption, "a bug was introduced by the lines of code that were modified to fix it", is just one case of how bugs are introduced in a software system. Finding what introduced a bug is not trivial: bugs can be introduced by the developers and be in the code, or be created irrespective of the code. Thus, further research towards a better understanding of the origin of bugs in software projects could help to improve design integration tests and to design other procedures to make software development more robust.}
}

@article{RodriguezPerez2020,
  doi = {10.1007/s10664-019-09781-y},
  url = {https://doi.org/10.1007/s10664-019-09781-y},
  year = {2020},
  month = feb,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {25},
  number = {2},
  pages = {1294--1340},
  author = {Gema Rodr{\'{\i}}guez-P{\'{e}}rez and Gregorio Robles and Alexander Serebrenik and Andy Zaidman and Daniel M. Germ{\'{a}}n and Jesus M. Gonzalez-Barahona},
  title = {How bugs are born: a model to identify how bugs are introduced in software components},
  journal = {Empirical Software Engineering},
  abstract = {When identifying the origin of software bugs, many studies assume that "a bug was introduced by the lines of code that were modified to fix it". However, this assumption does not always hold and at least in some cases, these modified lines are not responsible for introducing the bug. For example, when the bug was caused by a change in an external API. The lack of empirical evidence makes it impossible to assess how important these cases are and therefore, to which extent the assumption is valid. To advance in this direction, and better understand how bugs "are born", we propose a model for defining criteria to identify the first snapshot of an evolving software system that exhibits a bug. This model, based on the perfect test idea, decides whether a bug is observed after a change to the software. Furthermore, we studied the model's criteria by carefully analyzing how 116 bugs were introduced in two different open source software projects. The manual analysis helped classify the root cause of those bugs and created manually curated datasets with bug-introducing changes and with bugs that were not introduced by any change in the source code. Finally, we used these datasets to evaluate the performance of four existing SZZ-based algorithms for detecting bug-introducing changes. We found that SZZ-based algorithms are not very accurate, especially when multiple commits are found; the F-Score varies from 0.44 to 0.77, while the percentage of true positives does not exceed 63\%. Our results show empirical evidence that the prevalent assumption, "a bug was introduced by the lines of code that were modified to fix it", is just one case of how bugs are introduced in a software system. Finding what introduced a bug is not trivial: bugs can be introduced by the developers and be in the code, or be created irrespective of the code. Thus, further research towards a better understanding of the origin of bugs in software projects could help to improve design integration tests and to design other procedures to make software development more robust.}
}

@comment{SSS}

@inproceedings{Sarker2019,
  doi = {10.1109/icse.2019.00099},
  url = {https://doi.org/10.1109/icse.2019.00099},
  year = {2019},
  month = may,
  publisher = {{IEEE}},
  author = {Farhana Sarker and Bogdan Vasilescu and Kelly Blincoe and Vladimir Filkov},
  title = {Socio-Technical Work-Rate Increase Associates With Changes in Work Patterns in Online Projects},
  booktitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering ({ICSE})},
  abstract = {Software developers work on a variety of tasks ranging from the technical, e.g., writing code, to the social, e.g., participating in issue resolution discussions. The amount of work developers perform per week (their work-rate) also varies and depends on project needs and developer schedules. Prior work has shown that while moderate levels of increased technical work and multitasking lead to higher productivity, beyond a certain threshold, they can lead to lowered performance. Here, we study how increases in the short-term work-rate along both the technical and social dimensions are associated with changes in developers' work patterns, in particular communication sentiment, technical productivity, and social productivity. We surveyed active and prolific developers on GitHub to understand the causes and impacts of increased work-rates. Guided by the responses, we developed regression models to study how communication and committing patterns change with increased work-rates and fit those models to large-scale data gathered from traces left by thousands of GitHub developers. From our survey and models, we find that most developers do experience work-rate-increase-related changes in behavior. Most notably, our models show that there is a sizable effect when developers comment much more than their average: the negative sentiment in their comments increases, suggesting an increased level of stress. Our models also show that committing patterns do not change with increased commenting, and vice versa, suggesting that technical and social activities tend not to be multitasked.}
}

@article{Scalabrino2018,
  doi = {10.1002/smr.1958},
  url = {https://doi.org/10.1002/smr.1958},
  year = {2018},
  month = jun,
  publisher = {Wiley},
  volume = {30},
  number = {6},
  pages = {e1958},
  author = {Simone Scalabrino and Mario Linares-V{\'{a}}squez and Rocco Oliveto and Denys Poshyvanyk},
  title = {A comprehensive model for code readability},
  journal = {Journal of Software: Evolution and Process},
  abstract = {Unreadable code could compromise program comprehension, and it could cause the introduction of bugs. Code consists of mostly natural language text, both in identifiers and comments, and it is a particular form of text. Nevertheless, the models proposed to estimate code readability take into account only structural aspects and visual nuances of source code, such as line length and alignment of characters. In this paper, we extend our previous work in which we use textual features to improve code readability models. We introduce 2 new textual features, and we reassess the readability prediction power of readability models on more than 600 code snippets manually evaluated, in terms of readability, by 5K+ people. We also replicate a study by Buse and Weimer on the correlation between readability and FindBugs warnings, evaluating different models on 20 software systems, for a total of 3M lines of code. The results demonstrate that (1) textual features complement other features and (2) a model containing all the features achieves a significantly higher accuracy as compared with all the other state-of-the-art models. Also, readability estimation resulting from a more accurate model, ie, the combined model, is able to predict more accurately FindBugs warnings.}
}

@article{Scalabrino2021,
  doi = {10.1109/tse.2019.2901468},
  url = {https://doi.org/10.1109/tse.2019.2901468},
  year = {2021},
  month = mar,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {3},
  pages = {595--613},
  author = {Simone Scalabrino and Gabriele Bavota and Christopher Vendome and Mario Linares-Vasquez and Denys Poshyvanyk and Rocco Oliveto},
  title = {Automatically Assessing Code Understandability},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Understanding software is an inherent requirement for many maintenance and evolution tasks. Without a thorough understanding of the code, developers would not be able to fix bugs or add new features timely. Measuring code understandability might be useful to guide developers in writing better code, and could also help in estimating the effort required to modify code components. Unfortunately, there are no metrics designed to assess the understandability of code snippets. In this work, we perform an extensive evaluation of 121 existing as well as new code-related, documentation-related, and developer-related metrics. We try to (i) correlate each metric with understandability and (ii) build models combining metrics to assess understandability. To do this, we use 444 human evaluations from 63 developers and we obtained a bold negative result: none of the 121 experimented metrics is able to capture code understandability, not even the ones assumed to assess quality attributes apparently related, such as code readability and complexity. While we observed some improvements while combining metrics in models, their effectiveness is still far from making them suitable for practical applications. Finally, we conducted interviews with five professional developers to understand the factors that influence their ability to understand code snippets, aiming at identifying possible new metrics.}
}

@inproceedings{Sedano2017,
  doi = {10.1109/icse.2017.20},
  url = {https://doi.org/10.1109/icse.2017.20},
  year = {2017},
  month = may,
  publisher = {{IEEE}},
  author = {Todd Sedano and Paul Ralph and Cecile Peraire},
  title = {Software Development Waste},
  booktitle = {2017 {IEEE}/{ACM} 39th International Conference on Software Engineering ({ICSE})},
  abstract = {Context: Since software development is a complex socio-technical activity that involves coordinating different disciplines and skill sets, it provides ample opportunities for waste to emerge. Waste is any activity that produces no value for the customer or user. Objective: The purpose of this paper is to identify and describe different types of waste in software development. Method: Following Constructivist Grounded Theory, we conducted a two-year five-month participant-observation study of eight software development projects at Pivotal, a software development consultancy. We also interviewed 33 software engineers, interaction designers, and product managers, and analyzed one year of retrospection topics. We iterated between analysis and theoretical sampling until achieving theoretical saturation. Results: This paper introduces the first empirical waste taxonomy. It identifies nine wastes and explores their causes, underlying tensions, and overall relationship to the waste taxonomy found in Lean Software Development. Limitations: Grounded Theory does not support statistical generalization. While the proposed taxonomy appears widely applicable, organizations with different software development cultures may experience different waste types. Conclusion: Software development projects manifest nine types of waste: building the wrong feature or product, mismanaging the backlog, rework, unnecessarily complex solutions, extraneous cognitive load, psychological distress, waiting/multitasking, knowledge loss, and ineffective communication.}
}

@inproceedings{Shao2020,
  doi = {10.1109/icsme46990.2020.00016},
  url = {https://doi.org/10.1109/icsme46990.2020.00016},
  year = {2020},
  month = sep,
  publisher = {{IEEE}},
  author = {Shudi Shao and Zhengyi Qiu and Xiao Yu and Wei Yang and Guoliang Jin and Tao Xie and Xintao Wu},
  title = {Database-Access Performance Antipatterns in Database-Backed Web Applications},
  booktitle = {2020 {IEEE} International Conference on Software Maintenance and Evolution ({ICSME})},
  abstract = {Database-backed web applications are prone to performance bugs related to database accesses. While much work has been conducted on database-access antipatterns with some recent work focusing on performance impact, there still lacks a comprehensive view of database-access performance antipatterns in database-backed web applications. To date, no existing work systematically reports known antipatterns in the literature, and no existing work has studied database-access performance bugs in major types of web applications that access databases differently.To address this issue, we first summarize all known database-access performance antipatterns found through our literature survey, and we report all of them in this paper. We further collect database-access performance bugs from web applications that access databases through language-provided SQL interfaces, which have been largely ignored by recent work, to check how extensively the known antipatterns can cover these bugs. For bugs not covered by the known antipatterns, we extract new database-access performance antipatterns based on real-world performance bugs from such web applications. Our study in total reports 24 known and 10 new database-access performance antipatterns. Our results can guide future work to develop effective tool support for different types of web applications.}
}

@inproceedings{Sharma2021,
  doi = {10.1109/icse43902.2021.00095},
  url = {https://doi.org/10.1109/icse43902.2021.00095},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Pankajeshwara Nand Sharma and Bastin Tony Roy Savarimuthu and Nigel Stanger},
  title = {Extracting Rationale for Open Source Software Development Decisions{\textemdash}A Study of Python Email Archives},
  booktitle = {2021 {IEEE}/{ACM} 43rd International Conference on Software Engineering ({ICSE})},
  abstract = {A sound Decision-Making (DM) process is key to the successful governance of software projects. In many Open Source Software Development (OSSD) communities, DM processes lie buried amongst vast amounts of publicly available data. Hidden within this data lie the rationale for decisions that led to the evolution and maintenance of software products. While there have been some efforts to extract DM processes from publicly available data, the rationale behind 'how' the decisions are made have seldom been explored. Extracting the rationale for these decisions can facilitate transparency (by making them known), and also promote accountability on the part of decision-makers. This work bridges this gap by means of a large-scale study that unearths the rationale behind decisions from Python development email archives comprising about 1.5 million emails. This paper makes two main contributions. First, it makes a knowledge contribution by unearthing and presenting the rationale behind decisions made. Second, it makes a methodological contribution by presenting a heuristics-based rationale extraction system called Rationale Miner that employs multiple heuristics, and follows a data-driven, bottom-up approach to infer the rationale behind specific decisions (e.g., whether a new module is implemented based on core developer consensus or benevolent dictator's pronouncement). Our approach can be applied to extract rationale in other OSSD communities that have similar governance structures.}
}

@inproceedings{Shrestha2020,
  doi = {10.1145/3377811.3380352},
  url = {https://doi.org/10.1145/3377811.3380352},
  year = {2020},
  month = jun,
  publisher = {{ACM}},
  author = {Nischal Shrestha and Colton Botta and Titus Barik and Chris Parnin},
  title = {Here we go again: why is it difficult for developers to learn another programming language?},
  booktitle = {Proceedings of the {ACM}/{IEEE} 42nd International Conference on Software Engineering},
  abstract = {Once a programmer knows one language, they can leverage concepts and knowledge already learned, and easily pick up another programming language. But is that always the case? To understand if programmers have difficulty learning additional programming languages, we conducted an empirical study of Stack Overflow questions across 18 different programming languages. We hypothesized that previous knowledge could potentially interfere with learning a new programming language. From our inspection of 450 Stack Overflow questions, we found 276 instances of interference that occurred due to faulty assumptions originating from knowledge about a different language. To understand why these difficulties occurred, we conducted semi-structured interviews with 16 professional programmers. The interviews revealed that programmers make failed attempts to relate a new programming language with what they already know. Our findings inform design implications for technical authors, toolsmiths, and language designers, such as designing documentation and automated tools that reduce interference, anticipating uncommon language transitions during language design, and welcoming programmers not just into a language, but its entire ecosystem.}
}

@inproceedings{Sliwerski2005,
  doi = {10.1145/1083142.1083147},
  url = {https://doi.org/10.1145/1083142.1083147},
  year = {2005},
  publisher = {{ACM} Press},
  author = {Jacek {\'{S}}liwerski and Thomas Zimmermann and Andreas Zeller},
  title = {When do changes induce fixes?},
  booktitle = {Proceedings of the 2005 international workshop on Mining software repositories  - {MSR} {\textquotesingle}05},
  abstract = {As a software system evolves, programmers make changes that sometimes cause problems. We analyze CVS archives for fix-inducing changes---changes that lead to problems, indicated by fixes. We show how to automatically locate fix-inducing changes by linking a version archive (such as CVS) to a bug database (such as BUGZILLA). In a first investigation of the MOZILLA and ECLIPSE history, it turns out that fix-inducing changes show distinct patterns with respect to their size and the day of week they were applied.}
}

@article{Sobrinho2021,
  doi = {10.1109/tse.2018.2880977},
  url = {https://doi.org/10.1109/tse.2018.2880977},
  year = {2021},
  month = jan,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {1},
  pages = {17--66},
  author = {Elder Vicente de Paulo Sobrinho and Andrea De Lucia and Marcelo de Almeida Maia},
  title = {A Systematic Literature Review on Bad Smells{\textendash}5 W{\textquotesingle}s: Which,  When,  What,  Who,  Where},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Bad smells are sub-optimal code structures that may represent problems needing attention. We conduct an extensive literature review on bad smells relying on a large body of knowledge from 1990 to 2017. We show that some smells are much more studied in the literature than others, and also that some of them are intrinsically inter-related (which). We give a perspective on how the research has been driven across time (when). In particular, while the interest in duplicated code emerged before the reference publications by Fowler and Beck and by Brown et al., other types of bad smells only started to be studied after these seminal publications, with an increasing trend in the last decade. We analyzed aims, findings, and respective experimental settings, and observed that the variability of these elements may be responsible for some apparently contradictory findings on bad smells (what). Moreover, we could observe that, in general, papers tend to study different types of smells at once. However, only a small percentage of those papers actually investigate possible relations between the respective smells (co-studies), i.e., each smell tends to be studied in isolation. Despite of a few relations between some types of bad smells have been investigated, there are other possible relations for further investigation. We also report that authors have different levels of interest in the subject, some of them publishing sporadically and others continuously (who). We observed that scientific connections are ruled by a large "small world" connected graph among researchers and several small disconnected graphs. We also found that the communities studying duplicated code and other types of bad smells are largely separated. Finally, we observed that some venues are more likely to disseminate knowledge on Duplicate Code (which often is listed as a conference topic on its own), while others have a more balanced distribution among other smells (where). Finally, we provide a discussion on future directions for bad smell research.}
}

@article{Soremekun2021,
  doi = {10.1007/s10664-020-09931-7},
  url = {https://doi.org/10.1007/s10664-020-09931-7},
  year = {2021},
  month = apr,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {3},
  author = {Ezekiel Soremekun and Lukas Kirschner and Marcel B\"{o}hme and Andreas Zeller},
  title = {Locating faults with program slicing: an empirical analysis},
  journal = {Empirical Software Engineering},
  abstract = {Statistical fault localization is an easily deployed technique for quickly determining candidates for faulty code locations. If a human programmer has to search the fault beyond the top candidate locations, though, more traditional techniques of following dependencies along dynamic slices may be better suited. In a large study of 457 bugs (369 single faults and 88 multiple faults) in 46 open source C programs, we compare the effectiveness of statistical fault localization against dynamic slicing. For single faults, we find that dynamic slicing was eight percentage points more effective than the best performing statistical debugging formula; for 66\% of the bugs, dynamic slicing finds the fault earlier than the best performing statistical debugging formula. In our evaluation, dynamic slicing is more effective for programs with single fault, but statistical debugging performs better on multiple faults. Best results, however, are obtained by a hybrid approach : If programmers first examine at most the top five most suspicious locations from statistical debugging, and then switch to dynamic slices, on average, they will need to examine 15\% (30 lines) of the code. These findings hold for 18 most effective statistical debugging formulas and our results are independent of the number of faults (i.e. single or multiple faults) and error type (i.e. artificial or real errors).}
}

@article{SotoValero2021,
  doi = {10.1007/s10664-020-09914-8},
  url = {https://doi.org/10.1007/s10664-020-09914-8},
  year = {2021},
  month = mar,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {3},
  author = {C{\'{e}}sar Soto-Valero and Nicolas Harrand and Martin Monperrus and Benoit Baudry},
  title = {A comprehensive study of bloated dependencies in the Maven ecosystem},
  journal = {Empirical Software Engineering},
  abstract = {Build automation tools and package managers have a profound influence on software development. They facilitate the reuse of third-party libraries, support a clear separation between the application's code and its external dependencies, and automate several software development tasks. However, the wide adoption of these tools introduces new challenges related to dependency management. In this paper, we propose an original study of one such challenge: the emergence of bloated dependencies. Bloated dependencies are libraries that the build tool packages with the application's compiled code but that are actually not necessary to build and run the application. This phenomenon artificially grows the size of the built binary and increases maintenance effort. We propose a tool, called DepClean, to analyze the presence of bloated dependencies in Maven artifacts. We analyze 9,639 Java artifacts hosted on Maven Central, which include a total of 723,444 dependency relationships. Our key result is that 75.1\% of the analyzed dependency relationships are bloated. In other words, it is feasible to reduce the number of dependencies of Maven artifacts up to 1/4 of its current count. We also perform a qualitative study with 30 notable open-source projects. Our results indicate that developers pay attention to their dependencies and are willing to remove bloated dependencies: 18/21 answered pull requests were accepted and merged by developers, removing 131 dependencies in total.}
}

@inproceedings{Spadini2019,
  doi = {10.1109/icse.2019.00110},
  url = {https://doi.org/10.1109/icse.2019.00110},
  year = {2019},
  month = may,
  publisher = {{IEEE}},
  author = {Davide Spadini and Fabio Palomba and Tobias Baum and Stefan Hanenberg and Magiel Bruntink and Alberto Bacchelli},
  title = {Test-Driven Code Review: An Empirical Study},
  booktitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering ({ICSE})},
  abstract = {Test-Driven Code Review (TDR) is a code review practice in which a reviewer inspects a patch by examining the changed test code before the changed production code. Although this practice has been mentioned positively by practitioners in informal literature and interviews, there is no systematic knowledge of its effects, prevalence, problems, and advantages. In this paper, we aim at empirically understanding whether this practice has an effect on code review effectiveness and how developers' perceive TDR. We conduct (i) a controlled experiment with 93 developers that perform more than 150 reviews, and (ii) 9 semi-structured interviews and a survey with 103 respondents to gather information on how TDR is perceived. Key results from the experiment show that developers adopting TDR find the same proportion of defects in production code, but more in test code, at the expenses of fewer maintainability issues in production code. Furthermore, we found that most developers prefer to review production code as they deem it more critical and tests should follow from it. Moreover, general poor test code quality and no tool support hinder the adoption of TDR.}
}

@inproceedings{Spadini2020,
  doi = {10.1145/3377811.3380385},
  url = {https://doi.org/10.1145/3377811.3380385},
  year = {2020},
  month = jun,
  publisher = {{ACM}},
  author = {Davide Spadini and G\"{u}l {\c{C}}alikli and Alberto Bacchelli},
  title = {Primers or reminders?: the effects of existing review comments on code review},
  booktitle = {Proceedings of the {ACM}/{IEEE} 42nd International Conference on Software Engineering},
  abstract = {In contemporary code review, the comments put by reviewers on a specific code change are immediately visible to the other reviewers involved. Could this visibility prime new reviewers' attention (due to the human's proneness to availability bias), thus biasing the code review outcome? In this study, we investigate this topic by conducting a controlled experiment with 85 developers who perform a code review and a psychological experiment. With the psychological experiment, we find that ${\approx}$70\% of participants are prone to availability bias. However, when it comes to the code review, our experiment results show that participants are primed only when the existing code review comment is about a type of bug that is not normally considered; when this comment is visible, participants are more likely to find another occurrence of this type of bug. Moreover, this priming effect does not influence reviewers' likelihood of detecting other types of bugs. Our findings suggest that the current code review practice is effective because existing review comments about bugs in code changes are not negative primers, rather positive reminders for bugs that would otherwise be overlooked during code review. Data and materials: https://doi.org/10.5281/zenodo.3653856}
}

@article{Spiegler2021,
  doi = {10.1007/s10664-021-09949-5},
  url = {https://doi.org/10.1007/s10664-021-09949-5},
  year = {2021},
  month = mar,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {26},
  number = {3},
  author = {Simone V. Spiegler and Christoph Heinecke and Stefan Wagner},
  title = {An empirical study on changing leadership in agile teams},
  journal = {Empirical Software Engineering},
  abstract = {An increasing number of companies aim to enable their development teams to work in an agile manner. When introducing agile teams, companies face several challenges. This paper explores the kind of leadership needed to support teams to work in an agile way. One theoretical agile leadership concept describes a Scrum Master who is supposed to empower the team to lead itself. Empirical findings on such a leadership role are controversial. We still have not understood how leadership unfolds in a team that is by definition self-organizing. Further exploration is needed to better understand leadership in agile teams. Our goal is to explore how leadership changes while the team matures using the example of the Scrum Master. Through a grounded theory study containing 75 practitioners from 11 divisions at the Robert Bosch GmbH we identified a set of nine leadership roles that are transferred from the Scrum Master to the Development Team while it matures. We uncovered that a leadership gap and a supportive internal team climate are enablers of the role transfer process, whereas role conflicts may diminish the role transfer. To make the Scrum Master change in a mature team, team members need to receive trust and freedom to take on a leadership role which was previously filled by the Scrum Master. We conclude with practical implications for managers, Product Owners, Development Teams and Scrum Masters which they can apply in real settings.}
}

@article{Spinellis2021,
  doi = {10.1109/tse.2019.2892149},
  url = {https://doi.org/10.1109/tse.2019.2892149},
  year = {2021},
  month = jun,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {6},
  pages = {1134--1163},
  author = {Diomidis Spinellis and Paris Avgeriou},
  title = {Evolution of the Unix System Architecture: An Exploratory Case Study},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Unix has evolved for almost five decades, shaping modern operating systems, key software technologies, and development practices. Studying the evolution of this remarkable system from an architectural perspective can provide insights on how to manage the growth of large, complex, and long-lived software systems. Along main Unix releases leading to the FreeBSD lineage we examine core architectural design decisions, the number of features, and code complexity, based on the analysis of source code, reference documentation, and related publications. We report that the growth in size has been uniform, with some notable outliers, while cyclomatic complexity has been religiously safeguarded. A large number of Unix-defining design decisions were implemented right from the very early beginning, with most of them still playing a major role. Unix continues to evolve from an architectural perspective, but the rate of architectural innovation has slowed down over the system's lifetime. Architectural technical debt has accrued in the forms of functionality duplication and unused facilities, but in terms of cyclomatic complexity it is systematically being paid back through what appears to be a self-correcting process. Some unsung architectural forces that shaped Unix are the emphasis on conventions over rigid enforcement, the drive for portability, a sophisticated ecosystem of other operating systems and development organizations, and the emergence of a federated architecture, often through the adoption of third-party subsystems. These findings have led us to form an initial theory on the architecture evolution of large, complex operating system software.}
}

@article{Stol2018,
  doi = {10.1145/3241743},
  url = {https://doi.org/10.1145/3241743},
  year = {2018},
  month = oct,
  publisher = {Association for Computing Machinery ({ACM})},
  volume = {27},
  number = {3},
  pages = {1--51},
  author = {Klaas-Jan Stol and Brian Fitzgerald},
  title = {The {ABC} of Software Engineering Research},
  journal = {{ACM} Transactions on Software Engineering and Methodology},
  abstract = {A variety of research methods and techniques are available to SE researchers, and while several overviews exist, there is consistency neither in the research methods covered nor in the terminology used. Furthermore, research is sometimes critically reviewed for characteristics inherent to the methods. We adopt a taxonomy from the social sciences, termed here the ABC framework for SE research, which offers a holistic view of eight archetypal research strategies. ABC refers to the research goal that strives for generalizability over Actors (A) and precise measurement of their Behavior (B), in a realistic Context (C). The ABC framework uses two dimensions widely considered to be key in research design: the level of obtrusiveness of the research and the generalizability of research findings. We discuss metaphors for each strategy and their inherent limitations and potential strengths. We illustrate these research strategies in two key SE domains, global software engineering and requirements engineering, and apply the framework on a sample of 75 articles. Finally, we discuss six ways in which the framework can advance SE research.}
}

@comment{TTT}

@article{Taipalus2018,
  doi = {10.1145/3231712},
  url = {https://doi.org/10.1145/3231712},
  year = {2018},
  month = sep,
  publisher = {Association for Computing Machinery ({ACM})},
  volume = {18},
  number = {3},
  pages = {1--29},
  author = {Toni Taipalus and Mikko Siponen and Tero Vartiainen},
  title = {Errors and Complications in {SQL} Query Formulation},
  journal = {{ACM} Transactions on Computing Education},
  abstract = {SQL is taught in almost all university level database courses, yet SQL has received relatively little attention in educational research. In this study, we present a database management system independent categorization of SQL query errors that students make in an introductory database course. We base the categorization on previous literature, present a class of logical errors that has not been studied in detail, and review and complement these findings by analyzing over 33,000 SQL queries submitted by students. Our analysis verifies error findings presented in previous literature and reveals new types of errors, namely logical errors recurring in similar manners among different students. We present a listing of fundamental SQL query concepts we have identified and based our exercises on, a categorization of different errors and complications, and an operational model for designing SQL exercises.}
}

@article{Tamburri2020,
  doi = {10.1002/spe.2874},
  url = {https://doi.org/10.1002/spe.2874},
  year = {2020},
  month = jul,
  publisher = {Wiley},
  volume = {50},
  number = {10},
  pages = {1930--1951},
  author = {Damian Andrew Tamburri and Kelly Blincoe and Fabio Palomba and Rick Kazman},
  title = {{\textquotedblleft}The Canary in the Coal Mine{\ldots}{\textquotedblright} A cautionary tale from the decline of {SourceForge}},
  journal = {Software: Practice and Experience},
  abstract = {Forges are online collaborative platforms to support the development of distributed open source software. While once mighty keepers of open source vitality, software forges are rapidly becoming less and less relevant. For example, of the top 10 forges in 2011, only one survives today---SourceForge---the biggest of them all, but its numbers are dropping and its community is tenuous at best. Through mixed-methods research, this article chronicles and analyze the software practice and experiences of the project's history---in particular its architectural and community/organizational decisions. We discovered a number of suboptimal social and architectural decisions and circumstances that, may have led to SourceForge's demise. In addition, we found evidence suggesting that the impact of such decisions could have been monitored, reduced, and possibly avoided altogether. The use of sociotechnical insights needs to become a basic set of design and software/organization monitoring principles that tell a cautionary tale on what to measure and what not to do in the context of large-scale software forge and community design and management.}
}

@inproceedings{Tan2020a,
  doi = {10.1145/3368089.3409746},
  url = {https://doi.org/10.1145/3368089.3409746},
  year = {2020},
  month = nov,
  publisher = {{ACM}},
  author = {Xin Tan and Minghui Zhou and Zeyu Sun},
  title = {A first look at good first issues on {GitHub}},
  booktitle = {Proceedings of the 28th {ACM} Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  abstract = {Keeping a good influx of newcomers is critical for open source software projects' survival, while newcomers face many barriers to contributing to a project for the first time. To support newcomers onboarding, GitHub encourages projects to apply labels such as good first issue (GFI) to tag issues suitable for newcomers. However, many newcomers still fail to contribute even after many attempts, which not only reduces the enthusiasm of newcomers to contribute but makes the efforts of project members in vain. To better support the onboarding of newcomers, this paper reports a preliminary study on this mechanism from its application status, effect, problems, and best practices. By analyzing 9,368 GFIs from 816 popular GitHub projects and conducting email surveys with newcomers and project members, we obtain the following results. We find that more and more projects are applying this mechanism in the past decade, especially the popular projects. Compared to common issues, GFIs usually need more days to be solved. While some newcomers really join the projects through GFIs, almost half of GFIs are not solved by newcomers. We also discover a series of problems covering mechanism (e.g., inappropriate GFIs), project (e.g., insufficient GFIs) and newcomer (e.g., uneven skills) that makes this mechanism ineffective. We discover the practices that may address the problems, including identifying GFIs that have informative description and available support, and require limited scope and skill, etc. Newcomer onboarding is an important but challenging question in open source projects and our work enables a better understanding of GFI mechanism and its problems, as well as highlights ways in improving them.}
}

@article{Tan2020b,
  doi = {10.1002/smr.2319},
  url = {https://doi.org/10.1002/smr.2319},
  year = {2020},
  month = nov,
  publisher = {Wiley},
  volume = {33},
  number = {4},
  author = {Jie Tan and Daniel Feitosa and Paris Avgeriou and Mircea Lungu},
  title = {Evolution of technical debt remediation in Python: A case study on the Apache Software Ecosystem},
  journal = {Journal of Software: Evolution and Process},
  abstract = {In recent years, the evolution of software ecosystems and the detection of technical debt received significant attention by researchers from both industry and academia. While a few studies that analyze various aspects of technical debt evolution already exist, to the best of our knowledge, there is no large-scale study that focuses on the remediation of technical debt over time in Python projects---that is, one of the most popular programming languages at the moment. In this paper, we analyze the evolution of technical debt in 44 Python open-source software projects belonging to the Apache Software Foundation. We focus on the type and amount of technical debt that is paid back. The study required the mining of over 60K commits, detailed code analysis on 3.7K system versions, and the analysis of almost 43K fixed issues. The findings show that most of the repayment effort goes into testing, documentation, complexity, and duplication removal. Moreover, more than half of the Python technical debt is short term being repaid in less than 2 months. In particular, the observations that a minority of rules account for the majority of issues fixed and spent effort suggest that addressing those kinds of debt in the future is important for research and practice.}
}

@article{Tomasdottir2020,
  doi = {10.1109/tse.2018.2871058},
  url = {https://doi.org/10.1109/tse.2018.2871058},
  year = {2020},
  month = aug,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {46},
  number = {8},
  pages = {863--891},
  author = {Krist\'{i}n Fj\'{o}la T\'{o}masd\'{o}ttir and Maur\'{\i}cio Aniche and Arie van Deursen},
  title = {The Adoption of {JavaScript} Linters in Practice: A Case Study on {ESLint}},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {A linter is a static analysis tool that warns software developers about possible code errors or violations to coding standards. By using such a tool, errors can be surfaced early in the development process when they are cheaper to fix. For a linter to be successful, it is important to understand the needs and challenges of developers when using a linter. In this paper, we examine developers' perceptions on JavaScript linters. We study why and how developers use linters along with the challenges they face while using such tools. For this purpose we perform a case study on ESLint, the most popular JavaScript linter. We collect data with three different methods where we interviewed 15 developers from well-known open source projects, analyzed over 9,500 ESLint configuration files, and surveyed 337 developers from the JavaScript community. Our results provide practitioners with reasons for using linters in their JavaScript projects as well as several configuration strategies and their advantages. We also provide a list of linter rules that are often enabled and disabled, which can be interpreted as the most important rules to reason about when configuring linters. Finally, we propose several feature suggestions for tool makers and future work for researchers.}
}

@inproceedings{Tomassi2019,
  doi = {10.1109/icse.2019.00048},
  url = {https://doi.org/10.1109/icse.2019.00048},
  year = {2019},
  month = may,
  publisher = {{IEEE}},
  author = {David A. Tomassi and Naji Dmeiri and Yichen Wang and Antara Bhowmick and Yen-Chuan Liu and Premkumar T. Devanbu and Bogdan Vasilescu and Cindy Rubio-Gonzalez},
  title = {{BugSwarm}: Mining and Continuously Growing a Dataset of Reproducible Failures and Fixes},
  booktitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering ({ICSE})},
  abstract = {Fault-detection, localization, and repair methods are vital to software quality; but it is difficult to evaluate their generality, applicability, and current effectiveness. Large, diverse, realistic datasets of durably-reproducible faults and fixes are vital to good experimental evaluation of approaches to software quality, but they are difficult and expensive to assemble and keep current. Modern continuous-integration (CI) approaches, like TRAVIS-CI, which are widely used, fully configurable, and executed within custom-built containers, promise a path toward much larger defect datasets. If we can identify and archive failing and subsequent passing runs, the containers will provide a substantial assurance of durable future reproducibility of build and test. Several obstacles, however, must be overcome to make this a practical reality. We describe BUGSWARM, a toolset that navigates these obstacles to enable the creation of a scalable, diverse, realistic, continuously growing set of durably reproducible failing and passing versions of real-world, open-source systems. The BUGSWARM toolkit has already gathered 3,091 fail-pass pairs, in Java and Python, all packaged within fully reproducible containers. Furthermore, the toolkit can be run periodically to detect fail-pass activities, thus growing the dataset continually.}
}

@inproceedings{Tourani2017,
  doi = {10.1109/saner.2017.7884606},
  url = {https://doi.org/10.1109/saner.2017.7884606},
  year = {2017},
  month = feb,
  publisher = {{IEEE}},
  author = {Parastou Tourani and Bram Adams and Alexander Serebrenik},
  title = {Code of conduct in open source projects},
  booktitle = {2017 {IEEE} 24th International Conference on Software Analysis,  Evolution and Reengineering ({SANER})},
  abstract = {Open source projects rely on collaboration of members from all around the world using web technologies like GitHub and Gerrit. This mixture of people with a wide range of backgrounds including minorities like women, ethnic minorities, and people with disabilities may increase the risk of offensive and destroying behaviours in the community, potentially leading affected project members to leave towards a more welcoming and friendly environment. To counter these effects, open source projects increasingly are turning to codes of conduct, in an attempt to promote their expectations and standards of ethical behaviour. In this first of its kind empirical study of codes of conduct in open source software projects, we investigated the role, scope and influence of codes of conduct through a mixture of quantitative and qualitative analysis, supported by interviews with practitioners. We found that the top codes of conduct are adopted by hundreds to thousands of projects, while all of them share 5 common dimensions.}
}

@inproceedings{Tregubov2017,
  doi = {10.1145/3084100.3084116},
  url = {https://doi.org/10.1145/3084100.3084116},
  year = {2017},
  month = jul,
  publisher = {{ACM}},
  author = {Alexey Tregubov and Barry Boehm and Natalia Rodchenko and Jo Ann Lane},
  title = {Impact of task switching and work interruptions on software development processes},
  booktitle = {Proceedings of the 2017 International Conference on Software and System Process},
  abstract = {Software developers often work on multiple projects and tasks throughout a work day, which may affect their productivity and quality of work. Knowing how working on several projects at a time affects productivity can improve cost and schedule estimations. It also can provide additional insights for better work scheduling and the development process. We want to achieve a better productivity without losing the benefits of work interruptions and multitasking for developers involved in the process. To understand how the development process can be improved, first, we identify work interruptions that mostly have a negative effect on productivity, second, we need to quantitatively evaluate impact of multitasking (task switching, work context switching) and work interruptions on productivity. In this research we study cross-project multitasking among the developers working on multiple projects in an educational setting. We propose a way to evaluate the number of cross-project interruptions among software developers using self-reported work logs. This paper describes the research that found: a) software developers involved in two or more projects on average spend 17\% of their development effort on cross-project interruptions, b) the amount of effort spent on interruptions is overestimated by the G. Weinberg's heuristic, c) the correlation between the number of projects and effort spent by developers on cross-project interruptions is relatively weak, and d) there is strong correlation between the number of projects and the number of interruptions developers reported.}
}

@comment{UUU}

@comment{VVV}

@article{Venigalla2021,
  doi = {10.1002/spe.2985},
  url = {https://doi.org/10.1002/spe.2985},
  year = {2021},
  month = may,
  publisher = {Wiley},
  volume = {51},
  number = {8},
  pages = {1728--1744},
  author = {Akhila Sri Manasa Venigalla and Sridhar Chimalakonda},
  title = {On the comprehension of application programming interface usability in game engines},
  journal = {Software: Practice and Experience},
  abstract = {Extensive development of games for various purposes including education and entertainment has resulted in increased development of game engines. Game engines are being used on a large scale as they support and simplify game development to a greater extent. Game developers using game engines are often compelled to use various application programming interfaces (APIs) of game engines in the process of game development. Thus, both quality and ease of development of games are greatly influenced by APIs defined in game engines. Hence, understanding API usability in game engines could greatly help in choosing better game engines among the ones that are available for game development and also could help developers in designing better game engines. In this article, we thus aim to evaluate API usability of 95 publicly available game engine repositories on GitHub, written primarily in C++ programming language. We test API usability of these game engines against the eight structural API usability metrics---AMNOI, AMNCI, AMGI, APXI, APLCI, AESI, ATSI, and ADI. We see this research as a first step toward the direction of improving usability of APIs in game engines. We present the results of the study, which indicate that about 25\% of the game engines considered have minimal API usability, with respect to the considered metrics. It was observed that none of the considered repositories have ideal (all metric scores equal to 1) API usability, indicating the need for developers to consider API usability metrics while designing game engines.}
}

@comment{WWW}

@inproceedings{Wang2020,
  doi = {10.1145/3379597.3387464},
  url = {https://doi.org/10.1145/3379597.3387464},
  year = {2020},
  month = jun,
  publisher = {{ACM}},
  author = {Peipei Wang and Chris Brown and Jamie A. Jennings and Kathryn T. Stolee},
  title = {An Empirical Study on Regular Expression Bugs},
  booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
  abstract = {Understanding the nature of regular expression (regex) issues is important to tackle practical issues developers face in regular expression usage. Knowledge about the nature and frequency of various types of regular expression issues, such as those related to performance, API misuse, and code smells, can guide testing, inform documentation writers, and motivate refactoring efforts. However, beyond ReDoS (Regular expression Denial of Service), little is known about to what extent regular expression issues affect software development and how these issues are addressed in practice. This paper presents a comprehensive empirical study of 350 merged regex-related pull requests from Apache, Mozilla, Facebook, and Google GitHub repositories. Through classifying the root causes and manifestations of those bugs, we show that incorrect regular expression behavior is the dominant root cause of regular expression bugs (165/356, 46.3\%). The remaining root causes are incorrect API usage (9.3\%) and other code issues that require regular expression changes in the fix (29.5\%). By studying the code changes of regex-related pull requests, we observe that fixing regular expression bugs is nontrivial as it takes more time and more lines of code to fix them compared to the general pull requests. The results of this study contribute to a broader understanding of the practical problems faced by developers when using regular expressions.}
}

@article{Weintrop2017,
  doi = {10.1145/3089799},
  url = {https://doi.org/10.1145/3089799},
  year = {2017},
  month = dec,
  publisher = {Association for Computing Machinery ({ACM})},
  volume = {18},
  number = {1},
  pages = {1--25},
  author = {David Weintrop and Uri Wilensky},
  title = {Comparing Block-Based and Text-Based Programming in High School Computer Science Classrooms},
  journal = {{ACM} Transactions on Computing Education},
  abstract = {The number of students taking high school computer science classes is growing. Increasingly, these students are learning with graphical, block-based programming environments either in place of or prior to traditional text-based programming languages. Despite their growing use in formal settings, relatively little empirical work has been done to understand the impacts of using block-based programming environments in high school classrooms. In this article, we present the results of a 5-week, quasi-experimental study comparing isomorphic block-based and text-based programming environments in an introductory high school programming class. The findings from this study show students in both conditions improved their scores between pre- and postassessments; however, students in the blocks condition showed greater learning gains and a higher level of interest in future computing courses. Students in the text condition viewed their programming experience as more similar to what professional programmers do and as more effective at improving their programming ability. No difference was found between students in the two conditions with respect to confidence or enjoyment. The implications of these findings with respect to pedagogy and design are discussed, along with directions for future work.}
}

@inproceedings{Weir2021,
  doi = {10.1109/icse-seip52600.2021.00011},
  url = {https://doi.org/10.1109/icse-seip52600.2021.00011},
  year = {2021},
  month = may,
  publisher = {{IEEE}},
  author = {Charles Weir and Ingolf Becker and Lynne Blair},
  title = {A Passion for Security: Intervening to Help Software Developers},
  booktitle = {2021 {IEEE}/{ACM} 43rd International Conference on Software Engineering: Software Engineering in Practice ({ICSE}-{SEIP})},
  abstract = {While the techniques to achieve secure, privacy-preserving software are now well understood, evidence shows that many software development teams do not use them: they lack the 'security maturity' to assess security needs and decide on appropriate tools and processes; and they lack the ability to negotiate with product management for the required resources. This paper describes a measuring approach to assess twelve aspects of this security maturity; its use to assess the impact of a lightweight package of workshops designed to increase security maturity; and a novel approach within that package to support developers in resource negotiation. Based on trials in eight organizations, involving over 80 developers, this paper demonstrates that (1) development teams can notably improve their security maturity even in the absence of security specialists; and (2) suitably guided, developers can find effective ways to promote security to product management. Empowering developers to make their own decisions and promote security in this way offers a powerful grassroots approach to improving the security of software worldwide.}
}

@inproceedings{Wessel2020,
  doi = {10.1109/icsme46990.2020.00011},
  url = {https://doi.org/10.1109/icsme46990.2020.00011},
  year = {2020},
  month = sep,
  publisher = {{IEEE}},
  author = {Mairieli Wessel and Alexander Serebrenik and Igor Wiese and Igor Steinmacher and Marco A. Gerosa},
  title = {Effects of Adopting Code Review Bots on Pull Requests to {OSS} Projects},
  booktitle = {2020 {IEEE} International Conference on Software Maintenance and Evolution ({ICSME})},
  abstract = {Software bots, which are widely adopted by Open Source Software (OSS) projects, support developers on several activities, including code review. However, as with any new technology adoption, bots may impact group dynamics. Since understanding and anticipating such effects is important for planning and management, we investigate how several activity indicators change after the adoption of a code review bot. We employed a regression discontinuity design on 1,194 software projects from GitHub. Our results indicate that the adoption of code review bots increases the number of monthly merged pull requests, decreases monthly non-merged pull requests, and decreases communication among developers. Practitioners and maintainers may leverage our results to understand, or even predict, bot effects on their projects' social interactions.}
}

@comment{XXX}

@comment{YYY}

@inproceedings{Yasmin2020,
  doi = {10.1109/icsme46990.2020.00024},
  url = {https://doi.org/10.1109/icsme46990.2020.00024},
  year = {2020},
  month = sep,
  publisher = {{IEEE}},
  author = {Jerin Yasmin and Yuan Tian and Jinqiu Yang},
  title = {A First Look at the Deprecation of {RESTful} {APIs}: An Empirical Study},
  booktitle = {2020 {IEEE} International Conference on Software Maintenance and Evolution ({ICSME})},
  abstract = {REpresentational State Transfer (REST) is considered as one standard software architectural style to build web APIs that can integrate software systems over the internet. However, while connecting systems, RESTful APIs might also break the dependent applications that rely on their services when they introduce breaking changes, e.g., an older version of the API is no longer supported. To warn developers promptly and thus prevent critical impact on downstream applications, a deprecated-removed model should be followed, and deprecation-related information such as alternative approaches should also be listed. While API deprecation analysis as a theme is not new, most existing work focuses on non-web APIs, such as the ones provided by Java and Android.To investigate RESTful API deprecation, we propose a framework called RADA (RESTful API Deprecation Analyzer). RADA is capable of automatically identifying deprecated API elements and analyzing impacted operations from an OpenAPI specification, a machine-readable profile for describing RESTful web service. We apply RADA on 2,224 OpenAPI specifications of 1,368 RESTful APIs collected from APIs.guru, the largest directory of OpenAPI specifications. Based on the data mined by RADA, we perform an empirical study to investigate how the deprecated-removed protocol is followed in RESTful APIs and characterize practices in RESTful API deprecation. The results of our study reveal several severe deprecation-related problems in existing RESTful APIs. Our implementation of RADA and detailed empirical results are publicly available for future intelligent tools that could automatically identify and migrate usage of deprecated RESTful API operations in client code.}
}

@article{Yu2021,
  doi = {10.1109/tse.2019.2910516},
  url = {https://doi.org/10.1109/tse.2019.2910516},
  year = {2021},
  month = may,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {5},
  pages = {969--986},
  author = {Zhongxing Yu and Chenggang Bai and Lionel Seinturier and Martin Monperrus},
  title = {Characterizing the Usage,  Evolution and Impact of Java Annotations in Practice},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Annotations have been formally introduced into Java since Java 5. Since then, annotations have been widely used by the Java community for different purposes, such as compiler guidance and runtime processing. Despite the ever-growing use, there is still limited empirical knowledge about the actual usage of annotations in practice, the changes made to annotations during software evolution, and the potential impact of annotations on code quality. To fill this gap, we perform the first large-scale empirical study about Java annotations on 1,094 notable open-source projects hosted on GitHub. Our study systematically investigates annotation usage, annotation evolution, and annotation impact, and generates 10 novel and important findings. We also present the implications of our findings, which shed light for developers, researchers, tool builders, and language or library designers in order to improve all facets of Java annotation engineering.}
}

@comment{ZZZ}

@article{Zampetti2020,
  doi = {10.1007/s10664-019-09785-8},
  url = {https://doi.org/10.1007/s10664-019-09785-8},
  year = {2020},
  month = jan,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {25},
  number = {2},
  pages = {1095--1135},
  author = {Fiorella Zampetti and Carmine Vassallo and Sebastiano Panichella and Gerardo Canfora and Harald Gall and Massimiliano Di Penta},
  title = {An empirical characterization of bad practices in continuous integration},
  journal = {Empirical Software Engineering},
  abstract = {Continuous Integration (CI) has been claimed to introduce several benefits in software development, including high software quality and reliability. However, recent work pointed out challenges, barriers and bad practices characterizing its adoption. This paper empirically investigates what are the bad practices experienced by developers applying CI. The investigation has been conducted by leveraging semi-structured interviews of 13 experts and mining more than 2,300 Stack Overflow posts. As a result, we compiled a catalog of 79 CI bad smells belonging to 7 categories related to different dimensions of a CI pipeline management and process. We have also investigated the perceived importance of the identified bad smells through a survey involving 26 professional developers, and discussed how the results of our study relate to existing knowledge about CI bad practices. Whilst some results, such as the poor usage of branches, confirm existing literature, the study also highlights uncovered bad practices, e.g., related to static analysis tools or the abuse of shell scripts, and contradict knowledge from existing literature, e.g., about avoiding nightly builds. We discuss the implications of our catalog of CI bad smells for (i) practitioners, e.g., favor specific, portable tools over hacking, and do not ignore nor hide build failures, (ii) educators, e.g., teach CI culture, not just technology, and teach CI by providing examples of what not to do, and (iii) researchers, e.g., developing support for failure analysis, as well as automated CI bad smell detectors.}
}

@article{Zhang2020,
  doi = {10.1109/tse.2019.2954319},
  url = {https://doi.org/10.1109/tse.2019.2954319},
  year = {2020},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  pages = {1--1},
  author = {Haoxiang Zhang and Shaowei Wang and Tse-Hsun Chen and Ahmed E. Hassan},
  title = {Reading Answers on Stack Overflow: Not Enough!},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Stack Overflow is one of the most active communities for developers to share their programming knowledge. Answers posted on Stack Overflow help developers solve issues during software development. In addition to posting answers, users can also post comments to further discuss their associated answers. As of Aug 2017, there are 32.3 million comments that are associated with answers, forming a large collection of crowdsourced repository of knowledge on top of the commonly-studied Stack Overflow answers. In this study, we wish to understand how the commenting activities contribute to the crowdsourced knowledge. We investigate what users discuss in comments, and analyze the characteristics of the commenting dynamics, (i.e., the timing of commenting activities and the roles of commenters). We find that: 1) the majority of comments are informative and thus can enhance their associated answers from a diverse range of perspectives. However, some comments contain content that is discouraged by Stack Overflow. 2) The majority of commenting activities occur after the acceptance of an answer. More than half of the comments are fast responses occurring within one day of the creation of an answer, while later comments tend to be more informative. Most comments are rarely integrated back into their associated answers, even though such comments are informative. 3) Insiders (i.e., users who posted questions/answers before posting a comment in a question thread) post the majority of comments within one month, and outsiders (i.e., users who never posted any question/answer before posting a comment) post the majority of comments after one month. Inexperienced users tend to raise limitations and concerns while experienced users tend to enhance the answer through commenting. Our study provides insights into the commenting activities in terms of their content, timing, and the individuals who perform the commenting. For the purpose of long-term knowledge maintenance and effective information retrieval for developers, we also provide actionable suggestions to encourage Stack Overflow users/engineers/moderators to leverage our insights for enhancing the current Stack Overflow commenting system for improving the maintenance and organization of the crowdsourced knowledge.}
}

@article{Zhang2021a,
  doi = {10.1109/tse.2019.2919304},
  url = {https://doi.org/10.1109/tse.2019.2919304},
  year = {2021},
  month = jun,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {6},
  pages = {1299--1314},
  author = {Jingxuan Zhang and He Jiang and Zhilei Ren and Tao Zhang and Zhiqiu Huang},
  title = {Enriching {API} Documentation with Code Samples and Usage Scenarios from Crowd Knowledge},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {As one key resource to learn Application Programming Interfaces (APIs), a lot of API reference documentation lacks code samples with usage scenarios, thus heavily hindering developers from programming with APIs. Although researchers have investigated how to enrich API documentation with code samples from general code search engines, two main challenges remain to be resolved, including the quality challenge of acquiring high-quality code samples and the mapping challenge of matching code samples to usage scenarios. In this study, we propose a novel approach named ADECK towards enriching API documentation with code samples and corresponding usage scenarios by leveraging crowd knowledge from Stack Overflow, a popular technical Question and Answer (Q\&A) website attracting millions of developers. Given an API related Q\&A pair, a code sample in the answer is extensively evaluated by developers and targeted towards resolving the question under the specified usage scenario. Hence, ADECK can obtain high-quality code samples and map them to corresponding usage scenarios to address the above challenges. Extensive experiments on the Java SE and Android API documentation show that the number of code-sample-illustrated API types in the ADECK-enriched API documentation is 3.35 and 5.76 times as many as that in the raw API documentation. Meanwhile, the quality of code samples obtained by ADECK is better than that of code samples by the baseline approach eXoaDocs in terms of correctness, conciseness, and usability, e.g., the average correctness values of representative code samples obtained by ADECK and eXoaDocs are 4.26 and 3.28 on a 5-point scale in the enriched Java SE API documentation. In addition, an empirical study investigating the impacts of different types of API documentation on the productivity of developers shows that, compared against the raw and the eXoaDocs-enriched API documentation, the ADECK-enriched API documentation can help developers complete 23.81 and 14.29 percent more programming tasks and reduce the average completion time by 9.43 and 11.03 percent.}
}

@article{Zhang2021b,
  doi = {10.1109/tse.2019.2906315},
  url = {https://doi.org/10.1109/tse.2019.2906315},
  year = {2021},
  month = apr,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {47},
  number = {4},
  pages = {850--862},
  author = {Haoxiang Zhang and Shaowei Wang and Tse-Hsun Chen and Ying Zou and Ahmed E. Hassan},
  title = {An Empirical Study of Obsolete Answers on Stack Overflow},
  journal = {{IEEE} Transactions on Software Engineering},
  abstract = {Stack Overflow accumulates an enormous amount of software engineering knowledge. However, as time passes, certain knowledge in answers may become obsolete. Such obsolete answers, if not identified or documented clearly, may mislead answer seekers and cause unexpected problems (e.g., using an out-dated security protocol). In this paper, we investigate how the knowledge in answers becomes obsolete and identify the characteristics of such obsolete answers. We find that: 1) More than half of the obsolete answers (58.4 percent) were probably already obsolete when they were first posted. 2) When an obsolete answer is observed, only a small proportion (20.5 percent) of such answers are ever updated. 3) Answers to questions in certain tags (e.g., node.js, ajax, android, and objective-c) are more likely to become obsolete. Our findings suggest that Stack Overflow should develop mechanisms to encourage the whole community to maintain answers (to avoid obsolete answers) and answer seekers are encouraged to carefully go through all information (e.g., comments) in answer threads.}
}

@inproceedings{Zieris2020,
  doi = {10.1145/3377811.3380925},
  url = {https://doi.org/10.1145/3377811.3380925},
  year = {2020},
  month = jun,
  publisher = {{ACM}},
  author = {Franz Zieris and Lutz Prechelt},
  title = {Explaining pair programming session dynamics from knowledge gaps},
  booktitle = {Proceedings of the {ACM}/{IEEE} 42nd International Conference on Software Engineering},
  abstract = {Background: Despite a lot of research on the effectiveness of Pair Programming (PP), the question when it is useful or less useful remains unsettled. Method: We analyze recordings of many industrial PP sessions with Grounded Theory Methodology and build on prior work that identified various phenomena related to within-session knowledge build-up and transfer. We validate our findings with practitioners. Result: We identify two fundamentally different types of required knowledge and explain how different constellations of knowledge gaps in these two respects lead to different session dynamics. Gaps in project-specific systems knowledge are more hampering than gaps in general programming knowledge and are dealt with first and foremost in a PP session. Conclusion: Partner constellations with complementary knowledge make PP a particularly effective practice. In PP sessions, differences in system understanding are more important than differences in general software development knowledge.}
}
