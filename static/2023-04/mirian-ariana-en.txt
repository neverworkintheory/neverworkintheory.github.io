Thank you so much for the intro and thank you for having me here.
So yeah folks, I'm super excited to be here,
my name is Ariana and I just on Friday defended my PhD at the University of California San Diego.
And so this work was possible in large part because of a collaboration with the IT team at UCSD,
who I've been working over the last year and a half as an embedded security researcher within their operations team,
so a big thank you to that entire team and all the truly amazing work they do.
And so generally my work has been broadly on understanding and improving security processes,
your large-scale measurement,
and today I'm going to talk about the theory and practice of vulnerability remediation
and a very specific type of developer from a security lens: system administrators.
And so many organizations, especially newer ones, have moved their organizational infrastructure into the cloud.
AWS is large, GCP is large, and a lot of organizations have started to take advantage of that
and move their physical hardware components into the cloud so they no longer need to maintain the physical piece of hardware
but things are abstracted for them.
However,
not all organizations have or can do this.
In fact,
there are many organizations that have legacy machines,
or in other terms bare metal - the more canonical term that are - that still exist
and are critical pieces of infrastructure.
And UCSD is one of these such organizations where they definitely utilize cloud services
but there's just a ton of legacy systems that still exist physically on premise.
And so the theory, in an ideal world, is that every piece of infrastructure in an organization that is on premise is up-to-date security-wise.
So you have system administrators who are the ones generally maintaining these pieces of bare metal
who make sure that every piece of software and hardware is up to date
and there's no issues.
But the reality is that these disparate physical systems can affect the safety posture of an org
and they can have a large number of vulnerabilities that are very difficult to triage and maintain
and that an attacker can ultimately utilize to get into the system and thus the organization itself.
And so this process of getting rid of vulnerabilities is called patching or vulnerability remediation
and I'll use those terms sort of interchangeably.
And patching isn't a new problem I know there are folks in this crowd who are probably nodding their head,
like, yeah, it is a pain,
but it persists
and there are advances that have made patching an easier process
especially for organizations or parts of organizations that have been able to transition to cloud services,
like automation, abstraction,
and the thing about a lot of these advancements is that they optimize for the machine not the human.
And so when you're in an organization that still has legacy systems on premise
and still needs to maintain them
the question that i went out - set out to answer was, what if we tune the process for the human in the loop?
What if we took the process and the technologies that are being employed
and examined holistically how to make this process easier for the people doing the job?
In other terms,
how can we make patching a more effective process?
And so we asked this question in our organization at UCSD,
because like I said I've been working as an embedded security researcher
and this was an issue that was continually coming up -
that, oh, we, you know, are having difficulty getting people patch.
And so in order to answer this question and examine how we can optimize for the human in the loop
we first have to examine what was being done before.
And so I sat down with the team that was in charge of sending out these notifications
and this is an example of a notification that was sent out to folks within the IT team at our organization.
It was essentially a weekly report that was meant to give these admins information,
you know,
it's like - and just to read off bits of this -
it says, "The systems below have active critical or high severities, please patch within 24 hours,"
and then at the end of the email it listed who's the technical contact,
the host name, IP address, and then also listed a link for how they could get more information from Qualis
which is the third party tool that our organization utilizes for vulnerability scanning and information gathering.
And looking at this there were a couple things that stood out,
especially having done a related work search in the literature.
First,
it required users to go and log in to Qualis,
so not only required them to do this additional step but it required them to have a login to Qualis.
And if any of you have worked in a large organization,
you know that it is not always the easiest to get logins into third-party tools.
The second thing that really stood out is that
the email listed the raw number of vulnerabilities,
so in this instance there was one severity five which is critical,
and eight severity four,
but it didn't list the type -
it didn't give any other information.
It really relied on the system administrator having access and having time in that moment to go log into Qualis
to look up one of the sev 4's,sev 5's.
And with any third party tool there are obviously issues - down times - so this didn't help.
And so what I'm trying to get at is that this old notification was not ideal.
It was a weekly notification which is great in theory,
but it did not list the vulnerabilities or additional details it required these system administrators -
who were already juggling many jobs -
to perform extra steps to get the necessary information,
and it adds this amount of friction that is required in order to execute.
And so again,
working with the security team and taking best practices from security literature and looking at what has been done with vulnerability notification,
I worked with the team to craft a new notification in a new pipeline.
And so this is the new notification that gets sent out.
And the things that I want to draw your attention to is that,
one,
each email focuses on a very specific type of vulnerability,
so instead of sending a laundry list of "here are the nine on your system" or whatever,
this focuses just on Microsoft Windows security updates.
There are instructions on how to patch the system just in case this was a new vulnerability that they weren't aware of,
and at the end of this email,
which is cut out in the screenshot,
there was a CSV that was pulled from the third party tool
that had a plethora of additional metadata,
so it had the host name, the IP,
but I also had things like the full vulnerability name,
this - the CVE, other pieces of information that system administrators find really helpful.
And so for this first step,
to try and address how do we make patching a more efficient process,
we examine the old notification,
proposed changes that reduce effort and time from the system administrators,
and crafted new notifications that have actionable items focused on one vulnerability
and listed all machines and vulnerability types in the attached CSV.
But like I mentioned at the beginning of this talk,
I do a lot of large-scale quantitative data analysis,
and so we don't actually know whether these changes were effective until we went and analyzed the subsequent data.
And so I created an in-house pipeline that can be automatically run
that takes all the pieces of information from the system administrator side
and essentially produces a series of analyses that we can break down into different ways.
And in aggregate we saw that because of these changes,
the patching rate increased from 3% to 78% which is a huge difference.
This is already a success,
but the natural next question was,
"Why was the patch rate only at 78%?"
It seemed like we were doing everything right,
we have looked at the related work,
we're doing best practices,
and it was still not at a hundred percent.
And so the beauty of data is that there are different ways to look and slice it.
And so first,
I looked to see what different contacts - how they were patching their machines.
And we found that some contacts are just much better at patching.
When we then looked at the vulnerability families,
we found that certain vulnerability families get patched more things.
Like Zoom, browsers, standalone applications - were getting patched faster and at much higher rates
than things like operating system distros like Red Hat.
And the hypothesis there,
which you know intuitively makes some sense,
is that standalone applications that have easier patching processes were easier to prioritize
because they don't require downtime for the system administrator.
Because again,
system administrators are juggling many jobs and many needs,
including the needs of people who are using those machines.
And then finally we also found that some vulnerability families just take more time to patch,
and so this is kind of following up from the the last analysis,
which is that there were some vulnerability families,
like operating system distros, and, like, Microsoft Windows updates,
that just took more time,
and we - again, the hypothesis is that there is some overhead that is required there that was slowing the process down.
But at this step, you know,
we took a step back, okay,
the quantitative data is telling us a lot,
but we also conducted semi-structured interviews with the system administrators
because we knew them, they knew us,
to add the qualitative view to the quantitative data.
And we learned a lot in these interviews.
And some of the high-level takeaways was that,
first off,
the monotonicity of the old email notification made it really easy to ignore.
And the reason that we were seeing a much higher patch rate with this new notification was because it wasn't the same thing every week.
We also found that many teams have exception - exceptions,
and this was actually super interesting for us because it showed that
there was a discrepancy between the vulnerability remediation notification pipeline and this exception pipeline.
There are some teams that have exceptions for various servers, various vulnerabilities,
and they thought that that was getting incorporated in the vulnerability pipeline.
And now that we know that there's a discrepancy,
we are working on adding that in.
We also found that notifications fall outside of th assessment patch cycles,
you know,
if we send an email on the second Tuesday,
they hadn't gotten to patching around - they hadn't gotten to patching the system yet -
because they were patching on the second week of that month.
And so this added a lot of additional insight into why the patch rate was only at 78%.
And overall we found that there was very positive sentiment towards a new notification,
but there was room for improvement and better integrations.
And so the - while the theory is that if you do everything right then folks will just follow,
the practice is that there are these very real blockers that you need to take into account,
especially blockers that are unique to your organization.
And so in summary I looked at how we could increase the efficacy of patching within our organization.
We applied some very basic principles to reduce friction for system administrators
and in aggregate increase the patch rate from 3% to 78%
but additionally we found that by interviewing the system administrators,
many of them had a positive sentiment towards this notification
and that there were discrepancies in different systems that we can work on
to make it even more accurate and more productive moving forward.
And with that I'm happy to take questions and I'm also happy to take questions offline at these various pieces of online communication.
Thank you so much.
Fantastic thank you so much for a great and engaging presentation kicking off this last hour,
so again audience please make sure you're putting any questions that you have into the chat,
we have a few minutes so I am gonna kick off with a clarification question that probably would have a pretty easy answer.
So, like, the vulnerability - vulnerability families that you mentioned, I think that's really interesting concept obviously,
helps us think about that space,
is that a direct mapping to the kind of technology that's being built
or is that kind of, like, with security vulnerabilities where there's like ways to think about the types of security vulnerabilities that you have
regardless of the platform or the context or domain?
Yeah, really good question,
so when I say vulnerability families,
it's actually kind of a mix of both.
So it is very specific security vulnerabilities but for the given applications that were on the servers.
And so you know like, Zoom - Zoom for example has various, like, RCE vulnerabilities
but if a server that a system administrator was managing didn't have Zoom we didn't notify them on that,
it was,
we only notified them on the application and then also the type of vulnerability,
and so I guess to clarify a little bit further,
the emails focused on applications and then the CSV - the thing that was helpful for sys admins,
is that we then listed in the CSV the different types of security vulnerabilities
because different teams have different threat models,
you know,
some teams are like, "We're going to prioritize prioritize X over Y,"
and so it's useful that for them to know how many of X versus y there were.
Absolutely.
